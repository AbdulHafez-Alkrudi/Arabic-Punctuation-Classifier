{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "659c9b84",
   "metadata": {},
   "source": [
    "# ๐ง ุฎุท ุฃูุงุจูุจ ุงููุนุงูุฌุฉ ุงููุณุจูุฉ ููุฌููุนุฉ ุจูุงูุงุช ุงูุชุฑููู ุงูุนุฑุจู\n",
    "## ูุนุงูุฌุฉ ูููู SSAC-UNPC\n",
    "\n",
    "---\n",
    "\n",
    "### ๐ ุฌุฏูู ุงููุญุชููุงุช\n",
    "\n",
    "1. [ุงูููุฏูุฉ ูุงูุฅุนุฏุงุฏ](#1-ุงูููุฏูุฉ-ูุงูุฅุนุฏุงุฏ)\n",
    "2. [ุงูุฌุฒุก 1: ูุญุต ุงููุดููุงุช (ูุจู ุงููุนุงูุฌุฉ)](#2-ุงูุฌุฒุก-1-ูุญุต-ุงููุดููุงุช-ูุจู-ุงููุนุงูุฌุฉ)\n",
    "   - 2.1 ูุดููุงุช ูุณุชูู ุงูุญุฑูู\n",
    "   - 2.2 ูุดููุงุช ุนูุงูุงุช ุงูุชุฑููู\n",
    "   - 2.3 ูุดููุงุช ูุณุชูู ุงูุฌูู\n",
    "   - 2.4 ูุดููุงุช ุงูุฃููุงุท ุงูุฎุงุตุฉ\n",
    "3. [ุงูุฌุฒุก 2: ุฎุทูุงุช ุงููุนุงูุฌุฉ ุงูุฅูุฒุงููุฉ](#3-ุงูุฌุฒุก-2-ุฎุทูุงุช-ุงููุนุงูุฌุฉ-ุงูุฅูุฒุงููุฉ)\n",
    "   - 3.1 ุฅุฒุงูุฉ ุงูุชุดููู (ุงูุญุฑูุงุช)\n",
    "   - 3.2 ุชูุญูุฏ ุฃุดูุงู ุงูุฃูู\n",
    "   - 3.3 ุชูุญูุฏ ุงูุชุงุก ุงููุฑุจูุทุฉ ูุงูุฃูู ุงูููุตูุฑุฉ\n",
    "   - 3.4 ุฅุฒุงูุฉ ุงูุญุฑูู ุฎุงุฑุฌ ุงููุทุงู (OOV)\n",
    "   - 3.5 ุฅุฒุงูุฉ ุงูุญุฑูู ุงููุงุชูููุฉ\n",
    "   - 3.6 ุชูุญูุฏ ุงูุฃุฑูุงู (ุงูุฃุฑูุงู ุงูุนุฑุจูุฉ)\n",
    "   - 3.7 ุชูุญูุฏ ุนูุงูุงุช ุงูุชุฑููู (ุงูุชุฑููู ุงูุนุฑุจู)\n",
    "   - 3.8 ูุนุงูุฌุฉ ุงูุชุฑููู ุงููุชุชุงุจุน\n",
    "   - 3.9 ุชูุญูุฏ ุงููุณุงูุงุช ูุถุจุท ูุณุงูุงุช ุงูุชุฑููู\n",
    "   - 3.10 ุฅุฒุงูุฉ ุงูุฃุณุทุฑ ุงููุงุฑุบุฉ ูุงููุตูุฑุฉ ุฌุฏุงู\n",
    "   - 3.11 ูุนุงูุฌุฉ ุงูุฌูู ุงูุทูููุฉ\n",
    "4. [ุงูุฌุฒุก 3: ุฎุทูุงุช ุงููุนุงูุฌุฉ ุงูุงุฎุชูุงุฑูุฉ (ููุชุฌุฑูุจ)](#4-ุงูุฌุฒุก-3-ุฎุทูุงุช-ุงููุนุงูุฌุฉ-ุงูุงุฎุชูุงุฑูุฉ)\n",
    "   - 4.1 ูุตู ูุงู ุงูุนุทู ุนู ุงููููุงุช\n",
    "   - 4.2 ุงุณุชุฑุงุชูุฌูุงุช ุงูุชุนุงูู ูุน ูููุงุช ุงูุชููู\n",
    "   - 4.3 ุงุณุชุจุฏุงู ุงูุฃุฑูุงู ุจุฑูุฒ ุฎุงุต\n",
    "   - 4.4 ูุนุงูุฌุฉ ุงููููุงุช ุงููุงุฏุฑุฉ\n",
    "   - 4.5 ุชุณููุฉ ุทูู ุงูุฌูู\n",
    "   - 4.6 ุฅุฒุงูุฉ/ุงุณุชุจุฏุงู ุงููุตุทูุญุงุช ุงูุฃุฌูุจูุฉ\n",
    "5. [ุงูุฌุฒุก 4: ุฎุท ุฃูุงุจูุจ ุงููุนุงูุฌุฉ ุงููุงูู](#5-ุงูุฌุฒุก-4-ุฎุท-ุฃูุงุจูุจ-ุงููุนุงูุฌุฉ-ุงููุงูู)\n",
    "6. [ุงูุฌุฒุก 5: ุงููุญุต ุจุนุฏ ุงููุนุงูุฌุฉ](#6-ุงูุฌุฒุก-5-ุงููุญุต-ุจุนุฏ-ุงููุนุงูุฌุฉ)\n",
    "7. [ุงูุฌุฒุก 6: ุญูุธ ุงูุจูุงูุงุช ุงููุนุงูุฌุฉ](#7-ุงูุฌุฒุก-6-ุญูุธ-ุงูุจูุงูุงุช-ุงููุนุงูุฌุฉ)\n",
    "8. [ุงูููุฎุต ูุงูุชูุตูุงุช](#8-ุงูููุฎุต-ูุงูุชูุตูุงุช)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eae3009",
   "metadata": {},
   "source": [
    "## 1. ุงูููุฏูุฉ ูุงูุฅุนุฏุงุฏ\n",
    "\n",
    "### ๐ฏ ุงูุบุฑุถ ูู ูุฐุง ุงูุฏูุชุฑ\n",
    "\n",
    "ูููุฐ ูุฐุง ุงูุฏูุชุฑ ุฎุท ุฃูุงุจูุจ ูุนุงูุฌุฉ ูุณุจูุฉ ุดุงูู ููููู SSAC-UNPC \n",
    "ูู ูุฌููุนุฉ ุจูุงูุงุช ุงูุชุฑููู ุงูุนุฑุจู (APD). ุจูุงุกู ุนูู ูุชุงุฆุฌ ุชุญููู ุงูุจูุงูุงุช ุงูุงุณุชูุดุงูู (EDA)ุ ูุนุงูุฌ:\n",
    "\n",
    "**ุงููุดููุงุช ุงูุชู ุชู ุชุญุฏูุฏูุง ูู ุงูุชุญููู:**\n",
    "\n",
    "| ุงููุดููุฉ | ุงูุดุฏุฉ | ุงูุญู |\n",
    "|-------|----------|----------|\n",
    "| ูุฌูุฏ ุงูุชุดููู (0.27%) | ูุชูุณุทุฉ | ุฅุฒุงูุฉ ุฌููุน ุงูุญุฑูุงุช |\n",
    "| ุฎููุท ุชุฑููู ุนุฑุจู/ูุงุชููู | ุนุงููุฉ | ุงูุชูุญูุฏ ุฅูู ุงูุนุฑุจู |\n",
    "| ุฎููุท ุฃุฑูุงู ุนุฑุจูุฉ/ุบุฑุจูุฉ | ูุชูุณุทุฉ | ุงูุชูุญูุฏ ุฅูู ุงูุนุฑุจู |\n",
    "| ุฃุดูุงู ูุชุนุฏุฏุฉ ููุฃูู | ููุฎูุถุฉ | ุงูุชูุญูุฏ ุฅูู ุฃูู ูุฌุฑุฏุฉ |\n",
    "| ุญุฑูู ุฎุงุฑุฌ ุงููุทุงู | ููุฎูุถุฉ | ุฅุฒุงูุฉ ุฃู ุงุณุชุจุฏุงู |\n",
    "| ุญุฑูู ูุงุชูููุฉ ูู ุงููุต | ูุชูุณุทุฉ | ุฅุฒุงูุฉ |\n",
    "| ุฌูู ูุตูุฑุฉ ุฌุฏุงู (<3 ูููุงุช) | ูุชูุณุทุฉ | ุชุตููุฉ (ุญุฐู) |\n",
    "| ุฌูู ุทูููุฉ ุฌุฏุงู (>100 ูููุฉ) | ููุฎูุถุฉ | ูุต ุฃู ุชูุณูู |\n",
    "| ุชุฑููู ูุชุชุงุจุน | ููุฎูุถุฉ | ูุนุงูุฌุฉ ููุงุณุจุฉ |\n",
    "| ุชุฑููู ููุชุตู ุจุงููููุงุช | ูุชูุณุทุฉ | ุฅุถุงูุฉ ูุณุงูุงุช |\n",
    "\n",
    "### ๐ ุงููุชุงุฆุฌ ุงููุชููุนุฉ\n",
    "\n",
    "ุจุนุฏ ุงููุนุงูุฌุฉ:\n",
    "- ูุต ุนุฑุจู ูุธูู ููุชุณู\n",
    "- ูุธุงู ุชุฑููู ููุญุฏ (ุนุฑุจู ููุท)\n",
    "- ูุธุงู ุฃุฑูุงู ููุญุฏ (ุนุฑุจู ููุท)\n",
    "- ุฎูู ูู ุงูุชุดููู ูุงูุนูุงูุงุช ุงูุฎุงุตุฉ\n",
    "- ูุณุงูุงุช ุตุญูุญุฉ ุญูู ุนูุงูุงุช ุงูุชุฑููู\n",
    "- ุชุตููุฉ ุงูุฌูู ุงููุตูุฑุฉ/ุงูุฅุดูุงููุฉ\n",
    "- ุฌุงูุฒูุฉ ููุชุฑููุฒ (Tokenization) ูุชุฏุฑูุจ ุงููููุฐุฌ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03b95f19",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ุงููุณู 1: ุงูุงุณุชูุฑุงุฏ ูุงูุฅุนุฏุงุฏ\n",
    "# ============================================================================\n",
    "\n",
    "# -----------------------------\n",
    "# ููุชุจุงุช ุจุงูุซูู ุงูููุงุณูุฉ\n",
    "# -----------------------------\n",
    "import os                      # ูุนูููุงุช ุงููุธุงู (ุงููุณุงุฑุงุช)\n",
    "import re                      # ููุชุนุงุจูุฑ ุงูููุทูุฉ (Regex)\n",
    "import sys                     # ููุธุงุฆู ุงููุธุงู\n",
    "import json                    # ููุชุนุงูู ูุน ูููุงุช JSON\n",
    "import random                  # ููุชูููุฏ ุงูุนุดูุงุฆู\n",
    "from pathlib import Path       # ููุชุนุงูู ุงูุญุฏูุซ ูุน ุงููุณุงุฑุงุช\n",
    "from collections import Counter # ููุนุฏ ุงููุนุงู\n",
    "from typing import List, Tuple, Dict, Optional, Generator, Callable # ูุฃููุงุท ุงูุจูุงูุงุช\n",
    "from dataclasses import dataclass, field # ูุชุนุฑูู ููุงูู ุงูุจูุงูุงุช\n",
    "\n",
    "# -----------------------------\n",
    "# ููุชุจุงุช ุชุญููู ุงูุจูุงูุงุช\n",
    "# -----------------------------\n",
    "import numpy as np             # ููุนูููุงุช ุงูุญุณุงุจูุฉ\n",
    "\n",
    "# -----------------------------\n",
    "# ุดุฑูุท ุงูุชูุฏู\n",
    "# -----------------------------\n",
    "try:\n",
    "    from tqdm import tqdm      # ุดุฑูุท ุชูุฏู ููุนูููุงุช ุงูุทูููุฉ\n",
    "    TQDM_AVAILABLE = True\n",
    "except ImportError:\n",
    "    TQDM_AVAILABLE = False\n",
    "    print(\"ููุงุญุธุฉ: ููุชุจุฉ tqdm ุบูุฑ ูุซุจุชุฉ. ููุชุซุจูุช: pip install tqdm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "003d8fae",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ุงููุณู 2: ุฅุนุฏุงุฏ ุงููุณุฌู (LOGGER)\n",
    "# ============================================================================\n",
    "\n",
    "class NotebookLogger:\n",
    "    \"\"\"\n",
    "    ูุณุฌู ููุญุฏ ููุจุณุท ูุฏูุงุชุฑ ุฌูุจูุชุฑ.\n",
    "    \n",
    "    - ูุทุจุน ุงููุฎุฑุฌุงุช ูู ุงูุฏูุชุฑ\n",
    "    - ูุถูู ุงูุณุฌูุงุช ุฅูู ููู\n",
    "    - ุจุฏูู ุทูุงุจุน ุฒูููุฉ\n",
    "    - ุจุฏูู ุชุฑููุณุงุช ุงูุฌูุณุฉ\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        log_file: str | Path = \"preprocessing.log\",\n",
    "        enable_console: bool = True,\n",
    "        enable_file: bool = True,\n",
    "    ):\n",
    "        self.log_file = Path(log_file)\n",
    "        self.enable_console = enable_console\n",
    "        self.enable_file = enable_file\n",
    "\n",
    "        if self.enable_file:\n",
    "            self.log_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    def _write(self, message: str):\n",
    "        if self.enable_console:\n",
    "            print(message, end=\"\")\n",
    "\n",
    "        if self.enable_file:\n",
    "            with self.log_file.open(\"a\", encoding=\"utf-8\") as f:\n",
    "                f.write(message)\n",
    "\n",
    "    def info(self, message: str):\n",
    "        self._write(f\"{message}\\n\")\n",
    "\n",
    "    def warn(self, message: str):\n",
    "        self._write(f\"โ๏ธ  ุชุญุฐูุฑ: {message}\\n\")\n",
    "\n",
    "    def error(self, message: str):\n",
    "        self._write(f\"โ ุฎุทุฃ: {message}\\n\")\n",
    "\n",
    "    def success(self, message: str):\n",
    "        self._write(f\"โ {message}\\n\")\n",
    "\n",
    "    def section(self, title: str):\n",
    "        block = (\n",
    "            \"\\n\" + \"=\" * 70 +\n",
    "            f\"\\n{title}\\n\" +\n",
    "            \"=\" * 70 + \"\\n\"\n",
    "        )\n",
    "        self._write(block)\n",
    "\n",
    "    def subsection(self, title: str):\n",
    "        self._write(f\"\\n--- {title} ---\\n\")\n",
    "\n",
    "\n",
    "# ุชููุฆุฉ ุงููุณุฌู\n",
    "logger = NotebookLogger(log_file=\"logs/preprocessing_ar.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2587bc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "โ ุชู ุชููุฆุฉ ุงูุฅุนุฏุงุฏุงุช!\n",
      "   ูุฌูุฏ ุงููุฏุฎูุงุช: ../SSAC-UNPC\n",
      "   ูุฌูุฏ ุงููุฎุฑุฌุงุช: preprocessed_data_ar\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ุงููุณู 3: ุงูุฅุนุฏุงุฏุงุช (CONFIGURATION)\n",
    "# ============================================================================\n",
    "\n",
    "@dataclass\n",
    "class PreprocessingConfig:\n",
    "    \"\"\"\n",
    "    ุฅุนุฏุงุฏุงุช ุฎุท ุฃูุงุจูุจ ุงููุนุงูุฌุฉ ุงููุณุจูุฉ.\n",
    "    \n",
    "    ููุตู ุจูู ุฎุทูุงุช ุงููุนุงูุฌุฉ ุงูุฅูุฒุงููุฉ ูุงูุงุฎุชูุงุฑูุฉ.\n",
    "    \"\"\"\n",
    "    \n",
    "    # -----------------------------\n",
    "    # ูุณุงุฑุงุช ุงููููุงุช\n",
    "    # -----------------------------\n",
    "    input_dir: str = \"../SSAC-UNPC\"\n",
    "    output_dir: str = \"preprocessed_data_ar\"\n",
    "    log_dir: str = \"logs\"\n",
    "    \n",
    "    # -----------------------------\n",
    "    # ุงููุนุงูุฌุฉ ุงูุฅูุฒุงููุฉ (ุชุทุจู ุฏุงุฆูุงู)\n",
    "    # -----------------------------\n",
    "    remove_diacritics: bool = True       # ุฅุฒุงูุฉ ุงูุชุดููู\n",
    "    normalize_alef: bool = True          # ุชูุญูุฏ ุงูุฃูู\n",
    "    normalize_teh_marbuta: bool = True   # ุฉ (ุงุฎุชูุงุฑูุ ุงูุจุนุถ ูุญูููุง ูู ู)\n",
    "    normalize_alef_maksura: bool = True  # ู -> ู\n",
    "    remove_tatweel: bool = True          # ุฅุฒุงูุฉ ุงูุชุทููู (ู)\n",
    "    remove_latin_letters: bool = True    # ุฅุฒุงูุฉ ุงูุญุฑูู ุงููุงุชูููุฉ\n",
    "    remove_oov_chars: bool = True        # ุฅุฒุงูุฉ ุงูุญุฑูู ุฎุงุฑุฌ ุงููุทุงู\n",
    "    unify_numbers_to_arabic: bool = True # ุชูุญูุฏ ุงูุฃุฑูุงู ููุนุฑุจูุฉ\n",
    "    unify_punctuation_to_arabic: bool = True # ุชูุญูุฏ ุงูุชุฑููู ููุนุฑุจู\n",
    "    handle_consecutive_punct: bool = True # ูุนุงูุฌุฉ ุงูุชุฑููู ุงููุชุชุงุจุน\n",
    "    normalize_whitespace: bool = True    # ุชูุญูุฏ ุงููุณุงูุงุช\n",
    "    add_punct_spacing: bool = True       # ุฅุถุงูุฉ ูุณุงูุงุช ููุชุฑููู\n",
    "    \n",
    "    # -----------------------------\n",
    "    # ุชุตููุฉ ุงูุฌูู\n",
    "    # -----------------------------\n",
    "    min_words: int = 3\n",
    "    max_words: int = 100\n",
    "    remove_empty_lines: bool = True\n",
    "    \n",
    "    # -----------------------------\n",
    "    # ุงููุนุงูุฌุฉ ุงูุงุฎุชูุงุฑูุฉ (ููุชุฌุฑูุจ)\n",
    "    # -----------------------------\n",
    "    separate_waw_conjunction: bool = False   # ูุตู ูุงู ุงูุนุทู\n",
    "    remove_stopwords: bool = False           # ุฅุฒุงูุฉ ูููุงุช ุงูุชููู\n",
    "    replace_numbers_with_token: bool = False # ุงุณุชุจุฏุงู ุงูุฃุฑูุงู ุจุฑูุฒ\n",
    "    replace_rare_words: bool = False         # ุงุณุชุจุฏุงู ุงููููุงุช ุงููุงุฏุฑุฉ\n",
    "    rare_word_threshold: int = 5             # ุญุฏ ุงููููุงุช ุงููุงุฏุฑุฉ\n",
    "    remove_foreign_terms: bool = False       # ุฅุฒุงูุฉ ุงููุตุทูุญุงุช ุงูุฃุฌูุจูุฉ\n",
    "    \n",
    "    # -----------------------------\n",
    "    # ูุนุงููุงุช ุงููุนุงูุฌุฉ\n",
    "    # -----------------------------\n",
    "    sample_size: Optional[int] = None  # None = ูุนุงูุฌุฉ ุงููู\n",
    "    chunk_size: int = 100000           # ุนุฏุฏ ุงูุฃุณุทุฑ ููู ุฏูุนุฉ (ููููุงุกุฉ)\n",
    "    random_seed: int = 42\n",
    "\n",
    "\n",
    "# ุชููุฆุฉ ุงูุฅุนุฏุงุฏุงุช\n",
    "config = PreprocessingConfig()\n",
    "\n",
    "# ุฅูุดุงุก ูุฌูุฏุงุช ุงููุฎุฑุฌุงุช\n",
    "os.makedirs(config.output_dir, exist_ok=True)\n",
    "os.makedirs(config.log_dir, exist_ok=True)\n",
    "\n",
    "logger.info(\"โ ุชู ุชููุฆุฉ ุงูุฅุนุฏุงุฏุงุช!\")\n",
    "logger.info(f\"   ูุฌูุฏ ุงููุฏุฎูุงุช: {config.input_dir}\")\n",
    "logger.info(f\"   ูุฌูุฏ ุงููุฎุฑุฌุงุช: {config.output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "492c2f1a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "โ ุชู ุชุญููู ุชุนุฑููุงุช ุงูุญุฑูู ุงูุนุฑุจูุฉ!\n",
      "   - ุงูุญุฑูู ุงูุนุฑุจูุฉ: 36\n",
      "   - ุงูุชุดููู: 8\n",
      "   - ูููุงุช ุงูุชููู: 125\n",
      "   - ุนูุงูุงุช ุงูุชุฑููู ุงูุตุงูุญุฉ: 6\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ุงููุณู 4: ุชุนุฑููุงุช ุงูุญุฑูู ุงูุนุฑุจูุฉ\n",
    "# ============================================================================\n",
    "\n",
    "# -----------------------------\n",
    "# ุงูุญุฑูู ุงูุนุฑุจูุฉ ุงูุตุงูุญุฉ\n",
    "# -----------------------------\n",
    "# ุจูุงุกู ุนูู ูุชุงุฆุฌ ุงูุชุญููู: ุฌููุน ุงูุญุฑูู ุงูุนุฑุจูุฉ ุงูููุฌูุฏุฉ ูู ูุฌููุนุฉ ุงูุจูุงูุงุช\n",
    "\n",
    "ARABIC_LETTERS = set(\n",
    "    'ุก ุข ุฃ ุค ุฅ ุฆ ุง ุจ ุฉ ุช ุซ ุฌ ุญ ุฎ ุฏ ุฐ ุฑ ุฒ ุณ ุด ุต ุถ ุท ุธ ุน ุบ ู ู ู ู ู ู ู ู ู ู'\n",
    "    .split()\n",
    ")\n",
    "\n",
    "# ูุฌููุนุฉ ููุณุนุฉ ุชุดูู ุงูุญุฑูู ุงูุฃูู ุดููุนุงู (ุชุฃุซูุฑ ูุงุฑุณู/ุฃุฑุฏู ูู ุงูุฃุณูุงุก)\n",
    "ARABIC_LETTERS_EXTENDED = ARABIC_LETTERS | set('ูพ ฺ ฺ ฺฏ ฺค')\n",
    "\n",
    "# -----------------------------\n",
    "# ุงูุชุดููู ุงูุนุฑุจู (ุงูุญุฑูุงุช)\n",
    "# -----------------------------\n",
    "ARABIC_DIACRITICS = {\n",
    "    '\\u064B': 'ูุชุญุชุงู',     # ู\n",
    "    '\\u064C': 'ุถูุชุงู',      # ู\n",
    "    '\\u064D': 'ูุณุฑุชุงู',     # ู\n",
    "    '\\u064E': 'ูุชุญุฉ',       # ู\n",
    "    '\\u064F': 'ุถูุฉ',        # ู\n",
    "    '\\u0650': 'ูุณุฑุฉ',       # ู\n",
    "    '\\u0651': 'ุดุฏุฉ',        # ู\n",
    "    '\\u0652': 'ุณููู',       # ู\n",
    "}\n",
    "\n",
    "DIACRITICS_PATTERN = re.compile(r'[\\u064B-\\u0652]')\n",
    "\n",
    "# -----------------------------\n",
    "# ุงูุฃุฑูุงู ุงูุนุฑุจูุฉ\n",
    "# -----------------------------\n",
    "ARABIC_NUMERALS = 'ููกูขูฃูคูฅูฆูงูจูฉ'\n",
    "WESTERN_NUMERALS = '0123456789'\n",
    "\n",
    "# ุฌุฏุงูู ุงูุชุญููู\n",
    "WESTERN_TO_ARABIC_NUMS = str.maketrans(WESTERN_NUMERALS, ARABIC_NUMERALS)\n",
    "ARABIC_TO_WESTERN_NUMS = str.maketrans(ARABIC_NUMERALS, WESTERN_NUMERALS)\n",
    "\n",
    "# -----------------------------\n",
    "# ุนูุงูุงุช ุงูุชุฑููู\n",
    "# -----------------------------\n",
    "# ุงูุชุฑููู ุงููุณุชูุฏู (ุงูุนุฑุจู)\n",
    "ARABIC_PUNCTUATION = {\n",
    "    'ุ': 'ูุงุตูุฉ ุนุฑุจูุฉ',\n",
    "    'ุ': 'ูุงุตูุฉ ููููุทุฉ ุนุฑุจูุฉ',\n",
    "    'ุ': 'ุนูุงูุฉ ุงุณุชููุงู ุนุฑุจูุฉ',\n",
    "    '.': 'ููุทุฉ',\n",
    "    ':': 'ููุทุชุงู ุฑุฃุณูุชุงู',\n",
    "    '!': 'ุนูุงูุฉ ุชุนุฌุจ',\n",
    "}\n",
    "\n",
    "# ุงููุนุงุฏูุงุช ุงููุงุชูููุฉ ููุชูุญูุฏ\n",
    "LATIN_TO_ARABIC_PUNCT = {\n",
    "    ',': 'ุ',   # ูุงุตูุฉ ูุงุชูููุฉ -> ุนุฑุจูุฉ\n",
    "    ';': 'ุ',   # ูุงุตูุฉ ููููุทุฉ ูุงุชูููุฉ -> ุนุฑุจูุฉ\n",
    "    '?': 'ุ',   # ุนูุงูุฉ ุงุณุชููุงู ูุงุชูููุฉ -> ุนุฑุจูุฉ\n",
    "}\n",
    "\n",
    "# ุฌููุน ุนูุงูุงุช ุงูุชุฑููู ุงูุตุงูุญุฉ (ุจุนุฏ ุงูุชูุญูุฏ)\n",
    "VALID_PUNCTUATION = set(ARABIC_PUNCTUATION.keys())\n",
    "\n",
    "# ุนูุงูุงุช ููุงูุฉ ุงูุฌููุฉ\n",
    "SENTENCE_TERMINALS = {'.', 'ุ', '!'}\n",
    "\n",
    "# -----------------------------\n",
    "# ุฃุดูุงู ุงูุฃูู\n",
    "# -----------------------------\n",
    "ALEF_VARIATIONS = {\n",
    "    'ุฃ': 'ุง',  # ุฃูู ููุฒุฉ ููู\n",
    "    'ุฅ': 'ุง',  # ุฃูู ููุฒุฉ ุชุญุช\n",
    "    'ุข': 'ุง',  # ุฃูู ูุฏุฉ\n",
    "    'ูฑ': 'ุง',  # ุฃูู ูุตู\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# ูููุงุช ุงูุชููู ุงูุนุฑุจูุฉ\n",
    "# -----------------------------\n",
    "ARABIC_STOPWORDS = set([\n",
    "    # ุญุฑูู ุงูุฌุฑ\n",
    "    'ูู', 'ูู', 'ุนูู', 'ุฅูู', 'ุงูู', 'ุนู', 'ูุน', 'ุจูู', 'ุนูุฏ', 'ุญุชู', 'ููุฐ',\n",
    "    'ุงูู', 'ูู', 'ุนูู',\n",
    "    # ุฃุณูุงุก ุงูุฅุดุงุฑุฉ\n",
    "    'ูุฐุง', 'ูุฐู', 'ุฐูู', 'ุชูู', 'ูุคูุงุก', 'ุฃููุฆู',\n",
    "    # ุงูุฃุณูุงุก ุงูููุตููุฉ\n",
    "    'ุงูุชู', 'ุงูุฐู', 'ุงููุฐุงู', 'ุงููุชุงู', 'ุงูุฐูู', 'ุงููุงุชู', 'ุงูููุงุชู',\n",
    "    # ุฃุฏูุงุช ุงูุนุทู\n",
    "    'ู', 'ุฃู', 'ุงู', 'ุซู', 'ููู', 'ุจู', 'ุฅุฐุง', 'ูู', 'ุฅุฐ', 'ู',\n",
    "    # ุฃุฏูุงุช ุฃุฎุฑู\n",
    "    'ุฃู', 'ุงู', 'ุฅู', 'ูุฏ', 'ูุง', 'ูุง', 'ูู', 'ูู', 'ู', 'ุจ', 'ู',\n",
    "    # ุงูุถูุงุฆุฑ\n",
    "    'ูู', 'ูู', 'ูู', 'ูู', 'ุฃูุง', 'ูุญู', 'ุฃูุช', 'ุฃูุชู', 'ุงูุง', 'ุงูุช',\n",
    "    # ุงูุฃูุนุงู ุงููุณุงุนุฏุฉ\n",
    "    'ูุงู', 'ูุงูุช', 'ูููู', 'ุชููู', 'ูุงููุง', 'ููุณ', 'ููุณุช',\n",
    "    # ุฃุฎุฑู\n",
    "    'ูู', 'ุจุนุถ', 'ุฃู', 'ุงู', 'ุบูุฑ', 'ุจุนุฏ', 'ูุจู', 'ุญูุซ', 'ุนูุฏูุง',\n",
    "    'ุญูู', 'ุฏูู', 'ุถุฏ', 'ุฎูุงู', 'ุนุจุฑ', 'ูุญู', 'ููู', 'ุชุญุช',\n",
    "    # ูููุงุช ูุธูููุฉ ุดุงุฆุนุฉ\n",
    "    'ููู', 'ููู', 'ูุนูู', 'ูุงูู', 'ููุน', 'ููู', 'ููู', 'ููุฐุง', 'ููุฐู',\n",
    "    'ูุฅู', 'ูุงู', 'ูุฅู', 'ูุงู', 'ูุฃู', 'ูุงู', 'ููุง', 'ููุง', 'ุฅูู', 'ุงูู',\n",
    "    'ุฅููุง', 'ุงููุง', 'ุฃูู', 'ุฃููุง', 'ุฐุงุช', 'ููุง', 'ูู', 'ููู', 'ุจูุง', 'ุจู',\n",
    "    'ูููุง', 'ููู', 'ูููุง', 'ููู', 'ุนููุง', 'ุนูู', 'ุฅูููุง', 'ุฅููู',\n",
    "    'ุนูููุง', 'ุนููู', 'ูุนูุง', 'ูุนู', 'ุจูููุง', 'ุจูููู',\n",
    "])\n",
    "\n",
    "# -----------------------------\n",
    "# ุฃููุงุท ูุงู ุงูุนุทู\n",
    "# -----------------------------\n",
    "# ุงูุญุฏ ุงูุฃุฏูู ูุทูู ุงููููุฉ ููุตู ุงููุงู\n",
    "WAW_CONJUNCTION_MIN_LENGTH = 3  # ุงูุตู ููุท ุฅุฐุง ุชุจูู 3 ุญุฑูู ุฃู ุฃูุซุฑ\n",
    "\n",
    "logger.info(\"โ ุชู ุชุญููู ุชุนุฑููุงุช ุงูุญุฑูู ุงูุนุฑุจูุฉ!\")\n",
    "logger.info(f\"   - ุงูุญุฑูู ุงูุนุฑุจูุฉ: {len(ARABIC_LETTERS)}\")\n",
    "logger.info(f\"   - ุงูุชุดููู: {len(ARABIC_DIACRITICS)}\")\n",
    "logger.info(f\"   - ูููุงุช ุงูุชููู: {len(ARABIC_STOPWORDS)}\")\n",
    "logger.info(f\"   - ุนูุงูุงุช ุงูุชุฑููู ุงูุตุงูุญุฉ: {len(VALID_PUNCTUATION)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9c4c515",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "โ ุฃุฏูุงุช ุชุญููู ุงูุจูุงูุงุช ุฌุงูุฒุฉ!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ุงููุณู 5: ุฃุฏูุงุช ุชุญููู ุงูุจูุงูุงุช\n",
    "# ============================================================================\n",
    "\n",
    "def iter_dataset_lines(dataset_dir: str, encoding: str = \"utf-8\") -> Generator[str, None, None]:\n",
    "    \"\"\"\n",
    "    ุชูุฑุงุฑ (Iterate) ุนูู ุฌููุน ูููุงุช ูุฌููุนุฉ ุงูุจูุงูุงุช ูุชุฏูู ุฃุณุทุฑ ูุงุญุฏ.\n",
    "    \n",
    "    ุชุทุจู ูุฐู ุงูุฏุงูุฉ ุงูุชุญููู ุงููุณูู (Lazy Loading) ููุชุนุงูู ูุน ุงูุจูุงูุงุช ุงููุจูุฑุฉ\n",
    "    ุงูุชู ูุง ูููู ุชุญููููุง ูู ุงูุฐุงูุฑุฉ ุฏูุนุฉ ูุงุญุฏุฉ.\n",
    "    \n",
    "    ุงููุนุงููุงุช:\n",
    "    -----------\n",
    "    dataset_dir : str\n",
    "        ูุณุงุฑ ุงููุฌูุฏ ุงููุญุชูู ุนูู ูููุงุช .txt\n",
    "    encoding : str\n",
    "        ุชุฑููุฒ ุงูููู (ุงูุงูุชุฑุงุถู: utf-8)\n",
    "        \n",
    "    ุชูุชุฌ (Yields):\n",
    "    -------\n",
    "    str\n",
    "        ุฌููุฉ/ุณุทุฑ ูุงุญุฏ ูู ูู ูุฑุฉ (ุจุฏูู ูุญุฑู ุงูุณุทุฑ ุงูุฌุฏูุฏ)\n",
    "    \"\"\"\n",
    "    # ุงูุญุตูู ุนูู ุฌููุน ูููุงุช ุงููุตูุต ูุฑุชุจุฉ\n",
    "    txt_files = sorted(Path(dataset_dir).glob(\"*.txt\"))\n",
    "    \n",
    "    if not txt_files:\n",
    "        logger.error(f\"ูู ูุชู ุงูุนุซูุฑ ุนูู ูููุงุช .txt ูู {dataset_dir}\")\n",
    "        return\n",
    "    \n",
    "    for file_path in txt_files:\n",
    "        try:\n",
    "            with open(file_path, \"r\", encoding=encoding) as f:\n",
    "                for line in f:\n",
    "                    yield line.rstrip(\"\\n\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"ุฎุทุฃ ูู ูุฑุงุกุฉ {file_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "\n",
    "def count_total_lines(dataset_dir: str) -> int:\n",
    "    \"\"\"\n",
    "    ุนุฏ ุฅุฌูุงูู ุงูุฃุณุทุฑ ูู ูุฌููุนุฉ ุงูุจูุงูุงุช (ูุดุฑูุท ุงูุชูุฏู).\n",
    "    \n",
    "    ุงููุนุงููุงุช:\n",
    "    -----------\n",
    "    dataset_dir : str\n",
    "        ูุณุงุฑ ูุฌูุฏ ุงูุจูุงูุงุช\n",
    "        \n",
    "    ุชุฑุฌุน:\n",
    "    --------\n",
    "    int\n",
    "        ุฅุฌูุงูู ุนุฏุฏ ุงูุฃุณุทุฑ\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    for file_path in sorted(Path(dataset_dir).glob(\"*.txt\")):\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            total += sum(1 for _ in f)\n",
    "    return total\n",
    "\n",
    "\n",
    "def get_sample_lines(dataset_dir: str, n: int = 1000, seed: int = 42) -> List[str]:\n",
    "    \"\"\"\n",
    "    ุงูุญุตูู ุนูู ุนููุฉ ุนุดูุงุฆูุฉ ูู ุงูุฃุณุทุฑ ูููุญุต.\n",
    "    \n",
    "    ุงููุนุงููุงุช:\n",
    "    -----------\n",
    "    dataset_dir : str\n",
    "        ูุณุงุฑ ูุฌูุฏ ุงูุจูุงูุงุช\n",
    "    n : int\n",
    "        ุนุฏุฏ ุงูุนููุงุช\n",
    "    seed : int\n",
    "        ุงูุจุฐุฑุฉ ุงูุนุดูุงุฆูุฉ\n",
    "        \n",
    "    ุชุฑุฌุน:\n",
    "    --------\n",
    "    List[str]\n",
    "        ูุงุฆูุฉ ุฃุณุทุฑ ุงูุนููุฉ\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # ุฌูุน ุงูุฃุณุทุฑ ูู ุงูุจุฏุงูุฉ ูุฃุฎุฐ ุงูุนููุงุช\n",
    "    lines = []\n",
    "    for i, line in enumerate(iter_dataset_lines(dataset_dir)):\n",
    "        if i >= n * 10:  # ุฌูุน ุฃูุซุฑ ูู ุงููุทููุจ ููุงุฎุชูุงุฑ ุงูุนุดูุงุฆู\n",
    "            break\n",
    "        if line.strip():\n",
    "            lines.append(line)\n",
    "    \n",
    "    return random.sample(lines, min(n, len(lines)))\n",
    "\n",
    "\n",
    "logger.info(\"โ ุฃุฏูุงุช ุชุญููู ุงูุจูุงูุงุช ุฌุงูุฒุฉ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4da85cb",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. ุงูุฌุฒุก 1: ูุญุต ุงููุดููุงุช (ูุจู ุงููุนุงูุฌุฉ)\n",
    "\n",
    "ูุจู ุชุทุจูู ุฃู ูุนุงูุฌุฉุ ูุญุชุงุฌ ูุชุญุฏูุฏ ูููุงุณ ุฌููุน ุงููุดููุงุช ูู ุงูุจูุงูุงุช ุงูุฎุงู ุจุดูู ูููุฌู.\n",
    "ูุณุงุนุฏูุง ูุฐุง ูู:\n",
    "\n",
    "1. ููู ุญุฌู ูู ูุดููุฉ\n",
    "2. ุชุฑุชูุจ ุฃููููุงุช ุฎุทูุงุช ุงููุนุงูุฌุฉ\n",
    "3. ุงูุชุญูู ูู ุฃู ุงููุนุงูุฌุฉ ุฃุตูุญุช ุงููุดููุงุช"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38c8cf9",
   "metadata": {},
   "source": [
    "### 2.1 ูุดููุงุช ูุณุชูู ุงูุญุฑูู"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e960b785",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "๐ ูุญุต ูุดููุงุช ูุณุชูู ุงูุญุฑูู\n",
      "======================================================================\n",
      "ุฌุงุฑู ูุญุต 500,000 ุณุทุฑ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ูุญุต ุงูุญุฑูู: 100%|โโโโโโโโโโ| 500000/500000 [00:28<00:00, 17570.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ุงูุชุดููู (ุงูุญุฑูุงุช) ---\n",
      "ุฅุฌูุงูู ุงูุชุดููู ุงูููุฌูุฏ: 48,041\n",
      "ุฃุณุทุฑ ุชุญุชูู ุนูู ุชุดููู: 33,658 (6.73%)\n",
      "ุชูุฒูุน ุงูุชุดููู:\n",
      "   'ู' (ูุชุญุชุงู): 24,831\n",
      "   'ู' (ุถูุฉ): 18,231\n",
      "   'ู' (ุดุฏุฉ): 2,006\n",
      "   'ู' (ูุชุญุฉ): 1,331\n",
      "   'ู' (ูุณุฑุฉ): 1,107\n",
      "   'ู' (ูุณุฑุชุงู): 339\n",
      "   'ู' (ุณููู): 186\n",
      "   'ู' (ุถูุชุงู): 10\n",
      "\n",
      "--- ุงูุญุฑูู ุงููุงุชูููุฉ ---\n",
      "ุฅุฌูุงูู ุงูุญุฑูู ุงููุงุชูููุฉ: 147,461\n",
      "ุฃุณุทุฑ ุชุญุชูู ุนูู ูุงุชููู: 40,484 (8.10%)\n",
      "ุฃูุซุฑ ุงูุญุฑูู ุงููุงุชูููุฉ:\n",
      "   'A': 28,172\n",
      "   'C': 16,057\n",
      "   'd': 14,566\n",
      "   'S': 13,273\n",
      "   'L': 6,214\n",
      "   'R': 5,070\n",
      "   'e': 4,721\n",
      "   'E': 4,309\n",
      "   'P': 4,106\n",
      "   'r': 3,879\n",
      "\n",
      "--- ุฃุดูุงู ุงูุฃูู ---\n",
      "ุฅุฌูุงูู ุฃุดูุงู ุงูุฃูู: 0\n",
      "\n",
      "--- ุงูุชุทููู (ุงููุดูุฏุฉ) ---\n",
      "ุนุฏุฏ ูุฑุงุช ุงูุชุทููู: 0\n",
      "\n",
      "--- ุญุฑูู ุฎุงุฑุฌ ุงููุทุงู (OOV) ---\n",
      "ุฅุฌูุงูู ุงูุญุฑูู ุฎุงุฑุฌ ุงููุทุงู: 178,920\n",
      "ุฃุณุทุฑ ุชุญุชูู ุนูู OOV: 96,269 (19.25%)\n",
      "ุฃูู ุงูุญุฑูู ุฎุงุฑุฌ ุงููุทุงู:\n",
      "   '/' (U+002F): 166,275\n",
      "   '๏ฑ' (U+FC60): 5,628\n",
      "   '๏ฑข' (U+FC62): 3,159\n",
      "   '`' (U+0060): 1,979\n",
      "   '๏ฑก' (U+FC61): 793\n",
      "   'โ' (U+25CF): 714\n",
      "   '+' (U+002B): 91\n",
      "   '=' (U+003D): 71\n",
      "   'รฉ' (U+00E9): 43\n",
      "   'โฆ' (U+2666): 40\n",
      "   'รค' (U+00E4): 37\n",
      "   'โ' (U+2219): 16\n",
      "   'รณ' (U+00F3): 11\n",
      "   'ูช' (U+066A): 9\n",
      "   'โข' (U+2022): 8\n",
      "   '๏ป' (U+FECB): 7\n",
      "   '\\\\' (U+005C): 7\n",
      "   'รจ' (U+00E8): 5\n",
      "   'รก' (U+00E1): 3\n",
      "   '@' (U+0040): 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ุงููุญุต 2.1: ูุดููุงุช ูุณุชูู ุงูุญุฑูู\n",
    "# ============================================================================\n",
    "\n",
    "def inspect_character_issues(dataset_dir: str, sample_size: int = 500000) -> Dict:\n",
    "    \"\"\"\n",
    "    ูุญุต ูุดููุงุช ูุณุชูู ุงูุญุฑูู ูู ูุฌููุนุฉ ุงูุจูุงูุงุช.\n",
    "    \n",
    "    ูุชุญูู ูู:\n",
    "    - ุงูุชุดููู (ุงูุญุฑูุงุช)\n",
    "    - ุงูุญุฑูู ุฎุงุฑุฌ ุงููุทุงู (OOV)\n",
    "    - ุงูุญุฑูู ุงููุงุชูููุฉ\n",
    "    - ุงูุญุฑูู ุงูุฎุงุตุฉ\n",
    "    - ุฃุดูุงู ุงูุฃูู\n",
    "    - ุงูุชุทููู (ู)\n",
    "    \n",
    "    ุงููุนุงููุงุช:\n",
    "    -----------\n",
    "    dataset_dir : str\n",
    "        ูุณุงุฑ ูุฌูุฏ ุงูุจูุงูุงุช\n",
    "    sample_size : int\n",
    "        ุนุฏุฏ ุงูุฃุณุทุฑ ูููุญุต\n",
    "        \n",
    "    ุชุฑุฌุน:\n",
    "    --------\n",
    "    Dict\n",
    "        ูุงููุณ ูุญุชูู ุนูู ุฅุญุตุงุฆูุงุช ุงููุดููุงุช\n",
    "    \"\"\"\n",
    "    logger.section(\"๐ ูุญุต ูุดููุงุช ูุณุชูู ุงูุญุฑูู\")\n",
    "    logger.info(f\"ุฌุงุฑู ูุญุต {sample_size:,} ุณุทุฑ...\")\n",
    "    \n",
    "    # ุชููุฆุฉ ุงูุนุฏุงุฏุงุช\n",
    "    stats = {\n",
    "        'total_chars': 0,\n",
    "        'total_lines': 0,\n",
    "        'diacritics': Counter(),\n",
    "        'latin_letters': Counter(),\n",
    "        'oov_chars': Counter(),\n",
    "        'alef_variations': Counter(),\n",
    "        'tatweel_count': 0,\n",
    "        'lines_with_diacritics': 0,\n",
    "        'lines_with_latin': 0,\n",
    "        'lines_with_oov': 0,\n",
    "    }\n",
    "    \n",
    "    # ุชุนุฑูู ูุฌููุนุฉ ุงูุญุฑูู ุงูุตุงูุญุฉ\n",
    "    valid_chars = set()\n",
    "    valid_chars.update(ARABIC_LETTERS_EXTENDED)\n",
    "    valid_chars.update(ARABIC_NUMERALS)\n",
    "    valid_chars.update(WESTERN_NUMERALS)\n",
    "    valid_chars.update(VALID_PUNCTUATION)\n",
    "    valid_chars.update(LATIN_TO_ARABIC_PUNCT.keys())\n",
    "    valid_chars.update(' \\t\\n')  # ุงููุณุงูุงุช\n",
    "    valid_chars.update('()[]{}ยซยป\"\"\\'-โโ')  # ุงูุฃููุงุณ ูุนูุงูุงุช ุงูุชูุตูุต\n",
    "    valid_chars.update(ARABIC_DIACRITICS.keys())  # ุงูุชุดููู (ููุนุฏ)\n",
    "    \n",
    "    # ููุท ุงูุญุฑูู ุงููุงุชูููุฉ\n",
    "    latin_pattern = re.compile(r'[A-Za-z]')\n",
    "    \n",
    "    # ุฅูุดุงุก ุงูููุฑุฑ (Iterator)\n",
    "    iterator = iter_dataset_lines(dataset_dir)\n",
    "    if TQDM_AVAILABLE:\n",
    "        iterator = tqdm(iterator, total=sample_size, desc=\"ูุญุต ุงูุญุฑูู\")\n",
    "    \n",
    "    for i, line in enumerate(iterator):\n",
    "        if i >= sample_size:\n",
    "            break\n",
    "        \n",
    "        stats['total_lines'] += 1\n",
    "        stats['total_chars'] += len(line)\n",
    "        \n",
    "        has_diacritics = False\n",
    "        has_latin = False\n",
    "        has_oov = False\n",
    "        \n",
    "        for char in line:\n",
    "            # ุงูุชุญูู ูู ุงูุชุดููู\n",
    "            if char in ARABIC_DIACRITICS:\n",
    "                stats['diacritics'][char] += 1\n",
    "                has_diacritics = True\n",
    "            \n",
    "            # ุงูุชุญูู ูู ุงูุญุฑูู ุงููุงุชูููุฉ\n",
    "            if latin_pattern.match(char):\n",
    "                stats['latin_letters'][char] += 1\n",
    "                has_latin = True\n",
    "            \n",
    "            # ุงูุชุญูู ูู ุฃุดูุงู ุงูุฃูู\n",
    "            if char in ALEF_VARIATIONS:\n",
    "                stats['alef_variations'][char] += 1\n",
    "            \n",
    "            # ุงูุชุญูู ูู ุงูุชุทููู\n",
    "            if char == '\\u0640':\n",
    "                stats['tatweel_count'] += 1\n",
    "            \n",
    "            # ุงูุชุญูู ูู ุงูุญุฑูู ุฎุงุฑุฌ ุงููุทุงู\n",
    "            if char not in valid_chars and not latin_pattern.match(char):\n",
    "                stats['oov_chars'][char] += 1\n",
    "                has_oov = True\n",
    "        \n",
    "        if has_diacritics:\n",
    "            stats['lines_with_diacritics'] += 1\n",
    "        if has_latin:\n",
    "            stats['lines_with_latin'] += 1\n",
    "        if has_oov:\n",
    "            stats['lines_with_oov'] += 1\n",
    "    \n",
    "    # ุนุฑุถ ุงููุชุงุฆุฌ\n",
    "    logger.subsection(\"ุงูุชุดููู (ุงูุญุฑูุงุช)\")\n",
    "    total_diacritics = sum(stats['diacritics'].values())\n",
    "    logger.info(f\"ุฅุฌูุงูู ุงูุชุดููู ุงูููุฌูุฏ: {total_diacritics:,}\")\n",
    "    logger.info(f\"ุฃุณุทุฑ ุชุญุชูู ุนูู ุชุดููู: {stats['lines_with_diacritics']:,} ({stats['lines_with_diacritics']/stats['total_lines']*100:.2f}%)\")\n",
    "    \n",
    "    if stats['diacritics']:\n",
    "        logger.info(\"ุชูุฒูุน ุงูุชุดููู:\")\n",
    "        for char, count in stats['diacritics'].most_common():\n",
    "            name = ARABIC_DIACRITICS.get(char, 'ุบูุฑ ูุนุฑูู')\n",
    "            logger.info(f\"   {repr(char)} ({name}): {count:,}\")\n",
    "    \n",
    "    logger.subsection(\"ุงูุญุฑูู ุงููุงุชูููุฉ\")\n",
    "    total_latin = sum(stats['latin_letters'].values())\n",
    "    logger.info(f\"ุฅุฌูุงูู ุงูุญุฑูู ุงููุงุชูููุฉ: {total_latin:,}\")\n",
    "    logger.info(f\"ุฃุณุทุฑ ุชุญุชูู ุนูู ูุงุชููู: {stats['lines_with_latin']:,} ({stats['lines_with_latin']/stats['total_lines']*100:.2f}%)\")\n",
    "    \n",
    "    if stats['latin_letters']:\n",
    "        logger.info(\"ุฃูุซุฑ ุงูุญุฑูู ุงููุงุชูููุฉ:\")\n",
    "        for char, count in stats['latin_letters'].most_common(10):\n",
    "            logger.info(f\"   '{char}': {count:,}\")\n",
    "    \n",
    "    logger.subsection(\"ุฃุดูุงู ุงูุฃูู\")\n",
    "    total_alef_var = sum(stats['alef_variations'].values())\n",
    "    logger.info(f\"ุฅุฌูุงูู ุฃุดูุงู ุงูุฃูู: {total_alef_var:,}\")\n",
    "    \n",
    "    if stats['alef_variations']:\n",
    "        for char, count in stats['alef_variations'].most_common():\n",
    "            logger.info(f\"   '{char}': {count:,}\")\n",
    "    \n",
    "    logger.subsection(\"ุงูุชุทููู (ุงููุดูุฏุฉ)\")\n",
    "    logger.info(f\"ุนุฏุฏ ูุฑุงุช ุงูุชุทููู: {stats['tatweel_count']:,}\")\n",
    "    \n",
    "    logger.subsection(\"ุญุฑูู ุฎุงุฑุฌ ุงููุทุงู (OOV)\")\n",
    "    total_oov = sum(stats['oov_chars'].values())\n",
    "    logger.info(f\"ุฅุฌูุงูู ุงูุญุฑูู ุฎุงุฑุฌ ุงููุทุงู: {total_oov:,}\")\n",
    "    logger.info(f\"ุฃุณุทุฑ ุชุญุชูู ุนูู OOV: {stats['lines_with_oov']:,} ({stats['lines_with_oov']/stats['total_lines']*100:.2f}%)\")\n",
    "    \n",
    "    if stats['oov_chars']:\n",
    "        logger.info(\"ุฃูู ุงูุญุฑูู ุฎุงุฑุฌ ุงููุทุงู:\")\n",
    "        for char, count in stats['oov_chars'].most_common(20):\n",
    "            try:\n",
    "                char_name = f\"U+{ord(char):04X}\"\n",
    "            except:\n",
    "                char_name = \"Unknown\"\n",
    "            logger.info(f\"   {repr(char)} ({char_name}): {count:,}\")\n",
    "    \n",
    "    return stats\n",
    "\n",
    "\n",
    "# ุชุดุบูู ูุญุต ุงูุญุฑูู\n",
    "char_issues = inspect_character_issues(config.input_dir, sample_size=500000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c678cf64",
   "metadata": {},
   "source": [
    "### 2.2 ูุดููุงุช ุนูุงูุงุช ุงูุชุฑููู"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2acf61e5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "๐ ูุญุต ูุดููุงุช ุงูุชุฑููู\n",
      "======================================================================\n",
      "ุฌุงุฑู ูุญุต 500,000 ุณุทุฑ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ูุญุต ุงูุชุฑููู: 100%|โโโโโโโโโโ| 500000/500000 [00:13<00:00, 36974.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ุงูุชุฑููู ุงูุนุฑุจู ---\n",
      "   'ุ' (ูุงุตูุฉ ุนุฑุจูุฉ): 631,288\n",
      "   '.' (ููุทุฉ): 498,701\n",
      "   'ุ' (ูุงุตูุฉ ููููุทุฉ ุนุฑุจูุฉ): 59,512\n",
      "   ':' (ููุทุชุงู ุฑุฃุณูุชุงู): 26,744\n",
      "   'ุ' (ุนูุงูุฉ ุงุณุชููุงู ุนุฑุจูุฉ): 2,609\n",
      "   '!' (ุนูุงูุฉ ุชุนุฌุจ): 59\n",
      "\n",
      "--- ุงูุชุฑููู ุงููุงุชููู (ูุญุชุงุฌ ุชูุญูุฏ) ---\n",
      "   ',': 9,133 -> ูุฌุจ ุฃู ูุตุจุญ 'ุ'\n",
      "   ';': 36 -> ูุฌุจ ุฃู ูุตุจุญ 'ุ'\n",
      "   '?': 1 -> ูุฌุจ ุฃู ูุตุจุญ 'ุ'\n",
      "\n",
      "--- ุฃุณุทุฑ ุจุชุฑููู ูุฎุชูุท ---\n",
      "ุฃุณุทุฑ ุชุญูู ุฎููุทุงู ูู ุงูุชุฑููู ุงูุนุฑุจู ูุงููุงุชููู: 6,494\n",
      "ุงููุณุจุฉ: 1.30%\n",
      "\n",
      "--- ุงูุชุฑููู ุงููุชุชุงุจุน ---\n",
      "ุฅุฌูุงูู ุงูุญุงูุงุช: 64\n",
      "ุฃูุซูุฉ:\n",
      "   ',ุ' ูู: )ูกูฆูจ( ุงููุฑุงุฑ ูกูคูคูค )ุฏ - ูฅูฅ(ุ ุงูุฏูุฑุฉ ุงูุนุงุฏูุฉ ุงูุชุงุณุนุฉ ูุงูุนุดุฑูู ...\n",
      "   ':.' ูู: ุงูุณูุฉ ุงููุงููุฉ:....\n",
      "   'ุ:' ูู: 8(ุ ุงููุฌูุฏ ุงูุงููุ: ุงููุฑุงุฑุงุช ุงูุชู ุงุนุชูุฏูุง ุงููุคุชูุฑุ ุงููุฑุงุฑ ุงูุง...\n",
      "   '?,' ูู: , Latin American adjustment: how much has happened?, Institu...\n",
      "   'ุุ' ูู: ููุฒุงูุง ุงููุงูุฑูุฒูุฉ ูุนุฑููุฉ: ุนุฏู ุงุฑูุงู ูุจุงุฑ ุงููุฏูุฑูู ุจุงููุณุคูููุง...\n",
      "\n",
      "--- ุงูุชุฑููู ุงูููุชุตู ---\n",
      "ุญุงูุงุช ููุชูุฏ ูููุง ุงูุชุฑููู ููุณุงูุงุช ููุงุณุจุฉ: 13,935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ุงููุญุต 2.2: ูุดููุงุช ุนูุงูุงุช ุงูุชุฑููู\n",
    "# ============================================================================\n",
    "\n",
    "def inspect_punctuation_issues(dataset_dir: str, sample_size: int = 500000) -> Dict:\n",
    "    \"\"\"\n",
    "    ูุญุต ุงููุดููุงุช ุงููุชุนููุฉ ุจุนูุงูุงุช ุงูุชุฑููู.\n",
    "    \n",
    "    ูุชุญูู ูู:\n",
    "    - ุฎููุท ุงูุชุฑููู ุงูุนุฑุจู/ุงููุงุชููู\n",
    "    - ุงูุชุฑููู ุงููุชุชุงุจุน (ูุซู ุุุ ุฃู ..)\n",
    "    - ููุต ุงููุณุงูุงุช ุญูู ุงูุชุฑููู\n",
    "    - ุนูุงูุงุช ุชุฑููู ุบูุฑ ุตุงูุญุฉ\n",
    "    \n",
    "    ุงููุนุงููุงุช:\n",
    "    -----------\n",
    "    dataset_dir : str\n",
    "        ูุณุงุฑ ูุฌูุฏ ุงูุจูุงูุงุช\n",
    "    sample_size : int\n",
    "        ุนุฏุฏ ุงูุฃุณุทุฑ ูููุญุต\n",
    "        \n",
    "    ุชุฑุฌุน:\n",
    "    --------\n",
    "    Dict\n",
    "        ูุงููุณ ูุญุชูู ุนูู ุฅุญุตุงุฆูุงุช ุงููุดููุงุช\n",
    "    \"\"\"\n",
    "    logger.section(\"๐ ูุญุต ูุดููุงุช ุงูุชุฑููู\")\n",
    "    logger.info(f\"ุฌุงุฑู ูุญุต {sample_size:,} ุณุทุฑ...\")\n",
    "    \n",
    "    stats = {\n",
    "        'total_lines': 0,\n",
    "        'arabic_punct': Counter(),\n",
    "        'latin_punct': Counter(),\n",
    "        'other_punct': Counter(),\n",
    "        'consecutive_punct': [],  # ูุชุฎุฒูู ุฃูุซูุฉ\n",
    "        'consecutive_punct_count': 0,\n",
    "        'attached_punct_count': 0,\n",
    "        'lines_with_mixed_punct': 0,\n",
    "    }\n",
    "    \n",
    "    # ุฌููุน ุนูุงูุงุช ุงูุชุฑููู ูููุดู\n",
    "    all_punct = set(ARABIC_PUNCTUATION.keys()) | set(LATIN_TO_ARABIC_PUNCT.keys())\n",
    "    \n",
    "    # ููุท ุงูุชุฑููู ุงููุชุชุงุจุน\n",
    "    consecutive_pattern = re.compile(r'[ุุุ.,:;?!]{2,}')\n",
    "    \n",
    "    # ููุท ุงูุชุฑููู ุงูููุชุตู (ุจุฏูู ูุณุงูุฉ ูุจูู/ุจุนุฏู)\n",
    "    # ูููุฉ ุนุฑุจูุฉ ูุชุจูุนุฉ ูุจุงุดุฑุฉ ุจุชุฑููู ุจุฏูู ูุณุงูุฉ\n",
    "    attached_pattern = re.compile(r'[\\u0600-\\u06FF][ุุุ.:!][\\u0600-\\u06FF]')\n",
    "    \n",
    "    iterator = iter_dataset_lines(dataset_dir)\n",
    "    if TQDM_AVAILABLE:\n",
    "        iterator = tqdm(iterator, total=sample_size, desc=\"ูุญุต ุงูุชุฑููู\")\n",
    "    \n",
    "    for i, line in enumerate(iterator):\n",
    "        if i >= sample_size:\n",
    "            break\n",
    "        \n",
    "        stats['total_lines'] += 1\n",
    "        \n",
    "        has_arabic_punct = False\n",
    "        has_latin_punct = False\n",
    "        \n",
    "        # ุนุฏ ุฃููุงุน ุงูุชุฑููู\n",
    "        for char in line:\n",
    "            if char in ARABIC_PUNCTUATION:\n",
    "                stats['arabic_punct'][char] += 1\n",
    "                has_arabic_punct = True\n",
    "            elif char in LATIN_TO_ARABIC_PUNCT:\n",
    "                stats['latin_punct'][char] += 1\n",
    "                has_latin_punct = True\n",
    "            elif char in '()[]{}ยซยป\"\"\\'':\n",
    "                stats['other_punct'][char] += 1\n",
    "        \n",
    "        # ุงูุชุญูู ูู ุงูุชุฑููู ุงููุฎุชูุท\n",
    "        if has_arabic_punct and has_latin_punct:\n",
    "            stats['lines_with_mixed_punct'] += 1\n",
    "        \n",
    "        # ุงูุชุญูู ูู ุงูุชุฑููู ุงููุชุชุงุจุน\n",
    "        consecutive_matches = consecutive_pattern.findall(line)\n",
    "        if consecutive_matches:\n",
    "            stats['consecutive_punct_count'] += len(consecutive_matches)\n",
    "            if len(stats['consecutive_punct']) < 20:  # ุชุฎุฒูู ุฃูุซูุฉ\n",
    "                for match in consecutive_matches:\n",
    "                    stats['consecutive_punct'].append((match, line[:100]))\n",
    "        \n",
    "        # ุงูุชุญูู ูู ุงูุชุฑููู ุงูููุชุตู\n",
    "        attached_matches = attached_pattern.findall(line)\n",
    "        if attached_matches:\n",
    "            stats['attached_punct_count'] += len(attached_matches)\n",
    "    \n",
    "    # ุนุฑุถ ุงููุชุงุฆุฌ\n",
    "    logger.subsection(\"ุงูุชุฑููู ุงูุนุฑุจู\")\n",
    "    for char, count in stats['arabic_punct'].most_common():\n",
    "        name = ARABIC_PUNCTUATION.get(char, 'ุบูุฑ ูุนุฑูู')\n",
    "        logger.info(f\"   '{char}' ({name}): {count:,}\")\n",
    "    \n",
    "    logger.subsection(\"ุงูุชุฑููู ุงููุงุชููู (ูุญุชุงุฌ ุชูุญูุฏ)\")\n",
    "    for char, count in stats['latin_punct'].most_common():\n",
    "        logger.info(f\"   '{char}': {count:,} -> ูุฌุจ ุฃู ูุตุจุญ '{LATIN_TO_ARABIC_PUNCT.get(char, char)}'\")\n",
    "    \n",
    "    logger.subsection(\"ุฃุณุทุฑ ุจุชุฑููู ูุฎุชูุท\")\n",
    "    logger.info(f\"ุฃุณุทุฑ ุชุญูู ุฎููุทุงู ูู ุงูุชุฑููู ุงูุนุฑุจู ูุงููุงุชููู: {stats['lines_with_mixed_punct']:,}\")\n",
    "    logger.info(f\"ุงููุณุจุฉ: {stats['lines_with_mixed_punct']/stats['total_lines']*100:.2f}%\")\n",
    "    \n",
    "    logger.subsection(\"ุงูุชุฑููู ุงููุชุชุงุจุน\")\n",
    "    logger.info(f\"ุฅุฌูุงูู ุงูุญุงูุงุช: {stats['consecutive_punct_count']:,}\")\n",
    "    if stats['consecutive_punct']:\n",
    "        logger.info(\"ุฃูุซูุฉ:\")\n",
    "        for match, context in stats['consecutive_punct'][:5]:\n",
    "            logger.info(f\"   '{match}' ูู: {context[:60]}...\")\n",
    "    \n",
    "    logger.subsection(\"ุงูุชุฑููู ุงูููุชุตู\")\n",
    "    logger.info(f\"ุญุงูุงุช ููุชูุฏ ูููุง ุงูุชุฑููู ููุณุงูุงุช ููุงุณุจุฉ: {stats['attached_punct_count']:,}\")\n",
    "    \n",
    "    return stats\n",
    "\n",
    "\n",
    "# ุชุดุบูู ูุญุต ุงูุชุฑููู\n",
    "punct_issues = inspect_punctuation_issues(config.input_dir, sample_size=500000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9f7d62",
   "metadata": {},
   "source": [
    "### 2.3 ูุดููุงุช ูุณุชูู ุงูุฌูู"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "477f65ef",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "๐ ูุญุต ูุดููุงุช ูุณุชูู ุงูุฌูู\n",
      "======================================================================\n",
      "ุฌุงุฑู ูุญุต 1,000,000 ุณุทุฑ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ูุญุต ุงูุฌูู: 100%|โโโโโโโโโโ| 1000000/1000000 [00:16<00:00, 61823.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ุงูุฃุณุทุฑ ุงููุงุฑุบุฉ ---\n",
      "ุฃุณุทุฑ ูุงุฑุบุฉ: 0 (0.0000%)\n",
      "\n",
      "--- ุฅุญุตุงุฆูุงุช ุทูู ุงูุฌูู ---\n",
      "ุงููุชูุณุท: 25.78 ูููุฉ\n",
      "ุงููุณูุท: 22.00 ูููุฉ\n",
      "ุงูุฃุฏูู: 1 ูููุงุช\n",
      "ุงูุฃูุตู: 4036 ูููุงุช\n",
      "ุงูุงูุญุฑุงู ุงููุนูุงุฑู: 30.16 ูููุฉ\n",
      "\n",
      "--- ุงูุฌูู ุงููุตูุฑุฉ ุฌุฏุงู (<3 ูููุงุช) ---\n",
      "ุงูุนุฏุฏ: 30,783 (3.08%)\n",
      "ุฃูุซูุฉ:\n",
      "   '1(.'\n",
      "   'M.'\n",
      "   ', S.'\n",
      "   'J.'\n",
      "   'D.'\n",
      "\n",
      "--- ุงูุฌูู ุงูุทูููุฉ ุฌุฏุงู (>100 ูููุฉ) ---\n",
      "ุงูุนุฏุฏ: 7,861 (0.79%)\n",
      "ุฃูุซูุฉ:\n",
      "   [156 ูููุฉ] )ุง( ุชุชุนูุฏ ุจุงูุงูุชูุงุน ุงุซูุงุก ูุฐู ุงููุชุฑุฉ ุนู ุงูุชูุฏู ุจุงู ุงูุชุฑุงุญ ููุฒุน ุงูุซูุฉ ูู ุญูููุฉ ุงูููุงู ุงููุทููุฉ ุทุงููุง ุช...\n",
      "   [101 ูููุฉ] ุงูู ุงูุนุฏูุฏ ูู ุงููุชุจ ูุงูููุงูุงุชุ ูููุง Les exceptions prรฉliminaires dans la procรฉdure de la cour intern...\n",
      "   [770 ูููุฉ] ูก - ุชุญูุท ุนููุง ูุน ุงูุชูุฏูุฑ ุจุชูุฑูุฑ ุงูุงููู ุงูุนุงู ุนู ุญุงูุฉ ุงูุงุนูุงู ุงูุชุญุถูุฑูุฉ ููุณูุฉ ุงูุฏูููุฉ ููุงุณุฑุฉุูข - ุชุนุฑุจ...\n",
      "\n",
      "--- ูุดููุงุช ุนูุงูุงุช ุงูููุงูุฉ ---\n",
      "ุฃุณุทุฑ ุชูุชูุฏ ูุนูุงูุฉ ููุงูุฉ ููุงุณูุฉ: 0\n",
      "\n",
      "--- ุนูุงูุงุช ููุงูุฉ ูุชุนุฏุฏุฉ ---\n",
      "ุฃุณุทุฑ ุชุญุชูู ุนูู ุนูุงูุงุช ููุงูุฉ ูู ูุณุท ุงูุฌููุฉ: 2,327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ุงููุญุต 2.3: ูุดููุงุช ูุณุชูู ุงูุฌูู\n",
    "# ============================================================================\n",
    "\n",
    "def inspect_sentence_issues(dataset_dir: str, sample_size: int = 1000000) -> Dict:\n",
    "    \"\"\"\n",
    "    ูุญุต ูุดููุงุช ูุณุชูู ุงูุฌูู.\n",
    "    \n",
    "    ูุชุญูู ูู:\n",
    "    - ุงูุฃุณุทุฑ ุงููุงุฑุบุฉ\n",
    "    - ุงูุฌูู ุงููุตูุฑุฉ ุฌุฏุงู\n",
    "    - ุงูุฌูู ุงูุทูููุฉ ุฌุฏุงู\n",
    "    - ุบูุงุจ ุนูุงูุงุช ููุงูุฉ ุงูุฌููุฉ\n",
    "    - ุฌูู ูุชุนุฏุฏุฉ ูู ุณุทุฑ ูุงุญุฏ\n",
    "    \n",
    "    ุงููุนุงููุงุช:\n",
    "    -----------\n",
    "    dataset_dir : str\n",
    "        ูุณุงุฑ ูุฌูุฏ ุงูุจูุงูุงุช\n",
    "    sample_size : int\n",
    "        ุนุฏุฏ ุงูุฃุณุทุฑ ูููุญุต\n",
    "        \n",
    "    ุชุฑุฌุน:\n",
    "    --------\n",
    "    Dict\n",
    "        ูุงููุณ ูุญุชูู ุนูู ุฅุญุตุงุฆูุงุช ุงููุดููุงุช\n",
    "    \"\"\"\n",
    "    logger.section(\"๐ ูุญุต ูุดููุงุช ูุณุชูู ุงูุฌูู\")\n",
    "    logger.info(f\"ุฌุงุฑู ูุญุต {sample_size:,} ุณุทุฑ...\")\n",
    "    \n",
    "    stats = {\n",
    "        'total_lines': 0,\n",
    "        'empty_lines': 0,\n",
    "        'very_short': [],  # < 3 ูููุงุช\n",
    "        'very_long': [],   # > 100 ูููุฉ\n",
    "        'word_counts': [],\n",
    "        'missing_terminal': 0,\n",
    "        'wrong_terminal': Counter(),\n",
    "        'multiple_terminals': 0,\n",
    "    }\n",
    "    \n",
    "    iterator = iter_dataset_lines(dataset_dir)\n",
    "    if TQDM_AVAILABLE:\n",
    "        iterator = tqdm(iterator, total=sample_size, desc=\"ูุญุต ุงูุฌูู\")\n",
    "    \n",
    "    for i, line in enumerate(iterator):\n",
    "        if i >= sample_size:\n",
    "            break\n",
    "        \n",
    "        stats['total_lines'] += 1\n",
    "        \n",
    "        # ุงูุชุญูู ูู ุงููุฑุงุบ\n",
    "        stripped = line.strip()\n",
    "        if not stripped:\n",
    "            stats['empty_lines'] += 1\n",
    "            continue\n",
    "        \n",
    "        # ุนุฏ ุงููููุงุช\n",
    "        words = stripped.split()\n",
    "        word_count = len(words)\n",
    "        stats['word_counts'].append(word_count)\n",
    "        \n",
    "        # ุงูุชุญูู ูู ุงููุตุฑ ุงูุดุฏูุฏ\n",
    "        if word_count < 3:\n",
    "            if len(stats['very_short']) < 20:  # ุชุฎุฒูู ุฃูุซูุฉ\n",
    "                stats['very_short'].append(stripped)\n",
    "        \n",
    "        # ุงูุชุญูู ูู ุงูุทูู ุงูุดุฏูุฏ\n",
    "        if word_count > 100:\n",
    "            if len(stats['very_long']) < 10:\n",
    "                stats['very_long'].append((word_count, stripped[:100] + \"...\"))\n",
    "        \n",
    "        # ุงูุชุญูู ูู ุนูุงูุฉ ุงูููุงูุฉ\n",
    "        if stripped:\n",
    "            last_char = stripped[-1]\n",
    "            if last_char not in SENTENCE_TERMINALS:\n",
    "                stats['missing_terminal'] += 1\n",
    "                stats['wrong_terminal'][last_char] += 1\n",
    "        \n",
    "        # ุงูุชุญูู ูู ูุฌูุฏ ุนูุงูุงุช ููุงูุฉ ูุชุนุฏุฏุฉ ุฏุงุฎู ุงูุณุทุฑ\n",
    "        terminal_count = sum(1 for c in stripped[:-1] if c in SENTENCE_TERMINALS)\n",
    "        if terminal_count > 0:\n",
    "            stats['multiple_terminals'] += 1\n",
    "    \n",
    "    # ุนุฑุถ ุงููุชุงุฆุฌ\n",
    "    logger.subsection(\"ุงูุฃุณุทุฑ ุงููุงุฑุบุฉ\")\n",
    "    logger.info(f\"ุฃุณุทุฑ ูุงุฑุบุฉ: {stats['empty_lines']:,} ({stats['empty_lines']/stats['total_lines']*100:.4f}%)\")\n",
    "    \n",
    "    logger.subsection(\"ุฅุญุตุงุฆูุงุช ุทูู ุงูุฌูู\")\n",
    "    if stats['word_counts']:\n",
    "        word_arr = np.array(stats['word_counts'])\n",
    "        logger.info(f\"ุงููุชูุณุท: {np.mean(word_arr):.2f} ูููุฉ\")\n",
    "        logger.info(f\"ุงููุณูุท: {np.median(word_arr):.2f} ูููุฉ\")\n",
    "        logger.info(f\"ุงูุฃุฏูู: {np.min(word_arr)} ูููุงุช\")\n",
    "        logger.info(f\"ุงูุฃูุตู: {np.max(word_arr)} ูููุงุช\")\n",
    "        logger.info(f\"ุงูุงูุญุฑุงู ุงููุนูุงุฑู: {np.std(word_arr):.2f} ูููุฉ\")\n",
    "    \n",
    "    logger.subsection(\"ุงูุฌูู ุงููุตูุฑุฉ ุฌุฏุงู (<3 ูููุงุช)\")\n",
    "    short_count = sum(1 for w in stats['word_counts'] if w < 3)\n",
    "    logger.info(f\"ุงูุนุฏุฏ: {short_count:,} ({short_count/stats['total_lines']*100:.2f}%)\")\n",
    "    if stats['very_short']:\n",
    "        logger.info(\"ุฃูุซูุฉ:\")\n",
    "        for example in stats['very_short'][:5]:\n",
    "            logger.info(f\"   '{example}'\")\n",
    "    \n",
    "    logger.subsection(\"ุงูุฌูู ุงูุทูููุฉ ุฌุฏุงู (>100 ูููุฉ)\")\n",
    "    long_count = sum(1 for w in stats['word_counts'] if w > 100)\n",
    "    logger.info(f\"ุงูุนุฏุฏ: {long_count:,} ({long_count/stats['total_lines']*100:.2f}%)\")\n",
    "    if stats['very_long']:\n",
    "        logger.info(\"ุฃูุซูุฉ:\")\n",
    "        for wc, example in stats['very_long'][:3]:\n",
    "            logger.info(f\"   [{wc} ูููุฉ] {example}\")\n",
    "    \n",
    "    logger.subsection(\"ูุดููุงุช ุนูุงูุงุช ุงูููุงูุฉ\")\n",
    "    logger.info(f\"ุฃุณุทุฑ ุชูุชูุฏ ูุนูุงูุฉ ููุงูุฉ ููุงุณูุฉ: {stats['missing_terminal']:,}\")\n",
    "    if stats['wrong_terminal']:\n",
    "        logger.info(\"ููุงูุงุช ุบูุฑ ููุงุณูุฉ ูุฌุฏุช:\")\n",
    "        for char, count in stats['wrong_terminal'].most_common(10):\n",
    "            logger.info(f\"   '{char}': {count:,}\")\n",
    "    \n",
    "    logger.subsection(\"ุนูุงูุงุช ููุงูุฉ ูุชุนุฏุฏุฉ\")\n",
    "    logger.info(f\"ุฃุณุทุฑ ุชุญุชูู ุนูู ุนูุงูุงุช ููุงูุฉ ูู ูุณุท ุงูุฌููุฉ: {stats['multiple_terminals']:,}\")\n",
    "    \n",
    "    return stats\n",
    "\n",
    "\n",
    "# ุชุดุบูู ูุญุต ุงูุฌูู\n",
    "sentence_issues = inspect_sentence_issues(config.input_dir, sample_size=1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85af30de",
   "metadata": {},
   "source": [
    "### 2.4 ูุดููุงุช ุงูุฃููุงุท ุงูุฎุงุตุฉ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "003f1486",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "๐ ูุญุต ุงูุฃููุงุท ุงูุฎุงุตุฉ\n",
      "======================================================================\n",
      "ุฌุงุฑู ูุญุต 500,000 ุณุทุฑ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ูุญุต ุงูุฃููุงุท: 100%|โโโโโโโโโโ| 500000/500000 [00:13<00:00, 38004.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ุฃููุงุท ูุงู ุงูุนุทู ---\n",
      "ุฅุฌูุงูู ุงููููุงุช ุงูุชู ุชุจุฏุฃ ุจู ู: 1,212,040\n",
      "ุฃูุซุฑ ุงููููุงุช ุดููุนุงู ูุน ุงููุงู:\n",
      "   'ููู': 36,107\n",
      "   'ููุฏ': 21,846\n",
      "   'ููู': 16,316\n",
      "   'ูุงู': 16,131\n",
      "   'ููุง': 13,358\n",
      "   'ูุนูู': 8,929\n",
      "   'ููู': 8,436\n",
      "   'ูุถุน': 8,331\n",
      "   'ูููุง': 7,859\n",
      "   'ููู': 7,644\n",
      "   'ูููุจุบู': 7,473\n",
      "   'ูุงูุชูููุฉ': 7,015\n",
      "   'ูุฐูู': 6,968\n",
      "   'ููุฐูู': 5,639\n",
      "   'ููููุง': 5,473\n",
      "\n",
      "--- ุฃูุธูุฉ ุงูุฃุฑูุงู ---\n",
      "ุฃุฑูุงู ุนุฑุจูุฉ ูุฌุฏุช: 531,683\n",
      "ุฃุฑูุงู ุบุฑุจูุฉ ูุฌุฏุช: 81,871\n",
      "ุฃุณุทุฑ ุจุฃุฑูุงู ูุฎุชูุทุฉ: 16,461\n",
      "\n",
      "--- ูุฑุงุฌุน ุงููุณุชูุฏุงุช ---\n",
      "ุฃูุซูุฉ: ['A/47/10', 'S/25704', 'A/47/975', 'S/26063', 'A/47/975', 'S/26063', 'S/5634', 'S/5910', 'S/12342', 'S/25704']\n",
      "\n",
      "--- ุญุฑูู ููุฑุฑุฉ ---\n",
      "ุฃุณุทุฑ ุจุญุฑูู ููุฑุฑุฉ:\n",
      "   )ุง( ุงุนุชูุงุฏ ูุจูุบ ุงุฌูุงูู ูุฏุฑู ูจูู ูขูฅูจ ูขูฅ ูู ุฏููุงุฑุงุช ุงูููุงูุงุช ุงููุชุญุฏุฉ )ุตุงููู ููู ูขูก\n",
      "   ููุงุฌุฑุงุก ูุคูุชุ ูุฌุฑู ูุณูุฉ ุงููุจูุบ ุงูุฐู ุชูุฑุฑู ุงููุฌูุฉ ุงูุงุณุชุดุงุฑูุฉ ุจูู ุงูุฏูู ุงูุงุนุถุงุกุ ู\n",
      "   )ูข( ูุนุงูุฏุฉ ุงููุจุงุฏุฆ ุงูููุธูุฉ ูุงูุดุทุฉ ุงูุฏูู ูู ููุฏุงู ุงุณุชูุดุงู ูุงุณุชุฎุฏุงู ุงููุถุงุก ุงูุฎุงุฑุฌู\n",
      "\n",
      "--- ูููุงุช ุฃุฌูุจูุฉ ---\n",
      "ูููุงุช ุฃุฌูุจูุฉ ูุฑูุฏุฉ: 2,851\n",
      "ุฃูุซุฑ ุงููููุงุช ุงูุฃุฌูุจูุฉ ุดููุนุงู:\n",
      "   'Add': 6,581\n",
      "   'Rev': 1,386\n",
      "   'Corr': 828\n",
      "   'CRP': 527\n",
      "   'FCCC': 510\n",
      "   'Sub': 401\n",
      "   'PCN': 314\n",
      "   'LOS': 312\n",
      "   'CCPR': 307\n",
      "   'CONF': 301\n",
      "   'UNEP': 202\n",
      "   'and': 187\n",
      "   'Part': 182\n",
      "   'SCN': 167\n",
      "   'NUW': 153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ุงููุญุต 2.4: ูุดููุงุช ุงูุฃููุงุท ุงูุฎุงุตุฉ\n",
    "# ============================================================================\n",
    "\n",
    "def inspect_special_patterns(dataset_dir: str, sample_size: int = 500000) -> Dict:\n",
    "    \"\"\"\n",
    "    ูุญุต ุงูุฃููุงุท ุงูุฎุงุตุฉ ุงูุชู ูุฏ ุชุญุชุงุฌ ููุนุงูุฌุฉ.\n",
    "    \n",
    "    ูุชุญูู ูู:\n",
    "    - ูุงู ุงูุนุทู ุงููุชุตูุฉ ุจุงููููุงุช\n",
    "    - ุงูุฃุฑูุงู (ุงูุนุฑุจูุฉ ูุงูุบุฑุจูุฉ)\n",
    "    - ูุฑุงุฌุน ุงููุณุชูุฏุงุช (ูุซู A/47/10)\n",
    "    - ุฃููุงุท ุงูุฑูุงุจุท ุฃู ุงูุจุฑูุฏ ุงูุฅููุชุฑููู\n",
    "    - ุงูุญุฑูู ุงูููุฑุฑุฉ\n",
    "    \n",
    "    ุงููุนุงููุงุช:\n",
    "    -----------\n",
    "    dataset_dir : str\n",
    "        ูุณุงุฑ ูุฌูุฏ ุงูุจูุงูุงุช\n",
    "    sample_size : int\n",
    "        ุนุฏุฏ ุงูุฃุณุทุฑ ูููุญุต\n",
    "        \n",
    "    ุชุฑุฌุน:\n",
    "    --------\n",
    "    Dict\n",
    "        ูุงููุณ ูุญุชูู ุนูู ุฅุญุตุงุฆูุงุช ุงูุฃููุงุท\n",
    "    \"\"\"\n",
    "    logger.section(\"๐ ูุญุต ุงูุฃููุงุท ุงูุฎุงุตุฉ\")\n",
    "    logger.info(f\"ุฌุงุฑู ูุญุต {sample_size:,} ุณุทุฑ...\")\n",
    "    \n",
    "    stats = {\n",
    "        'total_lines': 0,\n",
    "        'waw_attached': Counter(),  # ูููุงุช ุชุจุฏุฃ ุจู ู\n",
    "        'arabic_numbers': 0,\n",
    "        'western_numbers': 0,\n",
    "        'mixed_number_lines': 0,\n",
    "        'doc_references': [],\n",
    "        'repeated_chars': [],\n",
    "        'foreign_words': Counter(),\n",
    "    }\n",
    "    \n",
    "    # ุงูุฃููุงุท (Patterns)\n",
    "    waw_word_pattern = re.compile(r'\\bู[\\u0600-\\u06FF]{2,}\\b')\n",
    "    arabic_num_pattern = re.compile(r'[ู-ูฉ]+')\n",
    "    western_num_pattern = re.compile(r'[0-9]+')\n",
    "    doc_ref_pattern = re.compile(r'[A-Z]/[0-9]+(?:/[0-9A-Z]+)*')\n",
    "    repeated_pattern = re.compile(r'(.)\\1{3,}')  # ููุณ ุงูุญุฑู 4 ูุฑุงุช ุฃู ุฃูุซุฑ\n",
    "    foreign_word_pattern = re.compile(r'\\b[A-Za-z]{3,}\\b')  # 3+ ุญุฑูู ูุงุชูููุฉ\n",
    "    \n",
    "    iterator = iter_dataset_lines(dataset_dir)\n",
    "    if TQDM_AVAILABLE:\n",
    "        iterator = tqdm(iterator, total=sample_size, desc=\"ูุญุต ุงูุฃููุงุท\")\n",
    "    \n",
    "    for i, line in enumerate(iterator):\n",
    "        if i >= sample_size:\n",
    "            break\n",
    "        \n",
    "        stats['total_lines'] += 1\n",
    "        \n",
    "        # ุงููููุงุช ุงููุชุตูุฉ ุจุงููุงู\n",
    "        waw_matches = waw_word_pattern.findall(line)\n",
    "        for match in waw_matches:\n",
    "            stats['waw_attached'][match] += 1\n",
    "        \n",
    "        # ุฃูุธูุฉ ุงูุฃุฑูุงู\n",
    "        has_arabic = bool(arabic_num_pattern.search(line))\n",
    "        has_western = bool(western_num_pattern.search(line))\n",
    "        \n",
    "        if has_arabic:\n",
    "            stats['arabic_numbers'] += len(arabic_num_pattern.findall(line))\n",
    "        if has_western:\n",
    "            stats['western_numbers'] += len(western_num_pattern.findall(line))\n",
    "        if has_arabic and has_western:\n",
    "            stats['mixed_number_lines'] += 1\n",
    "        \n",
    "        # ูุฑุงุฌุน ุงููุณุชูุฏุงุช\n",
    "        doc_refs = doc_ref_pattern.findall(line)\n",
    "        if doc_refs and len(stats['doc_references']) < 20:\n",
    "            stats['doc_references'].extend(doc_refs[:2])\n",
    "        \n",
    "        # ุงูุญุฑูู ุงูููุฑุฑุฉ\n",
    "        repeated = repeated_pattern.findall(line)\n",
    "        if repeated and len(stats['repeated_chars']) < 10:\n",
    "            stats['repeated_chars'].append(line[:80])\n",
    "        \n",
    "        # ุงููููุงุช ุงูุฃุฌูุจูุฉ\n",
    "        foreign = foreign_word_pattern.findall(line)\n",
    "        for word in foreign:\n",
    "            stats['foreign_words'][word] += 1\n",
    "    \n",
    "    # ุนุฑุถ ุงููุชุงุฆุฌ\n",
    "    logger.subsection(\"ุฃููุงุท ูุงู ุงูุนุทู\")\n",
    "    logger.info(f\"ุฅุฌูุงูู ุงููููุงุช ุงูุชู ุชุจุฏุฃ ุจู ู: {sum(stats['waw_attached'].values()):,}\")\n",
    "    logger.info(\"ุฃูุซุฑ ุงููููุงุช ุดููุนุงู ูุน ุงููุงู:\")\n",
    "    for word, count in stats['waw_attached'].most_common(15):\n",
    "        logger.info(f\"   '{word}': {count:,}\")\n",
    "    \n",
    "    logger.subsection(\"ุฃูุธูุฉ ุงูุฃุฑูุงู\")\n",
    "    logger.info(f\"ุฃุฑูุงู ุนุฑุจูุฉ ูุฌุฏุช: {stats['arabic_numbers']:,}\")\n",
    "    logger.info(f\"ุฃุฑูุงู ุบุฑุจูุฉ ูุฌุฏุช: {stats['western_numbers']:,}\")\n",
    "    logger.info(f\"ุฃุณุทุฑ ุจุฃุฑูุงู ูุฎุชูุทุฉ: {stats['mixed_number_lines']:,}\")\n",
    "    \n",
    "    logger.subsection(\"ูุฑุงุฌุน ุงููุณุชูุฏุงุช\")\n",
    "    logger.info(f\"ุฃูุซูุฉ: {stats['doc_references'][:10]}\")\n",
    "    \n",
    "    logger.subsection(\"ุญุฑูู ููุฑุฑุฉ\")\n",
    "    if stats['repeated_chars']:\n",
    "        logger.info(\"ุฃุณุทุฑ ุจุญุฑูู ููุฑุฑุฉ:\")\n",
    "        for example in stats['repeated_chars'][:3]:\n",
    "            logger.info(f\"   {example}\")\n",
    "    else:\n",
    "        logger.info(\"ูู ูุชู ุงูุนุซูุฑ ุนูู ุฃููุงุท ุญุฑูู ููุฑุฑุฉ ูููุฉ\")\n",
    "    \n",
    "    logger.subsection(\"ูููุงุช ุฃุฌูุจูุฉ\")\n",
    "    logger.info(f\"ูููุงุช ุฃุฌูุจูุฉ ูุฑูุฏุฉ: {len(stats['foreign_words']):,}\")\n",
    "    logger.info(\"ุฃูุซุฑ ุงููููุงุช ุงูุฃุฌูุจูุฉ ุดููุนุงู:\")\n",
    "    for word, count in stats['foreign_words'].most_common(15):\n",
    "        logger.info(f\"   '{word}': {count:,}\")\n",
    "    \n",
    "    return stats\n",
    "\n",
    "\n",
    "# ุชุดุบูู ูุญุต ุงูุฃููุงุท ุงูุฎุงุตุฉ\n",
    "special_issues = inspect_special_patterns(config.input_dir, sample_size=500000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da20edd",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. ุงูุฌุฒุก 2: ุฎุทูุงุช ุงููุนุงูุฌุฉ ุงูุฅูุฒุงููุฉ\n",
    "\n",
    "ูุฐู ุงูุฎุทูุงุช **ุชูุทุจู ุฏุงุฆูุงู** ูุฃููุง ุชุนุงูุฌ ูุดููุงุช ุฃุณุงุณูุฉ ูู ุฌูุฏุฉ ุงูุจูุงูุงุช\n",
    "ูุงูุชู ุณุชุคุซุฑ ุณูุจุงู ุนูู ุชุฏุฑูุจ ุงููููุฐุฌ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a4638d",
   "metadata": {},
   "source": [
    "### 3.1 ุฅุฒุงูุฉ ุงูุชุดููู (ุงูุญุฑูุงุช)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82ac8449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "๐ง ุงููุนุงูุฌุฉ ุงููุณุจูุฉ: ุฅุฒุงูุฉ ุงูุชุดููู\n",
      "======================================================================\n",
      "ุญุงูุงุช ุงูุงุฎุชุจุงุฑ:\n",
      "   'ุงููุนูุฑูุจููููุฉ' -> 'ุงูุนุฑุจูุฉ'\n",
      "   'ููุญููููุฏ' -> 'ูุญูุฏ'\n",
      "   'ุงูุฃููููู ุงูููุชููุญูุฏูุฉ' -> 'ุงูุฃูู ุงููุชุญุฏุฉ'\n",
      "   'ูุต ุจุฏูู ุชุดููู' -> 'ูุต ุจุฏูู ุชุดููู'\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ุงููุนุงูุฌุฉ 3.1: ุฅุฒุงูุฉ ุงูุชุดููู\n",
    "# ============================================================================\n",
    "\n",
    "def remove_diacritics(text: str) -> str:\n",
    "    \"\"\"\n",
    "    ุฅุฒุงูุฉ ุงูุชุดููู (ุงูุญุฑูุงุช) ูู ุงููุต ุงูุนุฑุจู.\n",
    "    \n",
    "    ุงูุชุดููู ุงูุฐู ูุชู ุฅุฒุงูุชู:\n",
    "    - ูุชุญุชุงู (ู)ุ ุถูุชุงู (ู)ุ ูุณุฑุชุงู (ู)\n",
    "    - ูุชุญุฉ (ู)ุ ุถูุฉ (ู)ุ ูุณุฑุฉ (ู)\n",
    "    - ุดุฏุฉ (ู)ุ ุณููู (ู)\n",
    "    \n",
    "    ุงููุนุงููุงุช:\n",
    "    -----------\n",
    "    text : str\n",
    "        ุงููุต ุงููุฏุฎู ูุน ุงุญุชูุงู ูุฌูุฏ ุชุดููู\n",
    "        \n",
    "    ุชุฑุฌุน:\n",
    "    --------\n",
    "    str\n",
    "        ุงููุต ุจุฏูู ุชุดููู\n",
    "        \n",
    "    ูุซุงู:\n",
    "    --------\n",
    "    >>> remove_diacritics(\"ุงููุนูุฑูุจููููุฉ\")\n",
    "    'ุงูุนุฑุจูุฉ'\n",
    "    \"\"\"\n",
    "    return DIACRITICS_PATTERN.sub('', text)\n",
    "\n",
    "\n",
    "# ุงุฎุชุจุงุฑ ุงูุฏุงูุฉ\n",
    "logger.section(\"๐ง ุงููุนุงูุฌุฉ ุงููุณุจูุฉ: ุฅุฒุงูุฉ ุงูุชุดููู\")\n",
    "\n",
    "test_cases = [\n",
    "    \"ุงููุนูุฑูุจููููุฉ\",\n",
    "    \"ููุญููููุฏ\",\n",
    "    \"ุงูุฃููููู ุงูููุชููุญูุฏูุฉ\",\n",
    "    \"ูุต ุจุฏูู ุชุดููู\",\n",
    "]\n",
    "\n",
    "logger.info(\"ุญุงูุงุช ุงูุงุฎุชุจุงุฑ:\")\n",
    "for test in test_cases:\n",
    "    result = remove_diacritics(test)\n",
    "    logger.info(f\"   '{test}' -> '{result}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76401a73",
   "metadata": {},
   "source": [
    "### 3.2 ุชูุญูุฏ ุฃุดูุงู ุงูุฃูู"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a260856",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "๐ง ุงููุนุงูุฌุฉ ุงููุณุจูุฉ: ุชูุญูุฏ ุงูุฃูู\n",
      "======================================================================\n",
      "ุญุงูุงุช ุงูุงุฎุชุจุงุฑ:\n",
      "   'ุฃุญูุฏ' -> 'ุงุญูุฏ'\n",
      "   'ุฅุจุฑุงููู' -> 'ุงุจุฑุงููู'\n",
      "   'ุขุฏู' -> 'ุงุฏู'\n",
      "   'ุงูุฃูู' -> 'ุงูุงูู'\n",
      "   'ุงูุฅูุณุงู' -> 'ุงูุงูุณุงู'\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ุงููุนุงูุฌุฉ 3.2: ุชูุญูุฏ ุฃุดูุงู ุงูุฃูู\n",
    "# ============================================================================\n",
    "\n",
    "# ุชุฌููุน ุงูููุท ููููุงุกุฉ\n",
    "ALEF_PATTERN = re.compile(r'[ุฃุฅุขูฑ]')\n",
    "\n",
    "def normalize_alef(text: str) -> str:\n",
    "    \"\"\"\n",
    "    ุชูุญูุฏ ุฌููุน ุฃุดูุงู ุงูุฃูู ุฅูู ุฃูู ูุฌุฑุฏุฉ (ุง).\n",
    "    \n",
    "    ุงูุชุญูููุงุช:\n",
    "    - ุฃ (ููุฒุฉ ููู) -> ุง\n",
    "    - ุฅ (ููุฒุฉ ุชุญุช) -> ุง\n",
    "    - ุข (ูุฏุฉ) -> ุง\n",
    "    - ูฑ (ูุตู) -> ุง\n",
    "    \n",
    "    ุงููุนุงููุงุช:\n",
    "    -----------\n",
    "    text : str\n",
    "        ุงููุต ุงููุฏุฎู\n",
    "        \n",
    "    ุชุฑุฌุน:\n",
    "    --------\n",
    "    str\n",
    "        ุงููุต ูุน ุฃูู ููุญุฏุฉ\n",
    "        \n",
    "    ูุซุงู:\n",
    "    --------\n",
    "    >>> normalize_alef(\"ุฃุญูุฏ ุฅุจุฑุงููู ุขุฏู\")\n",
    "    'ุงุญูุฏ ุงุจุฑุงููู ุงุฏู'\n",
    "    \"\"\"\n",
    "    return ALEF_PATTERN.sub('ุง', text)\n",
    "\n",
    "\n",
    "# ุงุฎุชุจุงุฑ ุงูุฏุงูุฉ\n",
    "logger.section(\"๐ง ุงููุนุงูุฌุฉ ุงููุณุจูุฉ: ุชูุญูุฏ ุงูุฃูู\")\n",
    "\n",
    "test_cases = [\n",
    "    \"ุฃุญูุฏ\",\n",
    "    \"ุฅุจุฑุงููู\",\n",
    "    \"ุขุฏู\",\n",
    "    \"ุงูุฃูู\",\n",
    "    \"ุงูุฅูุณุงู\",\n",
    "]\n",
    "\n",
    "logger.info(\"ุญุงูุงุช ุงูุงุฎุชุจุงุฑ:\")\n",
    "for test in test_cases:\n",
    "    result = normalize_alef(test)\n",
    "    logger.info(f\"   '{test}' -> '{result}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8fa82c",
   "metadata": {},
   "source": [
    "### 3.3 ุชูุญูุฏ ุงูุชุงุก ุงููุฑุจูุทุฉ ูุงูุฃูู ุงูููุตูุฑุฉ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c66d5712",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "๐ง ุงููุนุงูุฌุฉ ุงููุณุจูุฉ: ุชูุญูุฏ ุงูุชุงุก ุงููุฑุจูุทุฉ ูุงูุฃูู ุงูููุตูุฑุฉ\n",
      "======================================================================\n",
      "ุญุงูุงุช ุงูุงุฎุชุจุงุฑ:\n",
      "   'ูุฏุฑุณุฉ' (ุชุงุก ูุฑุจูุทุฉ)\n",
      "      ุชุงุก ูุฑุจูุทุฉ (ุฅุจูุงุก): 'ูุฏุฑุณุฉ'\n",
      "      ุฃูู ููุตูุฑุฉ -> ูุงุก: 'ูุฏุฑุณุฉ'\n",
      "   'ุนูู' (ุฃูู ููุตูุฑุฉ)\n",
      "      ุชุงุก ูุฑุจูุทุฉ (ุฅุจูุงุก): 'ุนูู'\n",
      "      ุฃูู ููุตูุฑุฉ -> ูุงุก: 'ุนูู'\n",
      "   'ูุณุชุดูู' (ุฃูู ููุตูุฑุฉ)\n",
      "      ุชุงุก ูุฑุจูุทุฉ (ุฅุจูุงุก): 'ูุณุชุดูู'\n",
      "      ุฃูู ููุตูุฑุฉ -> ูุงุก: 'ูุณุชุดูู'\n",
      "   'ุงููุงูุฑุฉ' (ุชุงุก ูุฑุจูุทุฉ)\n",
      "      ุชุงุก ูุฑุจูุทุฉ (ุฅุจูุงุก): 'ุงููุงูุฑุฉ'\n",
      "      ุฃูู ููุตูุฑุฉ -> ูุงุก: 'ุงููุงูุฑุฉ'\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ุงููุนุงูุฌุฉ 3.3: ุชูุญูุฏ ุงูุชุงุก ุงููุฑุจูุทุฉ ูุงูุฃูู ุงูููุตูุฑุฉ\n",
    "# ============================================================================\n",
    "\n",
    "def normalize_teh_marbuta(text: str, to_heh: bool = False) -> str:\n",
    "    \"\"\"\n",
    "    ูุนุงูุฌุฉ ุงูุชุงุก ุงููุฑุจูุทุฉ (ุฉ).\n",
    "    \n",
    "    ุฎูุงุฑุงุช:\n",
    "    - ุฅุจูุงุคูุง ููุง ูู (ุงูุงูุชุฑุงุถู ููุฐู ุงููููุฉ)\n",
    "    - ุชุญููููุง ุฅูู ูุงุก (ู) - ุจุนุถ ุชุทุจููุงุช NLP ุชูุนู ุฐูู\n",
    "    \n",
    "    ุงููุนุงููุงุช:\n",
    "    -----------\n",
    "    text : str\n",
    "        ุงููุต ุงููุฏุฎู\n",
    "    to_heh : bool\n",
    "        ุฅุฐุง ูุงู Trueุ ุญูู ุฉ ุฅูู ู\n",
    "        \n",
    "    ุชุฑุฌุน:\n",
    "    --------\n",
    "    str\n",
    "        ุงููุต ุงููุนุงูุฌ\n",
    "    \"\"\"\n",
    "    if to_heh:\n",
    "        return text.replace('ุฉ', 'ู')\n",
    "    return text\n",
    "\n",
    "\n",
    "def normalize_alef_maksura(text: str) -> str:\n",
    "    \"\"\"\n",
    "    ุชูุญูุฏ ุงูุฃูู ุงูููุตูุฑุฉ (ู) ุฅูู ูุงุก (ู).\n",
    "    \n",
    "    ููุงุญุธุฉ: ูู ุจุนุถ ุงูุณูุงูุงุชุ ูุชู ุงูุชูููุฒ ุจููููุง. ูุชูุจุค ุงูุชุฑูููุ\n",
    "    ุงูุชูุญูุฏ ูุญุณู ุงูุงุชุณุงู.\n",
    "    \n",
    "    ุงููุนุงููุงุช:\n",
    "    -----------\n",
    "    text : str\n",
    "        ุงููุต ุงููุฏุฎู\n",
    "        \n",
    "    ุชุฑุฌุน:\n",
    "    --------\n",
    "    str\n",
    "        ุงููุต ูุน ู -> ู\n",
    "        \n",
    "    ูุซุงู:\n",
    "    --------\n",
    "    >>> normalize_alef_maksura(\"ุนูู\")\n",
    "    'ุนูู'\n",
    "    \"\"\"\n",
    "    return text.replace('ู', 'ู')\n",
    "\n",
    "\n",
    "# ุงุฎุชุจุงุฑ ุงูุฏูุงู\n",
    "logger.section(\"๐ง ุงููุนุงูุฌุฉ ุงููุณุจูุฉ: ุชูุญูุฏ ุงูุชุงุก ุงููุฑุจูุทุฉ ูุงูุฃูู ุงูููุตูุฑุฉ\")\n",
    "\n",
    "test_cases = [\n",
    "    (\"ูุฏุฑุณุฉ\", \"ุชุงุก ูุฑุจูุทุฉ\"),\n",
    "    (\"ุนูู\", \"ุฃูู ููุตูุฑุฉ\"),\n",
    "    (\"ูุณุชุดูู\", \"ุฃูู ููุตูุฑุฉ\"),\n",
    "    (\"ุงููุงูุฑุฉ\", \"ุชุงุก ูุฑุจูุทุฉ\"),\n",
    "]\n",
    "\n",
    "logger.info(\"ุญุงูุงุช ุงูุงุฎุชุจุงุฑ:\")\n",
    "for test, note in test_cases:\n",
    "    result_tm = normalize_teh_marbuta(test, to_heh=False)\n",
    "    result_am = normalize_alef_maksura(test)\n",
    "    logger.info(f\"   '{test}' ({note})\")\n",
    "    logger.info(f\"      ุชุงุก ูุฑุจูุทุฉ (ุฅุจูุงุก): '{result_tm}'\")\n",
    "    logger.info(f\"      ุฃูู ููุตูุฑุฉ -> ูุงุก: '{result_am}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac75ef4",
   "metadata": {},
   "source": [
    "### 3.4 ุฅุฒุงูุฉ ุงูุญุฑูู ุฎุงุฑุฌ ุงููุทุงู (OOV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72ae13d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "๐ง ุงููุนุงูุฌุฉ ุงููุณุจูุฉ: ุฅุฒุงูุฉ ุงูุญุฑูู ุฎุงุฑุฌ ุงููุทุงู\n",
      "======================================================================\n",
      "ุญุฌู ูุฌููุนุฉ ุงูุญุฑูู ุงูุตุงูุญุฉ: 62\n",
      "ุญุงูุงุช ุงูุงุฎุชุจุงุฑ:\n",
      "   'ุงููุต ุงูุนุฑุจู ูุน English text'\n",
      "   -> 'ุงููุต ุงูุนุฑุจู ูุน  '\n",
      "   'ุฑูู: ูกูขูฃ ู 456'\n",
      "   -> 'ุฑูู: ูกูขูฃ ู '\n",
      "   'ูุน ุฑููุฒ ุฎุงุตุฉ: @#$%'\n",
      "   -> 'ูุน ุฑููุฒ ุฎุงุตุฉ: '\n",
      "   'ยซูุต ุจูู ุฃููุงุณยป'\n",
      "   -> 'ูุต ุจูู ุฃููุงุณ'\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ุงููุนุงูุฌุฉ 3.4: ุฅุฒุงูุฉ ุงูุญุฑูู ุฎุงุฑุฌ ุงููุทุงู (OOV)\n",
    "# ============================================================================\n",
    "\n",
    "def build_valid_charset() -> set:\n",
    "    \"\"\"\n",
    "    ุจูุงุก ูุฌููุนุฉ ุงูุญุฑูู ุงูุตุงูุญุฉ ููููุฉ ุงูุชุฑููู ุงูุนุฑุจู.\n",
    "    \n",
    "    ุชุดูู:\n",
    "    - ุงูุญุฑูู ุงูุนุฑุจูุฉ (ุงูุฃุณุงุณูุฉ + ุงูููุณุนุฉ)\n",
    "    - ุงูุฃุฑูุงู ุงูุนุฑุจูุฉ\n",
    "    - ุนูุงูุงุช ุงูุชุฑููู ุงูุตุงูุญุฉ\n",
    "    - ุงููุณุงูุงุช\n",
    "    \n",
    "    ุชุฑุฌุน:\n",
    "    --------\n",
    "    set\n",
    "        ูุฌููุนุฉ ุงูุญุฑูู ุงูุตุงูุญุฉ\n",
    "    \"\"\"\n",
    "    valid = set()\n",
    "    \n",
    "    # ุงูุญุฑูู ุงูุนุฑุจูุฉ (ุฃุณุงุณูุฉ + ููุณุนุฉ)\n",
    "    valid.update('ุกุขุฃุคุฅุฆุงุจุฉุชุซุฌุญุฎุฏุฐุฑุฒุณุดุตุถุทุธุนุบููููููููู')\n",
    "    valid.update('ููพฺฺฺฏฺค')  # ููุณุนุฉ\n",
    "    \n",
    "    # ุงูุฃุฑูุงู ุงูุนุฑุจูุฉ\n",
    "    valid.update('ููกูขูฃูคูฅูฆูงูจูฉ')\n",
    "    \n",
    "    # ุนูุงูุงุช ุงูุชุฑููู ุงูุตุงูุญุฉ\n",
    "    valid.update('ุุุ.:!')\n",
    "    \n",
    "    # ุญุฑูู ูููููุฉ ุฃุณุงุณูุฉ\n",
    "    valid.update(' ')  # ูุณุงูุฉ\n",
    "    \n",
    "    # ุฅุจูุงุก ุจุนุถ ุงูุฃููุงุณ ููููููุฉ (ุณุชุนุงูุฌ ูุงุญูุงู ุฅุฐุง ูุฒู)\n",
    "    valid.update('()[]')\n",
    "    \n",
    "    return valid\n",
    "\n",
    "\n",
    "VALID_CHARSET = build_valid_charset()\n",
    "\n",
    "\n",
    "def remove_oov_characters(text: str, valid_chars: set = None, replacement: str = '') -> str:\n",
    "    \"\"\"\n",
    "    ุฅุฒุงูุฉ ุงูุญุฑูู ุบูุฑ ุงูููุฌูุฏุฉ ูู ูุฌููุนุฉ ุงูุญุฑูู ุงูุตุงูุญุฉ.\n",
    "    \n",
    "    ุงููุนุงููุงุช:\n",
    "    -----------\n",
    "    text : str\n",
    "        ุงููุต ุงููุฏุฎู\n",
    "    valid_chars : set\n",
    "        ูุฌููุนุฉ ุงูุญุฑูู ุงูุตุงูุญุฉ (ูุณุชุฎุฏู VALID_CHARSET ุฅุฐุง None)\n",
    "    replacement : str\n",
    "        ุงูุญุฑู ุงูุจุฏูู ููุญุฑูู ุงููุญุฐููุฉ (ุงูุงูุชุฑุงุถู: ุฅุฒุงูุฉ)\n",
    "        \n",
    "    ุชุฑุฌุน:\n",
    "    --------\n",
    "    str\n",
    "        ุงููุต ุจุนุฏ ุฅุฒุงูุฉ ุงูุญุฑูู ุบูุฑ ุงูุตุงูุญุฉ\n",
    "    \"\"\"\n",
    "    if valid_chars is None:\n",
    "        valid_chars = VALID_CHARSET\n",
    "    \n",
    "    result = []\n",
    "    for char in text:\n",
    "        if char in valid_chars:\n",
    "            result.append(char)\n",
    "        elif replacement:\n",
    "            result.append(replacement)\n",
    "    \n",
    "    return ''.join(result)\n",
    "\n",
    "\n",
    "# ุงุฎุชุจุงุฑ ุงูุฏุงูุฉ\n",
    "logger.section(\"๐ง ุงููุนุงูุฌุฉ ุงููุณุจูุฉ: ุฅุฒุงูุฉ ุงูุญุฑูู ุฎุงุฑุฌ ุงููุทุงู\")\n",
    "\n",
    "test_cases = [\n",
    "    \"ุงููุต ุงูุนุฑุจู ูุน English text\",\n",
    "    \"ุฑูู: ูกูขูฃ ู 456\",\n",
    "    \"ูุน ุฑููุฒ ุฎุงุตุฉ: @#$%\",\n",
    "    \"ยซูุต ุจูู ุฃููุงุณยป\",\n",
    "]\n",
    "\n",
    "logger.info(f\"ุญุฌู ูุฌููุนุฉ ุงูุญุฑูู ุงูุตุงูุญุฉ: {len(VALID_CHARSET)}\")\n",
    "logger.info(\"ุญุงูุงุช ุงูุงุฎุชุจุงุฑ:\")\n",
    "for test in test_cases:\n",
    "    result = remove_oov_characters(test)\n",
    "    logger.info(f\"   '{test}'\")\n",
    "    logger.info(f\"   -> '{result}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e656c9c",
   "metadata": {},
   "source": [
    "### 3.5 ุฅุฒุงูุฉ ุงูุญุฑูู ุงููุงุชูููุฉ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef4a4aad",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "๐ง ุงููุนุงูุฌุฉ ุงููุณุจูุฉ: ุฅุฒุงูุฉ ุงูุญุฑูู ุงููุงุชูููุฉ\n",
      "======================================================================\n",
      "ุญุงูุงุช ุงูุงุฎุชุจุงุฑ:\n",
      "   'ุงูุฃูู ุงููุชุญุฏุฉ United Nations' -> 'ุงูุฃูู ุงููุชุญุฏุฉ  '\n",
      "   'ุงููุซููุฉ A/47/10' -> 'ุงููุซููุฉ /47/10'\n",
      "   'ุจุฑูุงูุฌ UNDP ููุชูููุฉ' -> 'ุจุฑูุงูุฌ  ููุชูููุฉ'\n",
      "   'add. 1' -> '. 1'\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ุงููุนุงูุฌุฉ 3.5: ุฅุฒุงูุฉ ุงูุญุฑูู ุงููุงุชูููุฉ\n",
    "# ============================================================================\n",
    "\n",
    "LATIN_PATTERN = re.compile(r'[A-Za-z]+')\n",
    "\n",
    "def remove_latin_letters(text: str, replacement: str = '') -> str:\n",
    "    \"\"\"\n",
    "    ุฅุฒุงูุฉ ุงูุญุฑูู ุงููุงุชูููุฉ ูู ุงููุต.\n",
    "    \n",
    "    ูุนุงูุฌ:\n",
    "    - ุงููููุงุช ุงูุฅูุฌููุฒูุฉ ุงูููุฑุฏุฉ\n",
    "    - ูุฑุงุฌุน ุงููุณุชูุฏุงุช (A/47/10 -> /47/10)\n",
    "    - ุงููุต ุงููุฎุชูุท\n",
    "    \n",
    "    ุงููุนุงููุงุช:\n",
    "    -----------\n",
    "    text : str\n",
    "        ุงููุต ุงููุฏุฎู\n",
    "    replacement : str\n",
    "        ุจุฏูู ููุชุชุงุจุนุงุช ุงููุงุชูููุฉ (ุงูุงูุชุฑุงุถู: ุฅุฒุงูุฉ)\n",
    "        \n",
    "    ุชุฑุฌุน:\n",
    "    --------\n",
    "    str\n",
    "        ุงููุต ุจุฏูู ุญุฑูู ูุงุชูููุฉ\n",
    "    \"\"\"\n",
    "    return LATIN_PATTERN.sub(replacement, text)\n",
    "\n",
    "\n",
    "# ุงุฎุชุจุงุฑ ุงูุฏุงูุฉ\n",
    "logger.section(\"๐ง ุงููุนุงูุฌุฉ ุงููุณุจูุฉ: ุฅุฒุงูุฉ ุงูุญุฑูู ุงููุงุชูููุฉ\")\n",
    "\n",
    "test_cases = [\n",
    "    \"ุงูุฃูู ุงููุชุญุฏุฉ United Nations\",\n",
    "    \"ุงููุซููุฉ A/47/10\",\n",
    "    \"ุจุฑูุงูุฌ UNDP ููุชูููุฉ\",\n",
    "    \"add. 1\",\n",
    "]\n",
    "\n",
    "logger.info(\"ุญุงูุงุช ุงูุงุฎุชุจุงุฑ:\")\n",
    "for test in test_cases:\n",
    "    result = remove_latin_letters(test)\n",
    "    logger.info(f\"   '{test}' -> '{result}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a94e6b2",
   "metadata": {},
   "source": [
    "### 3.6 ุชูุญูุฏ ุงูุฃุฑูุงู (ุงูุฃุฑูุงู ุงูุนุฑุจูุฉ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8412c040",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "๐ง ุงููุนุงูุฌุฉ ุงููุณุจูุฉ: ุชูุญูุฏ ุงูุฃุฑูุงู\n",
      "======================================================================\n",
      "ุญุงูุงุช ุงูุงุฎุชุจุงุฑ (-> ุฃุฑูุงู ุนุฑุจูุฉ):\n",
      "   'ุนุงู 2024' -> 'ุนุงู ูขููขูค'\n",
      "   'ุฑูู ูกูขูฃ' -> 'ุฑูู ูกูขูฃ'\n",
      "   'ูุจูุบ 100 ุฏููุงุฑ' -> 'ูุจูุบ ูกูู ุฏููุงุฑ'\n",
      "   'ูฅูู + 500 = ูกููู' -> 'ูฅูู + ูฅูู = ูกููู'\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ุงููุนุงูุฌุฉ 3.6: ุชูุญูุฏ ุงูุฃุฑูุงู ููุนุฑุจูุฉ\n",
    "# ============================================================================\n",
    "\n",
    "def unify_numbers_to_arabic(text: str) -> str:\n",
    "    \"\"\"\n",
    "    ุชุญููู ุฌููุน ุงูุฃุฑูุงู ุงูุบุฑุจูุฉ (0-9) ุฅูู ุฃุฑูุงู ุนุฑุจูุฉ (ู-ูฉ).\n",
    "    \n",
    "    ุงููุนุงููุงุช:\n",
    "    -----------\n",
    "    text : str\n",
    "        ุงููุต ุงููุฏุฎู\n",
    "        \n",
    "    ุชุฑุฌุน:\n",
    "    --------\n",
    "    str\n",
    "        ุงููุต ุจุฃุฑูุงู ุนุฑุจูุฉ ููุท\n",
    "        \n",
    "    ูุซุงู:\n",
    "    --------\n",
    "    >>> unify_numbers_to_arabic(\"ุนุงู 2024\")\n",
    "    'ุนุงู ูขููขูค'\n",
    "    \"\"\"\n",
    "    return text.translate(WESTERN_TO_ARABIC_NUMS)\n",
    "\n",
    "\n",
    "def unify_numbers_to_western(text: str) -> str:\n",
    "    \"\"\"\n",
    "    ุชุญููู ุฌููุน ุงูุฃุฑูุงู ุงูุนุฑุจูุฉ (ู-ูฉ) ุฅูู ุฃุฑูุงู ุบุฑุจูุฉ (0-9).\n",
    "    \n",
    "    ููุฌ ุจุฏูู - ุจุนุถ ุงูููุงุฐุฌ ุชูุถู ุงูุฃุฑูุงู ุงูุบุฑุจูุฉ.\n",
    "    \n",
    "    ุงููุนุงููุงุช:\n",
    "    -----------\n",
    "    text : str\n",
    "        ุงููุต ุงููุฏุฎู\n",
    "        \n",
    "    ุชุฑุฌุน:\n",
    "    --------\n",
    "    str\n",
    "        ุงููุต ุจุฃุฑูุงู ุบุฑุจูุฉ ููุท\n",
    "    \"\"\"\n",
    "    return text.translate(ARABIC_TO_WESTERN_NUMS)\n",
    "\n",
    "\n",
    "# ุงุฎุชุจุงุฑ ุงูุฏุงูุฉ\n",
    "logger.section(\"๐ง ุงููุนุงูุฌุฉ ุงููุณุจูุฉ: ุชูุญูุฏ ุงูุฃุฑูุงู\")\n",
    "\n",
    "test_cases = [\n",
    "    \"ุนุงู 2024\",\n",
    "    \"ุฑูู ูกูขูฃ\",\n",
    "    \"ูุจูุบ 100 ุฏููุงุฑ\",\n",
    "    \"ูฅูู + 500 = ูกููู\",\n",
    "]\n",
    "\n",
    "logger.info(\"ุญุงูุงุช ุงูุงุฎุชุจุงุฑ (-> ุฃุฑูุงู ุนุฑุจูุฉ):\")\n",
    "for test in test_cases:\n",
    "    result = unify_numbers_to_arabic(test)\n",
    "    logger.info(f\"   '{test}' -> '{result}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e0b8f1",
   "metadata": {},
   "source": [
    "### 3.7 ุชูุญูุฏ ุนูุงูุงุช ุงูุชุฑููู (ุงูุชุฑููู ุงูุนุฑุจู)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30bca179",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "๐ง ุงููุนุงูุฌุฉ ุงููุณุจูุฉ: ุชูุญูุฏ ุงูุชุฑููู\n",
      "======================================================================\n",
      "ุญุงูุงุช ุงูุงุฎุชุจุงุฑ:\n",
      "   'ุฃููุงู, ุซุงููุงู, ุซุงูุซุงู'\n",
      "   -> 'ุฃููุงูุ ุซุงููุงูุ ุซุงูุซุงู'\n",
      "   'ูู ูุฐุง ุตุญูุญ?'\n",
      "   -> 'ูู ูุฐุง ุตุญูุญุ'\n",
      "   'ููุงุญุธุฉ; ูุฐุง ููู'\n",
      "   -> 'ููุงุญุธุฉุ ูุฐุง ููู'\n",
      "   'ุงููุต ูุญุชูู ุนูู , ู ; ู ?'\n",
      "   -> 'ุงููุต ูุญุชูู ุนูู ุ ู ุ ู ุ'\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ุงููุนุงูุฌุฉ 3.7: ุชูุญูุฏ ุงูุชุฑููู ููุนุฑุจู\n",
    "# ============================================================================\n",
    "\n",
    "def unify_punctuation_to_arabic(text: str) -> str:\n",
    "    \"\"\"\n",
    "    ุชุญููู ุนูุงูุงุช ุงูุชุฑููู ุงููุงุชูููุฉ ุฅูู ูุธูุฑุงุชูุง ุงูุนุฑุจูุฉ.\n",
    "    \n",
    "    ุงูุชุญูููุงุช:\n",
    "    - , -> ุ  (ูุงุตูุฉ)\n",
    "    - ; -> ุ  (ูุงุตูุฉ ููููุทุฉ)\n",
    "    - ? -> ุ  (ุนูุงูุฉ ุงุณุชููุงู)\n",
    "    \n",
    "    ููุงุญุธุฉ: ุงูููุทุฉ (.)ุ ุงูููุทุชุงู (:)ุ ูุงูุชุนุฌุจ (!) ุชุจูู ููุง ูู\n",
    "    ูุฃููุง ูุดุชุฑูุฉ ูู ุงููุธุงููู.\n",
    "    \n",
    "    ุงููุนุงููุงุช:\n",
    "    -----------\n",
    "    text : str\n",
    "        ุงููุต ุงููุฏุฎู\n",
    "        \n",
    "    ุชุฑุฌุน:\n",
    "    --------\n",
    "    str\n",
    "        ุงููุต ุจุชุฑููู ุนุฑุจู\n",
    "    \"\"\"\n",
    "    for latin, arabic in LATIN_TO_ARABIC_PUNCT.items():\n",
    "        text = text.replace(latin, arabic)\n",
    "    return text\n",
    "\n",
    "\n",
    "# ุงุฎุชุจุงุฑ ุงูุฏุงูุฉ\n",
    "logger.section(\"๐ง ุงููุนุงูุฌุฉ ุงููุณุจูุฉ: ุชูุญูุฏ ุงูุชุฑููู\")\n",
    "\n",
    "test_cases = [\n",
    "    \"ุฃููุงู, ุซุงููุงู, ุซุงูุซุงู\",\n",
    "    \"ูู ูุฐุง ุตุญูุญ?\",\n",
    "    \"ููุงุญุธุฉ; ูุฐุง ููู\",\n",
    "    \"ุงููุต ูุญุชูู ุนูู , ู ; ู ?\",\n",
    "]\n",
    "\n",
    "logger.info(\"ุญุงูุงุช ุงูุงุฎุชุจุงุฑ:\")\n",
    "for test in test_cases:\n",
    "    result = unify_punctuation_to_arabic(test)\n",
    "    logger.info(f\"   '{test}'\")\n",
    "    logger.info(f\"   -> '{result}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7def2d",
   "metadata": {},
   "source": [
    "### 3.8 ูุนุงูุฌุฉ ุงูุชุฑููู ุงููุชุชุงุจุน"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12f71e88",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "๐ง ุงููุนุงูุฌุฉ ุงููุณุจูุฉ: ูุนุงูุฌุฉ ุงูุชุฑููู ุงููุชุชุงุจุน\n",
      "======================================================================\n",
      "ุญุงูุงุช ุงูุงุฎุชุจุงุฑ:\n",
      "   'ูุงุฐุงุุุ'\n",
      "      ุฅุจูุงุก ุงูุฃููู: 'ูุงุฐุงุ'\n",
      "      ุฐูู:          'ูุงุฐุงุ'\n",
      "   'ูุฐุง ุตุญูุญ..'\n",
      "      ุฅุจูุงุก ุงูุฃููู: 'ูุฐุง ุตุญูุญ.'\n",
      "      ุฐูู:          'ูุฐุง ุตุญูุญ.'\n",
      "   'ุฃููุงูุุ'\n",
      "      ุฅุจูุงุก ุงูุฃููู: 'ุฃููุงูุ'\n",
      "      ุฐูู:          'ุฃููุงูุ'\n",
      "   'ุงูุชูู.ุ'\n",
      "      ุฅุจูุงุก ุงูุฃููู: 'ุงูุชูู.'\n",
      "      ุฐูู:          'ุงูุชูู.'\n",
      "   'ููุงูุฉ ุงููุต.,'\n",
      "      ุฅุจูุงุก ุงูุฃููู: 'ููุงูุฉ ุงููุต.'\n",
      "      ุฐูู:          'ููุงูุฉ ุงููุต.'\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ุงููุนุงูุฌุฉ 3.8: ูุนุงูุฌุฉ ุงูุชุฑููู ุงููุชุชุงุจุน\n",
    "# ============================================================================\n",
    "\n",
    "def handle_consecutive_punctuation(text: str, keep_first: bool = True) -> str:\n",
    "    \"\"\"\n",
    "    ูุนุงูุฌุฉ ุนูุงูุงุช ุงูุชุฑููู ุงููุชุชุงุจุนุฉ.\n",
    "    \n",
    "    ุงูุงุณุชุฑุงุชูุฌูุงุช:\n",
    "    - keep_first: ุฅุจูุงุก ุงูุนูุงูุฉ ุงูุฃููู ูุญุฐู ุงูุจุงูู\n",
    "    - keep_last: ุฅุจูุงุก ุงูุนูุงูุฉ ุงูุฃุฎูุฑุฉ ูุญุฐู ุงูุจุงูู\n",
    "    \n",
    "    ุงููุนุงููุงุช:\n",
    "    -----------\n",
    "    text : str\n",
    "        ุงููุต ุงููุฏุฎู\n",
    "    keep_first : bool\n",
    "        ุฅุฐุง Trueุ ุงุญุชูุธ ุจุงูุฃููู\n",
    "        \n",
    "    ุชุฑุฌุน:\n",
    "    --------\n",
    "    str\n",
    "        ุงููุต ุจุนุฏ ูุนุงูุฌุฉ ุงูุชุชุงุจุน\n",
    "    \"\"\"\n",
    "    # ููุท ูุทุงุจู 2 ุฃู ุฃูุซุฑ ูู ุนูุงูุงุช ุงูุชุฑููู ุงููุชุชุงุจุนุฉ\n",
    "    punct_chars = r'ุุุ.,:;?!'\n",
    "    pattern = re.compile(f'([{punct_chars}])([{punct_chars}]+)')\n",
    "    \n",
    "    if keep_first:\n",
    "        # ุฅุจูุงุก ุงูุฃููู\n",
    "        return pattern.sub(r'\\1', text)\n",
    "    else:\n",
    "        # ุฅุจูุงุก ุงูุฃุฎูุฑุฉ\n",
    "        def keep_last_match(m):\n",
    "            return m.group(0)[-1]\n",
    "        return pattern.sub(keep_last_match, text)\n",
    "\n",
    "\n",
    "def handle_consecutive_punctuation_smart(text: str) -> str:\n",
    "    \"\"\"\n",
    "    ูุนุงูุฌุฉ ุฐููุฉ ููุชุฑููู ุงููุชุชุงุจุน.\n",
    "    \n",
    "    ุชุณุชุฎุฏู ุงูุฃููููุฉ: . > ุ > ! > ุ > ุ > :\n",
    "    ุชุญุชูุธ ุจุงูุนูุงูุฉ ุฐุงุช ุงูุฃููููุฉ ุงูุฃุนูู.\n",
    "    \n",
    "    ุงููุนุงููุงุช:\n",
    "    -----------\n",
    "    text : str\n",
    "        ุงููุต ุงููุฏุฎู\n",
    "        \n",
    "    ุชุฑุฌุน:\n",
    "    --------\n",
    "    str\n",
    "        ุงููุต ุจุนุฏ ุงุฎุชุฒุงู ุงูุชุฑููู\n",
    "    \"\"\"\n",
    "    # ุชุฑุชูุจ ุงูุฃููููุฉ (ุงูุฃุนูู ุฃููุงู)\n",
    "    priority = {'.': 6, 'ุ': 5, '?': 5, '!': 4, 'ุ': 3, ';': 3, 'ุ': 2, ',': 2, ':': 1}\n",
    "    \n",
    "    punct_chars = r'ุุุ.,:;?!'\n",
    "    pattern = re.compile(f'[{punct_chars}]{{2,}}')\n",
    "    \n",
    "    def replace_func(match):\n",
    "        sequence = match.group(0)\n",
    "        # ุฅูุฌุงุฏ ุงูุนูุงูุฉ ุฐุงุช ุงูุฃููููุฉ ุงูุฃุนูู\n",
    "        best_char = sequence[0]\n",
    "        best_priority = priority.get(best_char, 0)\n",
    "        \n",
    "        for char in sequence:\n",
    "            char_priority = priority.get(char, 0)\n",
    "            if char_priority > best_priority:\n",
    "                best_char = char\n",
    "                best_priority = char_priority\n",
    "        \n",
    "        return best_char\n",
    "    \n",
    "    return pattern.sub(replace_func, text)\n",
    "\n",
    "\n",
    "# ุงุฎุชุจุงุฑ ุงูุฏุงูุฉ\n",
    "logger.section(\"๐ง ุงููุนุงูุฌุฉ ุงููุณุจูุฉ: ูุนุงูุฌุฉ ุงูุชุฑููู ุงููุชุชุงุจุน\")\n",
    "\n",
    "test_cases = [\n",
    "    \"ูุงุฐุงุุุ\",\n",
    "    \"ูุฐุง ุตุญูุญ..\",\n",
    "    \"ุฃููุงูุุ\",\n",
    "    \"ุงูุชูู.ุ\",\n",
    "    \"ููุงูุฉ ุงููุต.,\",\n",
    "]\n",
    "\n",
    "logger.info(\"ุญุงูุงุช ุงูุงุฎุชุจุงุฑ:\")\n",
    "for test in test_cases:\n",
    "    result_first = handle_consecutive_punctuation(test, keep_first=True)\n",
    "    result_smart = handle_consecutive_punctuation_smart(test)\n",
    "    logger.info(f\"   '{test}'\")\n",
    "    logger.info(f\"      ุฅุจูุงุก ุงูุฃููู: '{result_first}'\")\n",
    "    logger.info(f\"      ุฐูู:          '{result_smart}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2783b0b",
   "metadata": {},
   "source": [
    "### 3.9 ุชูุญูุฏ ุงููุณุงูุงุช ูุถุจุท ูุณุงูุงุช ุงูุชุฑููู"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ee5d838",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "๐ง ุงููุนุงูุฌุฉ ุงููุณุจูุฉ: ุชูุญูุฏ ุงููุณุงูุงุช ูุถุจุท ุงูุชุฑููู\n",
      "======================================================================\n",
      "ุญุงูุงุช ุงูุงุฎุชุจุงุฑ:\n",
      "   'ุงููุต   ูุน   ูุณุงูุงุช    ูุซูุฑุฉ'\n",
      "      ุจุนุฏ ุชูุญูุฏ ุงููุณุงูุงุช: 'ุงููุต ูุน ูุณุงูุงุช ูุซูุฑุฉ'\n",
      "      ุจุนุฏ ุถุจุท ุงูุชุฑููู:    'ุงููุต ูุน ูุณุงูุงุช ูุซูุฑุฉ'\n",
      "   'ูููุฉุูููุฉ'\n",
      "      ุจุนุฏ ุชูุญูุฏ ุงููุณุงูุงุช: 'ูููุฉุูููุฉ'\n",
      "      ุจุนุฏ ุถุจุท ุงูุชุฑููู:    'ูููุฉุ ูููุฉ'\n",
      "   'ูุต .ูุน ูุณุงูุฉ ูุจู ุงูููุทุฉ'\n",
      "      ุจุนุฏ ุชูุญูุฏ ุงููุณุงูุงุช: 'ูุต .ูุน ูุณุงูุฉ ูุจู ุงูููุทุฉ'\n",
      "      ุจุนุฏ ุถุจุท ุงูุชุฑููู:    'ูุต. ูุน ูุณุงูุฉ ูุจู ุงูููุทุฉ'\n",
      "   'ุณุคุงูุุฌูุงุจ'\n",
      "      ุจุนุฏ ุชูุญูุฏ ุงููุณุงูุงุช: 'ุณุคุงูุุฌูุงุจ'\n",
      "      ุจุนุฏ ุถุจุท ุงูุชุฑููู:    'ุณุคุงูุ ุฌูุงุจ'\n",
      "   'ุฃููุงู ุ ุซุงููุงู ุ ุซุงูุซุงู'\n",
      "      ุจุนุฏ ุชูุญูุฏ ุงููุณุงูุงุช: 'ุฃููุงู ุ ุซุงููุงู ุ ุซุงูุซุงู'\n",
      "      ุจุนุฏ ุถุจุท ุงูุชุฑููู:    'ุฃููุงูุ ุซุงููุงูุ ุซุงูุซุงู'\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ุงููุนุงูุฌุฉ 3.9: ุชูุญูุฏ ุงููุณุงูุงุช ูุถุจุท ูุณุงูุงุช ุงูุชุฑููู\n",
    "# ============================================================================\n",
    "\n",
    "def normalize_whitespace(text: str) -> str:\n",
    "    \"\"\"\n",
    "    ุชูุญูุฏ ุงููุณุงูุงุช ูู ุงููุต.\n",
    "    \n",
    "    - ุงุณุชุจุฏุงู ุงููุณุงูุงุช ุงููุชุนุฏุฏุฉ ุจูุณุงูุฉ ูุงุญุฏุฉ\n",
    "    - ุฅุฒุงูุฉ ุงููุณุงูุงุช ูู ุงูุจุฏุงูุฉ ูุงูููุงูุฉ\n",
    "    - ุงุณุชุจุฏุงู ุนูุงูุงุช ุงูุฌุฏููุฉ (tabs) ุจูุณุงูุงุช\n",
    "    \n",
    "    ุงููุนุงููุงุช:\n",
    "    -----------\n",
    "    text : str\n",
    "        ุงููุต ุงููุฏุฎู\n",
    "        \n",
    "    ุชุฑุฌุน:\n",
    "    --------\n",
    "    str\n",
    "        ุงููุต ุจูุณุงูุงุช ููุญุฏุฉ\n",
    "    \"\"\"\n",
    "    # ุงุณุชุจุฏุงู tabs ุจูุณุงูุงุช\n",
    "    text = text.replace('\\t', ' ')\n",
    "    \n",
    "    # ุงุณุชุจุฏุงู ุงููุณุงูุงุช ุงููุชุนุฏุฏุฉ\n",
    "    text = re.sub(r' +', ' ', text)\n",
    "    \n",
    "    # ุฅุฒุงูุฉ ูุณุงูุงุช ุงูุจุฏุงูุฉ ูุงูููุงูุฉ\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def add_punctuation_spacing(text: str) -> str:\n",
    "    \"\"\"\n",
    "    ุถูุงู ูุฌูุฏ ูุณุงูุงุช ุตุญูุญุฉ ุญูู ุนูุงูุงุช ุงูุชุฑููู.\n",
    "    \n",
    "    ุงูููุงุนุฏ:\n",
    "    - ูุณุงูุฉ ุจุนุฏ ุนูุงูุฉ ุงูุชุฑููู (ุฅุฐุง ุชุจุนูุง ุญุฑู/ุฑูู)\n",
    "    - ูุง ูุณุงูุฉ ูุจู ุนูุงูุฉ ุงูุชุฑููู\n",
    "    \n",
    "    ุงููุนุงููุงุช:\n",
    "    -----------\n",
    "    text : str\n",
    "        ุงููุต ุงููุฏุฎู\n",
    "        \n",
    "    ุชุฑุฌุน:\n",
    "    --------\n",
    "    str\n",
    "        ุงููุต ุจูุณุงูุงุช ุชุฑููู ุตุญูุญุฉ\n",
    "    \"\"\"\n",
    "    punct_marks = 'ุุุ.:!'\n",
    "    \n",
    "    # ุฅุฒุงูุฉ ุงููุณุงูุฉ ูุจู ุงูุชุฑููู\n",
    "    for p in punct_marks:\n",
    "        text = re.sub(rf'\\s+{re.escape(p)}', p, text)\n",
    "    \n",
    "    # ุฅุถุงูุฉ ูุณุงูุฉ ุจุนุฏ ุงูุชุฑููู ุฅุฐุง ุชุจุนู ุญุฑู ุฃู ุฑูู ุนุฑุจู\n",
    "    for p in punct_marks:\n",
    "        # ุจุนุฏ ุงูุชุฑูููุ ุฅุฐุง ุชุจุนู ุญุฑู ุนุฑุจู ุจุฏูู ูุณุงูุฉุ ุฃุถู ูุณุงูุฉ\n",
    "        text = re.sub(\n",
    "            rf'{re.escape(p)}([\\u0600-\\u06FFู-ูฉ])',\n",
    "            rf'{p} \\1',\n",
    "            text\n",
    "        )\n",
    "    \n",
    "    # ุชูุธูู ุงููุณุงูุงุช ุงููุชุนุฏุฏุฉ ุงูุชู ูุฏ ุชููู ูุดุฃุช\n",
    "    text = re.sub(r' +', ' ', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "# ุงุฎุชุจุงุฑ ุงูุฏูุงู\n",
    "logger.section(\"๐ง ุงููุนุงูุฌุฉ ุงููุณุจูุฉ: ุชูุญูุฏ ุงููุณุงูุงุช ูุถุจุท ุงูุชุฑููู\")\n",
    "\n",
    "test_cases = [\n",
    "    \"ุงููุต   ูุน   ูุณุงูุงุช    ูุซูุฑุฉ\",\n",
    "    \"ูููุฉุูููุฉ\",\n",
    "    \"ูุต .ูุน ูุณุงูุฉ ูุจู ุงูููุทุฉ\",\n",
    "    \"ุณุคุงูุุฌูุงุจ\",\n",
    "    \"ุฃููุงู ุ ุซุงููุงู ุ ุซุงูุซุงู\",\n",
    "]\n",
    "\n",
    "logger.info(\"ุญุงูุงุช ุงูุงุฎุชุจุงุฑ:\")\n",
    "for test in test_cases:\n",
    "    result_ws = normalize_whitespace(test)\n",
    "    result_spacing = add_punctuation_spacing(result_ws)\n",
    "    logger.info(f\"   '{test}'\")\n",
    "    logger.info(f\"      ุจุนุฏ ุชูุญูุฏ ุงููุณุงูุงุช: '{result_ws}'\")\n",
    "    logger.info(f\"      ุจุนุฏ ุถุจุท ุงูุชุฑููู:    '{result_spacing}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbaf8b2",
   "metadata": {},
   "source": [
    "### 3.10 ุฅุฒุงูุฉ ุงูุฃุณุทุฑ ุงููุงุฑุบุฉ ูุงููุตูุฑุฉ ุฌุฏุงู"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97294005",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "๐ง ุงููุนุงูุฌุฉ ุงููุณุจูุฉ: ุชุตููุฉ ุงูุฌูู ุงููุตูุฑุฉ/ุงููุงุฑุบุฉ\n",
      "======================================================================\n",
      "ุงูุญุฏ ุงูุฃุฏูู ูููููุงุช: 3\n",
      "ุญุงูุงุช ุงูุงุฎุชุจุงุฑ:\n",
      "   '' -> โ ุบูุฑ ุตุงูุญ\n",
      "   'ูุนู' -> โ ุบูุฑ ุตุงูุญ\n",
      "   'ุฃ' -> โ ุบูุฑ ุตุงูุญ\n",
      "   'ูุนู ูุง' -> โ ุบูุฑ ุตุงูุญ\n",
      "   'ูุฐุง ูุต ุตุญูุญ ูููุจูู' -> โ ุตุงูุญ\n",
      "   '   ' -> โ ุบูุฑ ุตุงูุญ\n",
      "   '1.' -> โ ุบูุฑ ุตุงูุญ\n",
      "   'ูุต ูุตูุฑ ุฌุฏุง' -> โ ุตุงูุญ\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ุงููุนุงูุฌุฉ 3.10: ุฅุฒุงูุฉ ุงูุฃุณุทุฑ ุงููุงุฑุบุฉ ูุงููุตูุฑุฉ\n",
    "# ============================================================================\n",
    "\n",
    "def is_valid_sentence(text: str, min_words: int = 3) -> bool:\n",
    "    \"\"\"\n",
    "    ุงูุชุญูู ููุง ุฅุฐุง ูุงูุช ุงูุฌููุฉ ุชุณุชููู ุงูุญุฏ ุงูุฃุฏูู ูู ุงููุชุทูุจุงุช.\n",
    "    \n",
    "    ุงููุนุงููุงุช:\n",
    "    -----------\n",
    "    text : str\n",
    "        ุงููุต ุงููุฏุฎู (ูุฌุจ ุฃู ูููู ูุนุงูุฌุงู ูุณุจูุงู)\n",
    "    min_words : int\n",
    "        ุงูุญุฏ ุงูุฃุฏูู ูููููุงุช\n",
    "        \n",
    "    ุชุฑุฌุน:\n",
    "    --------\n",
    "    bool\n",
    "        True ุฅุฐุง ูุงูุช ุงูุฌููุฉ ุตุงูุญุฉ\n",
    "    \"\"\"\n",
    "    # ุฅุฒุงูุฉ ุงููุณุงูุงุช\n",
    "    text = text.strip()\n",
    "    \n",
    "    # ุงูุชุญูู ูู ุงููุฑุงุบ\n",
    "    if not text:\n",
    "        return False\n",
    "    \n",
    "    # ุนุฏ ุงููููุงุช ุงูุนุฑุจูุฉ ููุท\n",
    "    arabic_words = re.findall(r'[\\u0600-\\u06FF]+', text)\n",
    "    \n",
    "    return len(arabic_words) >= min_words\n",
    "\n",
    "\n",
    "def filter_sentence(text: str, min_words: int = 3) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    ุชุตููุฉ ูุฅุฑุฌุงุน ุงูุฌููุฉ ุฅุฐุง ูุงูุช ุตุงูุญุฉุ ูุฅูุง None.\n",
    "    \n",
    "    ุงููุนุงููุงุช:\n",
    "    -----------\n",
    "    text : str\n",
    "        ุงููุต ุงููุฏุฎู\n",
    "    min_words : int\n",
    "        ุงูุญุฏ ุงูุฃุฏูู ูููููุงุช\n",
    "        \n",
    "    ุชุฑุฌุน:\n",
    "    --------\n",
    "    Optional[str]\n",
    "        ุงูุฌููุฉ ุฅุฐุง ูุงูุช ุตุงูุญุฉุ ูุฅูุง None\n",
    "    \"\"\"\n",
    "    if is_valid_sentence(text, min_words):\n",
    "        return text\n",
    "    return None\n",
    "\n",
    "\n",
    "# ุงุฎุชุจุงุฑ ุงูุฏุงูุฉ\n",
    "logger.section(\"๐ง ุงููุนุงูุฌุฉ ุงููุณุจูุฉ: ุชุตููุฉ ุงูุฌูู ุงููุตูุฑุฉ/ุงููุงุฑุบุฉ\")\n",
    "\n",
    "test_cases = [\n",
    "    \"\",\n",
    "    \"ูุนู\",\n",
    "    \"ุฃ\",\n",
    "    \"ูุนู ูุง\",\n",
    "    \"ูุฐุง ูุต ุตุญูุญ ูููุจูู\",\n",
    "    \"   \",\n",
    "    \"1.\",\n",
    "    \"ูุต ูุตูุฑ ุฌุฏุง\",\n",
    "]\n",
    "\n",
    "logger.info(f\"ุงูุญุฏ ุงูุฃุฏูู ูููููุงุช: {config.min_words}\")\n",
    "logger.info(\"ุญุงูุงุช ุงูุงุฎุชุจุงุฑ:\")\n",
    "for test in test_cases:\n",
    "    is_valid = is_valid_sentence(test, min_words=config.min_words)\n",
    "    status = \"โ ุตุงูุญ\" if is_valid else \"โ ุบูุฑ ุตุงูุญ\"\n",
    "    logger.info(f\"   '{test}' -> {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4971fea",
   "metadata": {},
   "source": [
    "### 3.11 ูุนุงูุฌุฉ ุงูุฌูู ุงูุทูููุฉ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "670d01f3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "๐ง ุงููุนุงูุฌุฉ ุงููุณุจูุฉ: ูุนุงูุฌุฉ ุงูุฌูู ุงูุทูููุฉ\n",
      "======================================================================\n",
      "ุงูุทูู ุงูุฃุตูู: 150 ูููุฉ\n",
      "ุจุนุฏ ุงููุต: 100 ูููุฉ\n",
      "ููุชูู ุจู: 'ูููุฉ ูููุฉ.'\n",
      "\n",
      "ุชู ุงูุชูุณูู ุฅูู 10 ููุทุน:\n",
      "   ุงูููุทุน 1: 26 ูููุฉ\n",
      "   ุงูููุทุน 2: 26 ูููุฉ\n",
      "   ุงูููุทุน 3: 26 ูููุฉ\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ุงููุนุงูุฌุฉ 3.11: ูุนุงูุฌุฉ ุงูุฌูู ุงูุทูููุฉ\n",
    "# ============================================================================\n",
    "\n",
    "def truncate_sentence(text: str, max_words: int = 100) -> str:\n",
    "    \"\"\"\n",
    "    ูุต ุงูุฌููุฉ ูุชูุงุณุจ ุงูุญุฏ ุงูุฃูุตู ูููููุงุช.\n",
    "    \n",
    "    ุงูุงุณุชุฑุงุชูุฌูุฉ: ุงููุต ุนูุฏ ุญุฏูุฏ ุงููููุงุชุ ูุญุงููุฉ ุงูุฅููุงุก ุจุนูุงูุฉ ุชุฑููู.\n",
    "    \n",
    "    ุงููุนุงููุงุช:\n",
    "    -----------\n",
    "    text : str\n",
    "        ุงููุต ุงููุฏุฎู\n",
    "    max_words : int\n",
    "        ุงูุญุฏ ุงูุฃูุตู ูููููุงุช\n",
    "        \n",
    "    ุชุฑุฌุน:\n",
    "    --------\n",
    "    str\n",
    "        ุงููุต ุงูููุตูุต\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    \n",
    "    if len(words) <= max_words:\n",
    "        return text\n",
    "    \n",
    "    # ุงููุต ุฅูู max_words\n",
    "    truncated_words = words[:max_words]\n",
    "    truncated = ' '.join(truncated_words)\n",
    "    \n",
    "    # ุถูุงู ุงูููุงูุฉ ุจุนูุงูุฉ ุชุฑููู\n",
    "    if truncated and truncated[-1] not in SENTENCE_TERMINALS:\n",
    "        truncated += '.'\n",
    "    \n",
    "    return truncated\n",
    "\n",
    "\n",
    "def split_long_sentence(text: str, max_words: int = 100) -> List[str]:\n",
    "    \"\"\"\n",
    "    ุชูุณูู ุงูุฌููุฉ ุงูุทูููุฉ ุฅูู ุฌูู ูุชุนุฏุฏุฉ ุนูุฏ ุงูุญุฏูุฏ ุงูุทุจูุนูุฉ.\n",
    "    \n",
    "    ุงูุงุณุชุฑุงุชูุฌูุฉ: ุงูุชูุณูู ุนูุฏ ุนูุงูุงุช ุงูุชุฑููู (ุุ) ุงูุชู ุชุฎูู ููุงุตู ุทุจูุนูุฉ.\n",
    "    \n",
    "    ุงููุนุงููุงุช:\n",
    "    -----------\n",
    "    text : str\n",
    "        ุงููุต ุงููุฏุฎู\n",
    "    max_words : int\n",
    "        ุงูุญุฏ ุงูุฃูุตู ูููููุงุช ููู ููุทุน\n",
    "        \n",
    "    ุชุฑุฌุน:\n",
    "    --------\n",
    "    List[str]\n",
    "        ูุงุฆูุฉ ุจููุงุทุน ุงูุฌููุฉ\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    \n",
    "    if len(words) <= max_words:\n",
    "        return [text]\n",
    "    \n",
    "    # ุฅูุฌุงุฏ ููุงุท ุงููุตู ุงููุญุชููุฉ (ุจุนุฏ ุ ุฃู ุ)\n",
    "    segments = []\n",
    "    current_segment = []\n",
    "    word_count = 0\n",
    "    \n",
    "    for word in words:\n",
    "        current_segment.append(word)\n",
    "        word_count += 1\n",
    "        \n",
    "        # ุชุญูู ุฅุฐุง ูุงูุช ุงููููุฉ ุชูุชูู ุจูุงุตูุฉ ูุชุฌุงูุฒูุง ุงูููุชุตู\n",
    "        if word_count >= max_words // 2:\n",
    "            if word.endswith('ุ') or word.endswith('ุ'):\n",
    "                # ุฅูุดุงุก ููุทุน\n",
    "                segment_text = ' '.join(current_segment)\n",
    "                segments.append(segment_text)\n",
    "                current_segment = []\n",
    "                word_count = 0\n",
    "        \n",
    "        # ุฅุฌุจุงุฑ ุงูุชูุณูู ุฅุฐุง ูุตููุง ููุญุฏ ุงูุฃูุตู\n",
    "        if word_count >= max_words:\n",
    "            segment_text = ' '.join(current_segment)\n",
    "            if not segment_text.endswith(('.', 'ุ', '!')):\n",
    "                segment_text += '.'\n",
    "            segments.append(segment_text)\n",
    "            current_segment = []\n",
    "            word_count = 0\n",
    "    \n",
    "    # ุฅุถุงูุฉ ุงููุชุจูู\n",
    "    if current_segment:\n",
    "        segment_text = ' '.join(current_segment)\n",
    "        segments.append(segment_text)\n",
    "    \n",
    "    return segments\n",
    "\n",
    "\n",
    "# ุงุฎุชุจุงุฑ ุงูุฏูุงู\n",
    "logger.section(\"๐ง ุงููุนุงูุฌุฉ ุงููุณุจูุฉ: ูุนุงูุฌุฉ ุงูุฌูู ุงูุทูููุฉ\")\n",
    "\n",
    "# ุฅูุดุงุก ุฌููุฉ ุทูููุฉ ููุงุฎุชุจุงุฑ\n",
    "long_sentence = \" \".join([\"ูููุฉ\"] * 150)\n",
    "logger.info(f\"ุงูุทูู ุงูุฃุตูู: {len(long_sentence.split())} ูููุฉ\")\n",
    "\n",
    "truncated = truncate_sentence(long_sentence, max_words=100)\n",
    "logger.info(f\"ุจุนุฏ ุงููุต: {len(truncated.split())} ูููุฉ\")\n",
    "logger.info(f\"ููุชูู ุจู: '{truncated[-10:]}'\")\n",
    "\n",
    "# ุงุฎุชุจุงุฑ ุงูููุงุตู ุงูุทุจูุนูุฉ\n",
    "long_with_punct = \"ูุฐุง ูุต ุทููู ูุญุชูู ุนูู ููุฑุงุช ูุชุนุฏุฏุฉุ ููู ููุฑุฉ ุชุญุชูู ุนูู ูุนูููุงุช ูููุฉุ \" * 20\n",
    "segments = split_long_sentence(long_with_punct, max_words=50)\n",
    "logger.info(f\"\\nุชู ุงูุชูุณูู ุฅูู {len(segments)} ููุทุน:\")\n",
    "for i, seg in enumerate(segments[:3]):\n",
    "    logger.info(f\"   ุงูููุทุน {i+1}: {len(seg.split())} ูููุฉ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedc094f",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. ุงูุฌุฒุก 3: ุฎุทูุงุช ุงููุนุงูุฌุฉ ุงูุงุฎุชูุงุฑูุฉ (ููุชุฌุฑูุจ)\n",
    "\n",
    "ูุฐู ุงูุฎุทูุงุช **ุงุฎุชูุงุฑูุฉ** ููููู ุชูุนูููุง ููุชุฌุฑูุจ.\n",
    "ูุฏ ุชุญุณู ุฃู ุชุถุฑ ุจุฃุฏุงุก ุงููููุฐุฌ ุญุณุจ ุงููููุฉ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9688e677",
   "metadata": {},
   "source": [
    "### 4.1 ูุตู ูุงู ุงูุนุทู ุนู ุงููููุงุช"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a26ef9c2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "๐ง ุงุฎุชูุงุฑู: ูุตู ูุงู ุงูุนุทู\n",
      "======================================================================\n",
      "ุญุงูุงุช ุงูุงุฎุชุจุงุฑ:\n",
      "   'ููุงู ุงูุฑุฌู'\n",
      "   -> 'ู ูุงู ุงูุฑุฌู'\n",
      "   'ูุงูุฃูู ุงููุชุญุฏุฉ'\n",
      "   -> 'ู ุงูุฃูู ุงููุชุญุฏุฉ'\n",
      "   'ููู ูุฐุง ุงูุตุฏุฏ'\n",
      "   -> 'ููู ูุฐุง ุงูุตุฏุฏ'\n",
      "   'ููุช ุงูุงุฌุชูุงุน'\n",
      "   -> 'ููุช ุงูุงุฌุชูุงุน'\n",
      "   'ูุซููุฉ ูููุฉ'\n",
      "   -> 'ูุซููุฉ ูููุฉ'\n",
      "   'ูุงูุชูููุฉ ุงููุณุชุฏุงูุฉ'\n",
      "   -> 'ู ุงูุชูููุฉ ุงููุณุชุฏุงูุฉ'\n",
      "   'ููู ูุนูู'\n",
      "   -> 'ููู ูุนูู'\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ุงุฎุชูุงุฑู 4.1: ูุตู ูุงู ุงูุนุทู\n",
    "# ============================================================================\n",
    "\n",
    "def separate_waw_conjunction(text: str, min_remaining_length: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    ูุตู ูุงู ุงูุนุทู (ู) ุนู ุจุฏุงูุฉ ุงููููุงุช.\n",
    "    \n",
    "    ูู ุงูุนุฑุจูุฉุ ุชุชุตู ุงููุงู ุจุงููููุฉ ุงูุชุงููุฉ ูุณุงุจูุฉ. ูุตููุง ูุฏ ูุณุงุนุฏ ูู:\n",
    "    - ุชุฑููุฒ (Tokenization) ุฃูุถู\n",
    "    - ุญุฏูุฏ ูููุงุช ูุชุณูุฉ\n",
    "    - ุชุญุณูู ุชูุจุค ุงูุชุฑููู ูุจู ุงูุนุทู\n",
    "    \n",
    "    ุงููุนุงููุงุช:\n",
    "    -----------\n",
    "    text : str\n",
    "        ุงููุต ุงููุฏุฎู\n",
    "    min_remaining_length : int\n",
    "        ุงูุตู ููุท ุฅุฐุง ุชุจูู ูู ุงููููุฉ ูุฐุง ุงูุนุฏุฏ ูู ุงูุญุฑูู\n",
    "        \n",
    "    ุชุฑุฌุน:\n",
    "    --------\n",
    "    str\n",
    "        ุงููุต ูุน ูุงู ุนุทู ููุตููุฉ\n",
    "        \n",
    "    ูุซุงู:\n",
    "    --------\n",
    "    >>> separate_waw_conjunction(\"ููุงู ุงูุฑุฌู ูุฐูุจ\")\n",
    "    'ู ูุงู ุงูุฑุฌู ู ุฐูุจ'\n",
    "    \"\"\"\n",
    "    # ูููุงุช ุญูุซ ุงููุงู ุฌุฒุก ูู ุงูุฌุฐุฑ (ูุฌุจ ุนุฏู ูุตููุง)\n",
    "    waw_root_words = {\n",
    "        'ููุช', 'ูุฌู', 'ูุถุน', 'ูุตู', 'ููุน', 'ูุฒู', 'ููุฏ', 'ูุฑู', 'ูุทู',\n",
    "        'ูุณุท', 'ูุญุฏุฉ', 'ูุฒูุฑ', 'ูุฒุงุฑุฉ', 'ููุงูุฉ', 'ููุฏ', 'ูุงูุฏ', 'ูุงูุฏุฉ',\n",
    "        'ูุซููุฉ', 'ูุซุงุฆู', 'ูุงูุน', 'ูุงุฌุจ', 'ููุงุฉ', 'ููุงูุฉ', 'ูููู',\n",
    "        'ูุงุญุฏ', 'ูุงุญุฏุฉ', 'ูุณููุฉ', 'ูุณุงุฆู', 'ูุฑุดุฉ', 'ูุธููุฉ', 'ูุธุงุฆู',\n",
    "    }\n",
    "    \n",
    "    def should_separate(word: str) -> bool:\n",
    "        \"\"\"ุชุญูู ููุง ุฅุฐุง ูุงู ูุฌุจ ูุตู ุงููุงู ุนู ูุฐู ุงููููุฉ.\"\"\"\n",
    "        if not word.startswith('ู'):\n",
    "            return False\n",
    "        \n",
    "        if len(word) < min_remaining_length + 1:  # +1 ูููุงู\n",
    "            return False\n",
    "        \n",
    "        # ุงูุชุญูู ููุง ุฅุฐุง ูุงูุช ุงููููุฉ (ูุน ุงููุงู) ูููุฉ ุฌุฐุฑูุฉ\n",
    "        if word in waw_root_words:\n",
    "            return False\n",
    "        \n",
    "        # ุงูุชุญูู ููุง ุฅุฐุง ูุงูุช ุงููููุฉ ุจุฏูู ูุงู ููุฌูุฏุฉ ููููุฉ ุตุงูุญุฉ\n",
    "        remaining = word[1:]\n",
    "        \n",
    "        # ุจุงุฏุฆุงุช ุดุงุฆุนุฉ ุชุดูุฑ ุฅูู ุฃู ุงููุงู ููุนุทู\n",
    "        conjunction_indicators = [\n",
    "            'ุงู',   # ู + ุงู (ุงูุชุนุฑูู)\n",
    "            'ูู', 'ูู', 'ูู',  # ุถูุงุฆุฑ\n",
    "            'ูุฏ', 'ูู', 'ูู',  # ุฃุฏูุงุช\n",
    "            'ูุงู', 'ูููู',     # ุฃูุนุงู\n",
    "            'ุฃู', 'ุฅู',        # ุฃุฏูุงุช\n",
    "        ]\n",
    "        \n",
    "        for indicator in conjunction_indicators:\n",
    "            if remaining.startswith(indicator):\n",
    "                return True\n",
    "        \n",
    "        # ุฅุฐุง ุจุฏุฃุช ุงููููุฉ ุงููุชุจููุฉ ุจู ุงู ุงูุชุนุฑููุ ููู ุบุงูุจุงู ุนุทู\n",
    "        if remaining.startswith('ุงู'):\n",
    "            return True\n",
    "        \n",
    "        return len(remaining) >= min_remaining_length\n",
    "    \n",
    "    words = text.split()\n",
    "    result = []\n",
    "    \n",
    "    for word in words:\n",
    "        if should_separate(word):\n",
    "            result.append('ู')\n",
    "            result.append(word[1:])\n",
    "        else:\n",
    "            result.append(word)\n",
    "    \n",
    "    return ' '.join(result)\n",
    "\n",
    "\n",
    "# ุงุฎุชุจุงุฑ ุงูุฏุงูุฉ\n",
    "logger.section(\"๐ง ุงุฎุชูุงุฑู: ูุตู ูุงู ุงูุนุทู\")\n",
    "\n",
    "test_cases = [\n",
    "    \"ููุงู ุงูุฑุฌู\",\n",
    "    \"ูุงูุฃูู ุงููุชุญุฏุฉ\",\n",
    "    \"ููู ูุฐุง ุงูุตุฏุฏ\",\n",
    "    \"ููุช ุงูุงุฌุชูุงุน\",  # ูุง ูุฌุจ ูุตููุง (ููุช ูููุฉ ุฌุฐุฑูุฉ)\n",
    "    \"ูุซููุฉ ูููุฉ\",   # ูุง ูุฌุจ ูุตููุง\n",
    "    \"ูุงูุชูููุฉ ุงููุณุชุฏุงูุฉ\",\n",
    "    \"ููู ูุนูู\",\n",
    "]\n",
    "\n",
    "logger.info(\"ุญุงูุงุช ุงูุงุฎุชุจุงุฑ:\")\n",
    "for test in test_cases:\n",
    "    result = separate_waw_conjunction(test)\n",
    "    logger.info(f\"   '{test}'\")\n",
    "    logger.info(f\"   -> '{result}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d240f089",
   "metadata": {},
   "source": [
    "### 4.2 ุงุณุชุฑุงุชูุฌูุงุช ุงูุชุนุงูู ูุน ูููุงุช ุงูุชููู"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ceee0369",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "๐ง ุงุฎุชูุงุฑู: ุงูุชุนุงูู ูุน ูููุงุช ุงูุชููู\n",
      "======================================================================\n",
      "ุญุงูุงุช ุงูุงุฎุชุจุงุฑ:\n",
      "   ุงูุฃุตู:   'ููู ูุฐุง ุงูุตุฏุฏ'\n",
      "   ูููุฒุฉ:   'ููู<SW> ูุฐุง<SW> ุงูุตุฏุฏ'\n",
      "   ูุญุฐููุฉ:  'ุงูุตุฏุฏ'\n",
      "   ุงูุฃุตู:   'ูู ุฃุฌู ุงูุชูููุฉ'\n",
      "   ูููุฒุฉ:   'ูู<SW> ุฃุฌู ุงูุชูููุฉ'\n",
      "   ูุญุฐููุฉ:  'ุฃุฌู ุงูุชูููุฉ'\n",
      "   ุงูุฃุตู:   'ุงูุฃูู ุงููุชุญุฏุฉ ูู ููุธูุฉ ุฏูููุฉ'\n",
      "   ูููุฒุฉ:   'ุงูุฃูู ุงููุชุญุฏุฉ ูู<SW> ููุธูุฉ ุฏูููุฉ'\n",
      "   ูุญุฐููุฉ:  'ุงูุฃูู ุงููุชุญุฏุฉ ููุธูุฉ ุฏูููุฉ'\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ุงุฎุชูุงุฑู 4.2: ุงูุชุนุงูู ูุน ูููุงุช ุงูุชููู\n",
    "# ============================================================================\n",
    "\n",
    "def mark_stopwords(text: str, marker: str = '<SW>') -> str:\n",
    "    \"\"\"\n",
    "    ุชูููุฒ ูููุงุช ุงูุชููู ุจุฑูุฒ ุฎุงุต (ููุชุญููู/ุงูุชุฌุฑูุจ).\n",
    "    \n",
    "    ุงููุนุงููุงุช:\n",
    "    -----------\n",
    "    text : str\n",
    "        ุงููุต ุงููุฏุฎู\n",
    "    marker : str\n",
    "        ุงูุฑูุฒ ููุฅุถุงูุฉ ุจุนุฏ ูููุงุช ุงูุชููู\n",
    "        \n",
    "    ุชุฑุฌุน:\n",
    "    --------\n",
    "    str\n",
    "        ุงููุต ูุน ูููุงุช ุชููู ูููุฒุฉ\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    result = []\n",
    "    \n",
    "    for word in words:\n",
    "        # ุฅุฒุงูุฉ ุงูุชุฑููู ูููุญุต\n",
    "        clean_word = re.sub(r'[ุุุ.:!]', '', word)\n",
    "        \n",
    "        if clean_word in ARABIC_STOPWORDS:\n",
    "            result.append(word + marker)\n",
    "        else:\n",
    "            result.append(word)\n",
    "    \n",
    "    return ' '.join(result)\n",
    "\n",
    "\n",
    "def remove_stopwords(text: str, keep_structure: bool = True) -> str:\n",
    "    \"\"\"\n",
    "    ุฅุฒุงูุฉ ูููุงุช ุงูุชููู ูู ุงููุต.\n",
    "    \n",
    "    ุชุญุฐูุฑ: ูุฐุง ูุฏ ูุถุฑ ุจุชูุจุค ุงูุชุฑููู ูุฃู ูููุงุช ุงูุชููู ุชููุฑ ุณูุงูุงู ูููููุงู ูููุงู.\n",
    "    \n",
    "    ุงููุนุงููุงุช:\n",
    "    -----------\n",
    "    text : str\n",
    "        ุงููุต ุงููุฏุฎู\n",
    "    keep_structure : bool\n",
    "        ุฅุฐุง Trueุ ุงุญุชูุธ ุจุงูุชุฑููู ุญุชู ูู ูุงู ููุชุตูุงู ุจูููุงุช ุชููู\n",
    "        \n",
    "    ุชุฑุฌุน:\n",
    "    --------\n",
    "    str\n",
    "        ุงููุต ุจุฏูู ูููุงุช ุชููู\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    result = []\n",
    "    \n",
    "    for word in words:\n",
    "        # ูุตู ุงููููุฉ ุนู ุงูุชุฑููู ุงููุงุญู\n",
    "        punct = ''\n",
    "        clean_word = word\n",
    "        \n",
    "        if word and word[-1] in 'ุุุ.:!':\n",
    "            punct = word[-1]\n",
    "            clean_word = word[:-1]\n",
    "        \n",
    "        if clean_word not in ARABIC_STOPWORDS:\n",
    "            result.append(word)\n",
    "        elif keep_structure and punct:\n",
    "            # ุงูุงุญุชูุงุธ ุจุงูุชุฑููู ุญุชู ูู ูุงูุช ุงููููุฉ ูููุฉ ุชููู\n",
    "            if result:\n",
    "                result[-1] += punct\n",
    "    \n",
    "    return ' '.join(result)\n",
    "\n",
    "\n",
    "# ุงุฎุชุจุงุฑ ุงูุฏุงูุฉ\n",
    "logger.section(\"๐ง ุงุฎุชูุงุฑู: ุงูุชุนุงูู ูุน ูููุงุช ุงูุชููู\")\n",
    "\n",
    "test_cases = [\n",
    "    \"ููู ูุฐุง ุงูุตุฏุฏ\",\n",
    "    \"ูู ุฃุฌู ุงูุชูููุฉ\",\n",
    "    \"ุงูุฃูู ุงููุชุญุฏุฉ ูู ููุธูุฉ ุฏูููุฉ\",\n",
    "]\n",
    "\n",
    "logger.info(\"ุญุงูุงุช ุงูุงุฎุชุจุงุฑ:\")\n",
    "for test in test_cases:\n",
    "    marked = mark_stopwords(test)\n",
    "    removed = remove_stopwords(test)\n",
    "    logger.info(f\"   ุงูุฃุตู:   '{test}'\")\n",
    "    logger.info(f\"   ูููุฒุฉ:   '{marked}'\")\n",
    "    logger.info(f\"   ูุญุฐููุฉ:  '{removed}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d86b4b",
   "metadata": {},
   "source": [
    "### 4.3 ุงุณุชุจุฏุงู ุงูุฃุฑูุงู ุจุฑูุฒ ุฎุงุต"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "205e8c42",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "๐ง ุงุฎุชูุงุฑู: ุงุณุชุจุฏุงู ุงูุฃุฑูุงู ุจุฑูุฒ\n",
      "======================================================================\n",
      "ุญุงูุงุช ุงูุงุฎุชุจุงุฑ:\n",
      "   'ูู ุนุงู ูขููขูค'\n",
      "   -> 'ูู ุนุงู <NUM>'\n",
      "   'ูุจูุบ ูกููููู ุฏููุงุฑ'\n",
      "   -> 'ูุจูุบ <NUM> ุฏููุงุฑ'\n",
      "   'ูู ูฅ ุฅูู ูกู ุณููุงุช'\n",
      "   -> 'ูู <NUM> ุฅูู <NUM> ุณููุงุช'\n",
      "   'ุงููุฑุงุฑ ุฑูู ูคูง/ูกูขูฃ'\n",
      "   -> 'ุงููุฑุงุฑ ุฑูู <NUM>/<NUM>'\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ุงุฎุชูุงุฑู 4.3: ุงุณุชุจุฏุงู ุงูุฃุฑูุงู ุจุฑูุฒ\n",
    "# ============================================================================\n",
    "\n",
    "def replace_numbers_with_token(text: str, token: str = '<NUM>') -> str:\n",
    "    \"\"\"\n",
    "    ุงุณุชุจุฏุงู ุฌููุน ุงูุฃุฑูุงู ุจุฑูุฒ ุฎุงุต.\n",
    "    \n",
    "    ูุฐุง ูุณุงุนุฏ ูู:\n",
    "    - ุชูููู ุญุฌู ุงูููุฑุฏุงุช\n",
    "    - ุชุฑููุฒ ุงููููุฐุฌ ุนูู ุงููููู ุจุฏูุงู ูู ุฃุฑูุงู ูุญุฏุฏุฉ\n",
    "    \n",
    "    ุงููุนุงููุงุช:\n",
    "    -----------\n",
    "    text : str\n",
    "        ุงููุต ุงููุฏุฎู\n",
    "    token : str\n",
    "        ุงูุฑูุฒ ูุงุณุชุจุฏุงู ุงูุฃุฑูุงู ุจู\n",
    "        \n",
    "    ุชุฑุฌุน:\n",
    "    --------\n",
    "    str\n",
    "        ุงููุต ุจุนุฏ ุงุณุชุจุฏุงู ุงูุฃุฑูุงู\n",
    "    \"\"\"\n",
    "    # ููุท ููุฃุฑูุงู ุงูุนุฑุจูุฉ ุฃู ุงูุบุฑุจูุฉ\n",
    "    number_pattern = re.compile(r'[ู-ูฉ0-9]+')\n",
    "    return number_pattern.sub(token, text)\n",
    "\n",
    "\n",
    "def normalize_number_format(text: str) -> str:\n",
    "    \"\"\"\n",
    "    ุชูุญูุฏ ุชูุณูู ุงูุฃุฑูุงู (ูุซู ููุงุตู ุงูุขูุงู).\n",
    "    \n",
    "    ุงููุนุงููุงุช:\n",
    "    -----------\n",
    "    text : str\n",
    "        ุงููุต ุงููุฏุฎู\n",
    "        \n",
    "    ุชุฑุฌุน:\n",
    "    --------\n",
    "    str\n",
    "        ุงููุต ุจุชูุณูู ุฃุฑูุงู ููุญุฏ\n",
    "    \"\"\"\n",
    "    # ุฅุฒุงูุฉ ููุงุตู ุงูุขูุงู (ูู ูู , ู ูฌ)\n",
    "    text = re.sub(r'(\\d),(\\d)', r'\\1\\2', text)\n",
    "    text = re.sub(r'([\\u0660-\\u0669])ูฌ([\\u0660-\\u0669])', r'\\1\\2', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "# ุงุฎุชุจุงุฑ ุงูุฏุงูุฉ\n",
    "logger.section(\"๐ง ุงุฎุชูุงุฑู: ุงุณุชุจุฏุงู ุงูุฃุฑูุงู ุจุฑูุฒ\")\n",
    "\n",
    "test_cases = [\n",
    "    \"ูู ุนุงู ูขููขูค\",\n",
    "    \"ูุจูุบ ูกููููู ุฏููุงุฑ\",\n",
    "    \"ูู ูฅ ุฅูู ูกู ุณููุงุช\",\n",
    "    \"ุงููุฑุงุฑ ุฑูู ูคูง/ูกูขูฃ\",\n",
    "]\n",
    "\n",
    "logger.info(\"ุญุงูุงุช ุงูุงุฎุชุจุงุฑ:\")\n",
    "for test in test_cases:\n",
    "    result = replace_numbers_with_token(test)\n",
    "    logger.info(f\"   '{test}'\")\n",
    "    logger.info(f\"   -> '{result}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01519dc3",
   "metadata": {},
   "source": [
    "### 4.4 ูุนุงูุฌุฉ ุงููููุงุช ุงููุงุฏุฑุฉ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96d0a7f2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "๐ง ุงุฎุชูุงุฑู: ูุนุงูุฌุฉ ุงููููุงุช ุงููุงุฏุฑุฉ\n",
      "======================================================================\n",
      "ุจูุงุก ุงููุงููุณ ุนูููุฉ ููููุฉ ุญุณุงุจูุงู.\n",
      "ูู ุงูุฅูุชุงุฌุ ูุฌุจ ุจูุงุก ุงููุงููุณ ูุฑุฉ ูุงุญุฏุฉ ูุญูุธู.\n",
      "\n",
      "ูุซุงู ุงูุงุณุชุฎุฏุงู:\n",
      "   vocab = build_vocabulary(dataset_dir, sample_size=1000000)\n",
      "   text = replace_rare_words(text, vocab, threshold=5)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ุงุฎุชูุงุฑู 4.4: ูุนุงูุฌุฉ ุงููููุงุช ุงููุงุฏุฑุฉ\n",
    "# ============================================================================\n",
    "\n",
    "def build_vocabulary(dataset_dir: str, sample_size: int = 1000000) -> Counter:\n",
    "    \"\"\"\n",
    "    ุจูุงุก ูุงููุณ ุจุชูุฑุงุฑ ุงููููุงุช.\n",
    "    \n",
    "    ุงููุนุงููุงุช:\n",
    "    -----------\n",
    "    dataset_dir : str\n",
    "        ูุณุงุฑ ุงูุจูุงูุงุช\n",
    "    sample_size : int\n",
    "        ุนุฏุฏ ุงูุฃุณุทุฑ ูููุนุงูุฌุฉ\n",
    "        \n",
    "    ุชุฑุฌุน:\n",
    "    --------\n",
    "    Counter\n",
    "        ุนุฏุงุฏ ุชูุฑุงุฑ ุงููููุงุช\n",
    "    \"\"\"\n",
    "    vocab = Counter()\n",
    "    arabic_word_pattern = re.compile(r'[\\u0600-\\u06FF]+')\n",
    "    \n",
    "    for i, line in enumerate(iter_dataset_lines(dataset_dir)):\n",
    "        if i >= sample_size:\n",
    "            break\n",
    "        \n",
    "        words = arabic_word_pattern.findall(line)\n",
    "        vocab.update(words)\n",
    "    \n",
    "    return vocab\n",
    "\n",
    "\n",
    "def replace_rare_words(text: str, vocab: Counter, threshold: int = 5, \n",
    "                       token: str = '<UNK>') -> str:\n",
    "    \"\"\"\n",
    "    ุงุณุชุจุฏุงู ุงููููุงุช ุงููุงุฏุฑุฉ (ุฃูู ูู ุญุฏ ุงูุชูุฑุงุฑ) ุจุฑูุฒ ุฎุงุต.\n",
    "    \n",
    "    ุงููุนุงููุงุช:\n",
    "    -----------\n",
    "    text : str\n",
    "        ุงููุต ุงููุฏุฎู\n",
    "    vocab : Counter\n",
    "        ุงููุงููุณ ูุน ุงูุชูุฑุงุฑุงุช\n",
    "    threshold : int\n",
    "        ุงูุญุฏ ุงูุฃุฏูู ููุชูุฑุงุฑ ูุฅุจูุงุก ุงููููุฉ\n",
    "    token : str\n",
    "        ุฑูุฒ ุงูุงุณุชุจุฏุงู\n",
    "        \n",
    "    ุชุฑุฌุน:\n",
    "    --------\n",
    "    str\n",
    "        ุงููุต ูุน ุงุณุชุจุฏุงู ุงููููุงุช ุงููุงุฏุฑุฉ\n",
    "    \"\"\"\n",
    "    arabic_word_pattern = re.compile(r'[\\u0600-\\u06FF]+')\n",
    "    \n",
    "    def replace_if_rare(match):\n",
    "        word = match.group(0)\n",
    "        if vocab.get(word, 0) < threshold:\n",
    "            return token\n",
    "        return word\n",
    "    \n",
    "    return arabic_word_pattern.sub(replace_if_rare, text)\n",
    "\n",
    "\n",
    "# ููุงุญุธุฉ: ุจูุงุก ุงููุงููุณ ูููู ุญุณุงุจูุงูุ ุณููุถุญ ุจูุญุงูุงุฉ\n",
    "logger.section(\"๐ง ุงุฎุชูุงุฑู: ูุนุงูุฌุฉ ุงููููุงุช ุงููุงุฏุฑุฉ\")\n",
    "\n",
    "logger.info(\"ุจูุงุก ุงููุงููุณ ุนูููุฉ ููููุฉ ุญุณุงุจูุงู.\")\n",
    "logger.info(\"ูู ุงูุฅูุชุงุฌุ ูุฌุจ ุจูุงุก ุงููุงููุณ ูุฑุฉ ูุงุญุฏุฉ ูุญูุธู.\")\n",
    "logger.info(\"\\nูุซุงู ุงูุงุณุชุฎุฏุงู:\")\n",
    "logger.info(\"   vocab = build_vocabulary(dataset_dir, sample_size=1000000)\")\n",
    "logger.info(\"   text = replace_rare_words(text, vocab, threshold=5)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb99f56a",
   "metadata": {},
   "source": [
    "### 4.5 ุชุณููุฉ ุทูู ุงูุฌูู"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26c36afe",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "๐ง ุงุฎุชูุงุฑู: ุชุณููุฉ ุทูู ุงูุฌูู\n",
      "======================================================================\n",
      "ุงูุฃุตู: 12 ูููุฉ\n",
      "ุชู ุงูุชูุณูู ุฅูู 4 ุฃุฌุฒุงุก:\n",
      "   ุงูุฌุฒุก 1: 'ูุฐุง ูุต ุทููู ูุญุชูู ุนูู'\n",
      "   ุงูุฌุฒุก 2: 'ูุญุชูู ุนูู ุงูุนุฏูุฏ ูู ุงููููุงุช'\n",
      "   ุงูุฌุฒุก 3: 'ูู ุงููููุงุช ุงูุชู ุชุญุชุงุฌ ุฅูู'\n",
      "   ุงูุฌุฒุก 4: 'ุชุญุชุงุฌ ุฅูู ูุนุงูุฌุฉ'\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ุงุฎุชูุงุฑู 4.5: ุชุณููุฉ ุทูู ุงูุฌูู\n",
    "# ============================================================================\n",
    "\n",
    "def pad_sentence(text: str, target_length: int, pad_token: str = '<PAD>') -> str:\n",
    "    \"\"\"\n",
    "    ุญุดู ุงูุฌููุฉ ูุชุตู ููุทูู ุงููุณุชูุฏู.\n",
    "    \n",
    "    ููุงุญุธุฉ: ูุฐุง ูุชู ุนุงุฏุฉ ุฃุซูุงุก ุงูู batchingุ ููุณ ุงููุนุงูุฌุฉ ุงููุณุจูุฉ.\n",
    "    ูุฏุฑุฌ ููุง ููุงูุชูุงู.\n",
    "    \n",
    "    ุงููุนุงููุงุช:\n",
    "    -----------\n",
    "    text : str\n",
    "        ุงููุต ุงููุฏุฎู\n",
    "    target_length : int\n",
    "        ุนุฏุฏ ุงููููุงุช ุงููุณุชูุฏู\n",
    "    pad_token : str\n",
    "        ุฑูุฒ ุงูุญุดู\n",
    "        \n",
    "    ุชุฑุฌุน:\n",
    "    --------\n",
    "    str\n",
    "        ุงููุต ุงููุญุดู\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    \n",
    "    if len(words) >= target_length:\n",
    "        return text\n",
    "    \n",
    "    padding = [pad_token] * (target_length - len(words))\n",
    "    return text + ' ' + ' '.join(padding)\n",
    "\n",
    "\n",
    "def split_into_chunks(text: str, chunk_size: int = 50, overlap: int = 10) -> List[str]:\n",
    "    \"\"\"\n",
    "    ุชูุณูู ุงููุต ุงูุทููู ุฅูู ุฃุฌุฒุงุก ูุชุฏุงุฎูุฉ.\n",
    "    \n",
    "    ูููุฏ ูููุณุชูุฏุงุช ุงูุทูููุฉ ุฌุฏุงู ุญูุซ ูุฌุจ ุงูุญูุงุธ ุนูู ุงูุณูุงู.\n",
    "    \n",
    "    ุงููุนุงููุงุช:\n",
    "    -----------\n",
    "    text : str\n",
    "        ุงููุต ุงููุฏุฎู\n",
    "    chunk_size : int\n",
    "        ุงููููุงุช ุงููุณุชูุฏูุฉ ููู ุฌุฒุก\n",
    "    overlap : int\n",
    "        ุนุฏุฏ ูููุงุช ุงูุชุฏุงุฎู ุจูู ุงูุฃุฌุฒุงุก\n",
    "        \n",
    "    ุชุฑุฌุน:\n",
    "    --------\n",
    "    List[str]\n",
    "        ูุงุฆูุฉ ุฃุฌุฒุงุก ุงููุต\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    \n",
    "    if len(words) <= chunk_size:\n",
    "        return [text]\n",
    "    \n",
    "    chunks = []\n",
    "    start = 0\n",
    "    \n",
    "    while start < len(words):\n",
    "        end = min(start + chunk_size, len(words))\n",
    "        chunk_words = words[start:end]\n",
    "        chunks.append(' '.join(chunk_words))\n",
    "        \n",
    "        # ุชุญุฑูู ุงูุจุฏุงูุฉ ูุน ุงูุชุฏุงุฎู\n",
    "        start = end - overlap\n",
    "        if start >= len(words) - overlap:\n",
    "            break\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "\n",
    "# ุงุฎุชุจุงุฑ ุงูุฏูุงู\n",
    "logger.section(\"๐ง ุงุฎุชูุงุฑู: ุชุณููุฉ ุทูู ุงูุฌูู\")\n",
    "\n",
    "test_text = \"ูุฐุง ูุต ุทููู ูุญุชูู ุนูู ุงูุนุฏูุฏ ูู ุงููููุงุช ุงูุชู ุชุญุชุงุฌ ุฅูู ูุนุงูุฌุฉ\"\n",
    "logger.info(f\"ุงูุฃุตู: {len(test_text.split())} ูููุฉ\")\n",
    "\n",
    "chunks = split_into_chunks(test_text, chunk_size=5, overlap=2)\n",
    "logger.info(f\"ุชู ุงูุชูุณูู ุฅูู {len(chunks)} ุฃุฌุฒุงุก:\")\n",
    "for i, chunk in enumerate(chunks):\n",
    "    logger.info(f\"   ุงูุฌุฒุก {i+1}: '{chunk}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d646392d",
   "metadata": {},
   "source": [
    "### 4.6 ุฅุฒุงูุฉ/ุงุณุชุจุฏุงู ุงููุตุทูุญุงุช ุงูุฃุฌูุจูุฉ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0fe89ab",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "๐ง ุงุฎุชูุงุฑู: ุงูุชุนุงูู ูุน ุงููุตุทูุญุงุช ุงูุฃุฌูุจูุฉ\n",
      "======================================================================\n",
      "ุญุงูุงุช ุงูุงุฎุชุจุงุฑ:\n",
      "   ุงูุฃุตู:      'ุงููุซููุฉ A/47/10 ุงููุคุฑุฎุฉ'\n",
      "   ุฅุฒุงูุฉ ูุฑุงุฌุน:'ุงููุซููุฉ  ุงููุคุฑุฎุฉ'\n",
      "   ุงุณุชุจุฏุงู:    'ุงููุซููุฉ A/47/10 ุงููุคุฑุฎุฉ'\n",
      "   ุงูุฃุตู:      'ุจุฑูุงูุฌ UNDP ููุชูููุฉ'\n",
      "   ุฅุฒุงูุฉ ูุฑุงุฌุน:'ุจุฑูุงูุฌ UNDP ููุชูููุฉ'\n",
      "   ุงุณุชุจุฏุงู:    'ุจุฑูุงูุฌ <FOREIGN> ููุชูููุฉ'\n",
      "   ุงูุฃุตู:      'ูุฑุงุฑ ูุฌูุณ ุงูุฃูู S/RES/1234'\n",
      "   ุฅุฒุงูุฉ ูุฑุงุฌุน:'ูุฑุงุฑ ูุฌูุณ ุงูุฃูู '\n",
      "   ุงุณุชุจุฏุงู:    'ูุฑุงุฑ ูุฌูุณ ุงูุฃูู S/<FOREIGN>/1234'\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ุงุฎุชูุงุฑู 4.6: ุงูุชุนุงูู ูุน ุงููุตุทูุญุงุช ุงูุฃุฌูุจูุฉ\n",
    "# ============================================================================\n",
    "\n",
    "def remove_document_references(text: str) -> str:\n",
    "    \"\"\"\n",
    "    ุฅุฒุงูุฉ ูุฑุงุฌุน ูุณุชูุฏุงุช ุงูุฃูู ุงููุชุญุฏุฉ (ูุซู A/47/10, S/RES/1234).\n",
    "    \n",
    "    ุงููุนุงููุงุช:\n",
    "    -----------\n",
    "    text : str\n",
    "        ุงููุต ุงููุฏุฎู\n",
    "        \n",
    "    ุชุฑุฌุน:\n",
    "    --------\n",
    "    str\n",
    "        ุงููุต ุจุฏูู ูุฑุงุฌุน ุงููุณุชูุฏุงุช\n",
    "    \"\"\"\n",
    "    # ููุท ูุฑุงุฌุน ุงููุณุชูุฏุงุช\n",
    "    doc_pattern = re.compile(r'[A-Z]/[A-Z0-9]+(?:/[A-Z0-9]+)*')\n",
    "    return doc_pattern.sub('', text)\n",
    "\n",
    "\n",
    "def replace_foreign_with_token(text: str, token: str = '<FOREIGN>') -> str:\n",
    "    \"\"\"\n",
    "    ุงุณุชุจุฏุงู ุงููุตุทูุญุงุช ุงูุฃุฌูุจูุฉ (ุบูุฑ ุงูุนุฑุจูุฉ) ุจุฑูุฒ ุฎุงุต.\n",
    "    \n",
    "    ุงููุนุงููุงุช:\n",
    "    -----------\n",
    "    text : str\n",
    "        ุงููุต ุงููุฏุฎู\n",
    "    token : str\n",
    "        ุฑูุฒ ุงูุงุณุชุจุฏุงู\n",
    "        \n",
    "    ุชุฑุฌุน:\n",
    "    --------\n",
    "    str\n",
    "        ุงููุต ูุน ุงุณุชุจุฏุงู ุงููุตุทูุญุงุช ุงูุฃุฌูุจูุฉ\n",
    "    \"\"\"\n",
    "    # ููุท ูููููุงุช ุงููุงุชูููุฉ (3+ ุญุฑูู)\n",
    "    foreign_pattern = re.compile(r'\\b[A-Za-z]{3,}\\b')\n",
    "    return foreign_pattern.sub(token, text)\n",
    "\n",
    "\n",
    "# ุงุฎุชุจุงุฑ ุงูุฏูุงู\n",
    "logger.section(\"๐ง ุงุฎุชูุงุฑู: ุงูุชุนุงูู ูุน ุงููุตุทูุญุงุช ุงูุฃุฌูุจูุฉ\")\n",
    "\n",
    "test_cases = [\n",
    "    \"ุงููุซููุฉ A/47/10 ุงููุคุฑุฎุฉ\",\n",
    "    \"ุจุฑูุงูุฌ UNDP ููุชูููุฉ\",\n",
    "    \"ูุฑุงุฑ ูุฌูุณ ุงูุฃูู S/RES/1234\",\n",
    "]\n",
    "\n",
    "logger.info(\"ุญุงูุงุช ุงูุงุฎุชุจุงุฑ:\")\n",
    "for test in test_cases:\n",
    "    no_refs = remove_document_references(test)\n",
    "    replaced = replace_foreign_with_token(test)\n",
    "    logger.info(f\"   ุงูุฃุตู:      '{test}'\")\n",
    "    logger.info(f\"   ุฅุฒุงูุฉ ูุฑุงุฌุน:'{no_refs}'\")\n",
    "    logger.info(f\"   ุงุณุชุจุฏุงู:    '{replaced}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ecaf1b",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. ุงูุฌุฒุก 4: ุฎุท ุฃูุงุจูุจ ุงููุนุงูุฌุฉ ุงููุงูู"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ba8569c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "โ ุชู ุชููุฆุฉ ุงููุนุงูุฌ!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ุงููุณู 5: ุฎุท ุฃูุงุจูุจ ุงููุนุงูุฌุฉ ุงููุงูู\n",
    "# ============================================================================\n",
    "\n",
    "@dataclass\n",
    "class PreprocessingStats:\n",
    "    \"\"\"ุฅุญุตุงุฆูุงุช ุชู ุฌูุนูุง ุฃุซูุงุก ุงููุนุงูุฌุฉ.\"\"\"\n",
    "    total_input_lines: int = 0\n",
    "    total_output_lines: int = 0\n",
    "    empty_lines_removed: int = 0\n",
    "    short_lines_removed: int = 0\n",
    "    long_lines_truncated: int = 0\n",
    "    diacritics_removed: int = 0\n",
    "    alef_normalized: int = 0\n",
    "    punct_normalized: int = 0\n",
    "    numbers_normalized: int = 0\n",
    "    latin_removed: int = 0\n",
    "    oov_removed: int = 0\n",
    "    consecutive_punct_fixed: int = 0\n",
    "    whitespace_fixed: int = 0\n",
    "\n",
    "\n",
    "class ArabicTextPreprocessor:\n",
    "    \"\"\"\n",
    "    ุฎุท ุฃูุงุจูุจ ูุนุงูุฌุฉ ูุงูู ููุฌููุนุฉ ุจูุงูุงุช ุงูุชุฑููู ุงูุนุฑุจู.\n",
    "    \n",
    "    ูููุฑ ูุฐุง ุงูููุงุณ ุฎุท ุฃูุงุจูุจ ูุงุจู ููุชููุฆุฉ ูููู ุงุณุชุฎุฏุงูู ูุน\n",
    "    ูู ูู ุฎุทูุงุช ุงููุนุงูุฌุฉ ุงูุฅูุฒุงููุฉ ูุงูุงุฎุชูุงุฑูุฉ.\n",
    "    \n",
    "    ุงูุณูุงุช:\n",
    "    -----------\n",
    "    config : PreprocessingConfig\n",
    "        ูุงุฆู ุงูุฅุนุฏุงุฏุงุช ุงููุญุชูู ุนูู ุฌููุน ุงูุฎูุงุฑุงุช\n",
    "    stats : PreprocessingStats\n",
    "        ุงูุฅุญุตุงุฆูุงุช ุงููุฌูุนุฉ ุฃุซูุงุก ุงููุนุงูุฌุฉ\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: PreprocessingConfig):\n",
    "        \"\"\"\n",
    "        ุชููุฆุฉ ุงููุนุงูุฌ ุจุงูุฅุนุฏุงุฏุงุช.\n",
    "        \n",
    "        ุงููุนุงููุงุช:\n",
    "        -----------\n",
    "        config : PreprocessingConfig\n",
    "            ูุงุฆู ุงูุฅุนุฏุงุฏุงุช\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        self.stats = PreprocessingStats()\n",
    "        self.vocab = None  # ููุนุงูุฌุฉ ุงููููุงุช ุงููุงุฏุฑุฉ\n",
    "        \n",
    "        # ุชุฌููุน ุงูุฃููุงุท ููููุงุกุฉ\n",
    "        self._compile_patterns()\n",
    "    \n",
    "    def _compile_patterns(self):\n",
    "        \"\"\"ุชุฌููุน ุฃููุงุท Regex ููููุงุกุฉ.\"\"\"\n",
    "        self.diacritics_pattern = re.compile(r'[\\u064B-\\u0652]')\n",
    "        self.alef_pattern = re.compile(r'[ุฃุฅุขูฑ]')\n",
    "        self.latin_pattern = re.compile(r'[A-Za-z]+')\n",
    "        self.number_western = re.compile(r'[0-9]')\n",
    "        self.consecutive_punct = re.compile(r'[ุุุ.,:;?!]{2,}')\n",
    "        self.multi_space = re.compile(r' +')\n",
    "        self.arabic_word = re.compile(r'[\\u0600-\\u06FF]+')\n",
    "    \n",
    "    def preprocess_line(self, text: str, apply_optional: bool = False) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        ุชุทุจูู ุฎุท ุฃูุงุจูุจ ุงููุนุงูุฌุฉ ุงููุงูู ุนูู ุณุทุฑ ูุงุญุฏ.\n",
    "        \n",
    "        ุงููุนุงููุงุช:\n",
    "        -----------\n",
    "        text : str\n",
    "            ุณุทุฑ ุงููุต ุงููุฏุฎู\n",
    "        apply_optional : bool\n",
    "            ุชุทุจูู ุงูุฎุทูุงุช ุงูุงุฎุชูุงุฑูุฉ ุฃู ูุง\n",
    "            \n",
    "        ุชุฑุฌุน:\n",
    "        --------\n",
    "        Optional[str]\n",
    "            ุงููุต ุงููุนุงูุฌุ ุฃู None ุฅุฐุง ุชู ุชุตููุฉ ุงูุณุทุฑ\n",
    "        \"\"\"\n",
    "        original = text\n",
    "        \n",
    "        # ุชุชุจุน ุงูุชุบููุฑุงุช ููุฅุญุตุงุฆูุงุช\n",
    "        had_diacritics = bool(self.diacritics_pattern.search(text))\n",
    "        had_alef_var = bool(self.alef_pattern.search(text))\n",
    "        had_latin = bool(self.latin_pattern.search(text))\n",
    "        had_consec_punct = bool(self.consecutive_punct.search(text))\n",
    "        \n",
    "        # ============================================\n",
    "        # ุงููุนุงูุฌุฉ ุงูุฅูุฒุงููุฉ\n",
    "        # ============================================\n",
    "        \n",
    "        # 1. ุฅุฒุงูุฉ ุงูุชุดููู\n",
    "        if self.config.remove_diacritics:\n",
    "            text = self.diacritics_pattern.sub('', text)\n",
    "            if had_diacritics:\n",
    "                self.stats.diacritics_removed += 1\n",
    "        \n",
    "        # 2. ุชูุญูุฏ ุงูุฃูู\n",
    "        if self.config.normalize_alef:\n",
    "            text = self.alef_pattern.sub('ุง', text)\n",
    "            if had_alef_var:\n",
    "                self.stats.alef_normalized += 1\n",
    "        \n",
    "        # 3. ุชูุญูุฏ ุงูุฃูู ุงูููุตูุฑุฉ (ู -> ู)\n",
    "        if self.config.normalize_alef_maksura:\n",
    "            text = text.replace('ู', 'ู')\n",
    "        \n",
    "        # 4. ุฅุฒุงูุฉ ุงูุชุทููู\n",
    "        if self.config.remove_tatweel:\n",
    "            text = text.replace('\\u0640', '')\n",
    "        \n",
    "        # 5. ุชูุญูุฏ ุงูุชุฑููู ููุนุฑุจู\n",
    "        if self.config.unify_punctuation_to_arabic:\n",
    "            for latin, arabic in LATIN_TO_ARABIC_PUNCT.items():\n",
    "                if latin in text:\n",
    "                    text = text.replace(latin, arabic)\n",
    "                    self.stats.punct_normalized += 1\n",
    "        \n",
    "        # 6. ุชูุญูุฏ ุงูุฃุฑูุงู ููุนุฑุจูุฉ\n",
    "        if self.config.unify_numbers_to_arabic:\n",
    "            if self.number_western.search(text):\n",
    "                text = text.translate(WESTERN_TO_ARABIC_NUMS)\n",
    "                self.stats.numbers_normalized += 1\n",
    "        \n",
    "        # 7. ุฅุฒุงูุฉ ุงูุญุฑูู ุงููุงุชูููุฉ\n",
    "        if self.config.remove_latin_letters:\n",
    "            if had_latin:\n",
    "                text = self.latin_pattern.sub('', text)\n",
    "                self.stats.latin_removed += 1\n",
    "        \n",
    "        # 8. ุฅุฒุงูุฉ ุงูุญุฑูู ุฎุงุฑุฌ ุงููุทุงู\n",
    "        if self.config.remove_oov_chars:\n",
    "            original_len = len(text)\n",
    "            text = remove_oov_characters(text)\n",
    "            if len(text) < original_len:\n",
    "                self.stats.oov_removed += 1\n",
    "        \n",
    "        # 9. ูุนุงูุฌุฉ ุงูุชุฑููู ุงููุชุชุงุจุน\n",
    "        if self.config.handle_consecutive_punct:\n",
    "            if had_consec_punct:\n",
    "                text = handle_consecutive_punctuation_smart(text)\n",
    "                self.stats.consecutive_punct_fixed += 1\n",
    "        \n",
    "        # 10. ุชูุญูุฏ ุงููุณุงูุงุช\n",
    "        if self.config.normalize_whitespace:\n",
    "            text = self.multi_space.sub(' ', text)\n",
    "            text = text.strip()\n",
    "            self.stats.whitespace_fixed += 1\n",
    "        \n",
    "        # 11. ุฅุถุงูุฉ ูุณุงูุงุช ุงูุชุฑููู\n",
    "        if self.config.add_punct_spacing:\n",
    "            text = add_punctuation_spacing(text)\n",
    "        \n",
    "        # ============================================\n",
    "        # ุงููุนุงูุฌุฉ ุงูุงุฎุชูุงุฑูุฉ\n",
    "        # ============================================\n",
    "        \n",
    "        if apply_optional:\n",
    "            # ูุตู ูุงู ุงูุนุทู\n",
    "            if self.config.separate_waw_conjunction:\n",
    "                text = separate_waw_conjunction(text)\n",
    "            \n",
    "            # ุงุณุชุจุฏุงู ุงูุฃุฑูุงู ุจุฑูุฒ\n",
    "            if self.config.replace_numbers_with_token:\n",
    "                text = replace_numbers_with_token(text, '<NUM>')\n",
    "            \n",
    "            # ุฅุฒุงูุฉ ุงููุตุทูุญุงุช ุงูุฃุฌูุจูุฉ\n",
    "            if self.config.remove_foreign_terms:\n",
    "                text = remove_document_references(text)\n",
    "        \n",
    "        # ============================================\n",
    "        # ุงูุชุตููุฉ\n",
    "        # ============================================\n",
    "        \n",
    "        # ุชูุธูู ูุณุงูุงุช ููุงุฆู\n",
    "        text = self.multi_space.sub(' ', text).strip()\n",
    "        \n",
    "        # ุงูุชุญูู ูู ุงููุฑุงุบ\n",
    "        if self.config.remove_empty_lines and not text:\n",
    "            self.stats.empty_lines_removed += 1\n",
    "            return None\n",
    "        \n",
    "        # ุงูุชุญูู ูู ุนุฏุฏ ุงููููุงุช\n",
    "        word_count = len(self.arabic_word.findall(text))\n",
    "        \n",
    "        # ุชุตููุฉ ุงูุฌูู ุงููุตูุฑุฉ\n",
    "        if word_count < self.config.min_words:\n",
    "            self.stats.short_lines_removed += 1\n",
    "            return None\n",
    "        \n",
    "        # ูุนุงูุฌุฉ ุงูุฌูู ุงูุทูููุฉ\n",
    "        if word_count > self.config.max_words:\n",
    "            text = truncate_sentence(text, self.config.max_words)\n",
    "            self.stats.long_lines_truncated += 1\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def process_dataset(self, input_dir: str, output_file: str, \n",
    "                        apply_optional: bool = False,\n",
    "                        sample_size: Optional[int] = None) -> PreprocessingStats:\n",
    "        \"\"\"\n",
    "        ูุนุงูุฌุฉ ูุฌููุนุฉ ุงูุจูุงูุงุช ุจุงููุงูู ูุญูุธูุง ูู ููู.\n",
    "        \n",
    "        ุงููุนุงููุงุช:\n",
    "        -----------\n",
    "        input_dir : str\n",
    "            ูุณุงุฑ ูุฌูุฏ ุงููุฏุฎูุงุช\n",
    "        output_file : str\n",
    "            ูุณุงุฑ ููู ุงููุฎุฑุฌุงุช\n",
    "        apply_optional : bool\n",
    "            ุชุทุจูู ุงููุนุงูุฌุฉ ุงูุงุฎุชูุงุฑูุฉ ุฃู ูุง\n",
    "        sample_size : Optional[int]\n",
    "            ุญุฏ ุงููุนุงูุฌุฉ ูุนุฏุฏ ูุนูู ูู ุงูุฃุณุทุฑ (None = ุงููู)\n",
    "            \n",
    "        ุชุฑุฌุน:\n",
    "        --------\n",
    "        PreprocessingStats\n",
    "            ุฅุญุตุงุฆูุงุช ุงููุนุงูุฌุฉ\n",
    "        \"\"\"\n",
    "        logger.section(\"๐ ูุนุงูุฌุฉ ูุฌููุนุฉ ุงูุจูุงูุงุช\")\n",
    "        logger.info(f\"ุงููุฏุฎูุงุช: {input_dir}\")\n",
    "        logger.info(f\"ุงููุฎุฑุฌุงุช: {output_file}\")\n",
    "        logger.info(f\"ุชุทุจูู ุงูุงุฎุชูุงุฑู: {apply_optional}\")\n",
    "        \n",
    "        # ุฅุนุงุฏุฉ ุชุนููู ุงูุฅุญุตุงุฆูุงุช\n",
    "        self.stats = PreprocessingStats()\n",
    "        \n",
    "        # ุนุฏ ุฅุฌูุงูู ุงูุฃุณุทุฑ ูุดุฑูุท ุงูุชูุฏู\n",
    "        if sample_size is None:\n",
    "            total_lines = count_total_lines(input_dir)\n",
    "            logger.info(f\"ุฅุฌูุงูู ุงูุฃุณุทุฑ ูููุนุงูุฌุฉ: {total_lines:,}\")\n",
    "        else:\n",
    "            total_lines = sample_size\n",
    "            logger.info(f\"ูุนุงูุฌุฉ ุนููุฉ ูู {total_lines:,} ุณุทุฑ\")\n",
    "        \n",
    "        # ุฅูุดุงุก ูุฌูุฏ ุงููุฎุฑุฌุงุช ุฅุฐุง ูุฒู ุงูุฃูุฑ\n",
    "        os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "        \n",
    "        # ุงููุนุงูุฌุฉ ูุงููุชุงุจุฉ\n",
    "        iterator = iter_dataset_lines(input_dir)\n",
    "        if TQDM_AVAILABLE:\n",
    "            iterator = tqdm(iterator, total=total_lines, desc=\"ุฌุงุฑู ุงููุนุงูุฌุฉ\")\n",
    "        \n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            for i, line in enumerate(iterator):\n",
    "                if sample_size and i >= sample_size:\n",
    "                    break\n",
    "                \n",
    "                self.stats.total_input_lines += 1\n",
    "                \n",
    "                # ูุนุงูุฌุฉ ุงูุณุทุฑ\n",
    "                processed = self.preprocess_line(line, apply_optional)\n",
    "                \n",
    "                # ุงููุชุงุจุฉ ุฅุฐุง ูู ูุชู ุชุตููุชู\n",
    "                if processed:\n",
    "                    f.write(processed + '\\n')\n",
    "                    self.stats.total_output_lines += 1\n",
    "        \n",
    "        # ุชุณุฌูู ุงูุฅุญุตุงุฆูุงุช\n",
    "        self._log_statistics()\n",
    "        \n",
    "        return self.stats\n",
    "    \n",
    "    def _log_statistics(self):\n",
    "        \"\"\"ุชุณุฌูู ุฅุญุตุงุฆูุงุช ุงููุนุงูุฌุฉ.\"\"\"\n",
    "        logger.section(\"๐ ุฅุญุตุงุฆูุงุช ุงููุนุงูุฌุฉ\")\n",
    "        \n",
    "        logger.info(f\"ุฃุณุทุฑ ุงููุฏุฎูุงุช:  {self.stats.total_input_lines:,}\")\n",
    "        logger.info(f\"ุฃุณุทุฑ ุงููุฎุฑุฌุงุช:  {self.stats.total_output_lines:,}\")\n",
    "        \n",
    "        kept_pct = self.stats.total_output_lines / max(self.stats.total_input_lines, 1) * 100\n",
    "        logger.info(f\"ูุณุจุฉ ุงูุฅุจูุงุก:   {kept_pct:.2f}%\")\n",
    "        \n",
    "        logger.subsection(\"ุฅุญุตุงุฆูุงุช ุงูุชุตููุฉ\")\n",
    "        logger.info(f\"ุฃุณุทุฑ ูุงุฑุบุฉ ูุญุฐููุฉ:     {self.stats.empty_lines_removed:,}\")\n",
    "        logger.info(f\"ุฃุณุทุฑ ูุตูุฑุฉ ูุญุฐููุฉ:     {self.stats.short_lines_removed:,}\")\n",
    "        logger.info(f\"ุฃุณุทุฑ ุทูููุฉ ููุตูุตุฉ:     {self.stats.long_lines_truncated:,}\")\n",
    "        \n",
    "        logger.subsection(\"ุฅุญุตุงุฆูุงุช ุงูุชุทุจูุน\")\n",
    "        logger.info(f\"ุชุดููู ูุญุฐูู:           {self.stats.diacritics_removed:,}\")\n",
    "        logger.info(f\"ุฃูู ููุญุฏุฉ:             {self.stats.alef_normalized:,}\")\n",
    "        logger.info(f\"ุชุฑููู ููุญุฏ:            {self.stats.punct_normalized:,}\")\n",
    "        logger.info(f\"ุฃุฑูุงู ููุญุฏุฉ:           {self.stats.numbers_normalized:,}\")\n",
    "        logger.info(f\"ูุงุชููู ูุญุฐูู:          {self.stats.latin_removed:,}\")\n",
    "        logger.info(f\"OOV ูุญุฐูู:             {self.stats.oov_removed:,}\")\n",
    "        logger.info(f\"ุชุฑููู ูุชุชุงุจุน ูุตูุญ:     {self.stats.consecutive_punct_fixed:,}\")\n",
    "\n",
    "\n",
    "# ุฅูุดุงุก ุงููุนุงูุฌ\n",
    "preprocessor = ArabicTextPreprocessor(config)\n",
    "logger.success(\"ุชู ุชููุฆุฉ ุงููุนุงูุฌ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587b4712",
   "metadata": {},
   "source": [
    "### ุงุฎุชุจุงุฑ ุฎุท ุงูุฃูุงุจูุจ ุงููุงูู"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d98ce523",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "๐งช ุงุฎุชุจุงุฑ ุฎุท ุงูุฃูุงุจูุจ ุงููุงูู\n",
      "======================================================================\n",
      "ูุนุงูุฌุฉ ุญุงูุงุช ุงูุงุฎุชุจุงุฑ:\n",
      "\n",
      "ุงูุงุฎุชุจุงุฑ 1:\n",
      "   ุงูุฏุฎู:  'ุงูุฃููููู ุงูููุชููุญูุฏูุฉ ููููุธููููุฉ ุฏููููููููุฉ.'\n",
      "   ุงูุฎุฑุฌ:  'ุงูุงูู ุงููุชุญุฏุฉ ููุธูุฉ ุฏูููุฉ.'\n",
      "\n",
      "ุงูุงุฎุชุจุงุฑ 2:\n",
      "   ุงูุฏุฎู:  'ุฃููุงู, ุซุงููุงู; ุซุงูุซุงู?'\n",
      "   ุงูุฎุฑุฌ:  'ุงููุงุ ุซุงููุงุ ุซุงูุซุงุ'\n",
      "\n",
      "ุงูุงุฎุชุจุงุฑ 3:\n",
      "   ุงูุฏุฎู:  'ุฃุญูุฏ ูุฅุจุฑุงููู ูุขุฏู'\n",
      "   ุงูุฎุฑุฌ:  'ุงุญูุฏ ูุงุจุฑุงููู ูุงุฏู'\n",
      "\n",
      "ุงูุงุฎุชุจุงุฑ 4:\n",
      "   ุงูุฏุฎู:  'ูู ุนุงู 2024 ูุตู ุงูุนุฏุฏ ุฅูู 100'\n",
      "   ุงูุฎุฑุฌ:  'ูู ุนุงู ูขููขูค ูุตู ุงูุนุฏุฏ ุงูู ูกูู'\n",
      "\n",
      "ุงูุงุฎุชุจุงุฑ 5:\n",
      "   ุงูุฏุฎู:  'ุงููุซููุฉ A/47/10 ูุงููุฑุงุฑ UNDP/2024'\n",
      "   ุงูุฎุฑุฌ:  'ุงููุซููุฉ ูคูงูกู ูุงููุฑุงุฑ ูขููขูค'\n",
      "\n",
      "ุงูุงุฎุชุจุงุฑ 6:\n",
      "   ุงูุฏุฎู:  'ูุงุฐุงุุุ ูุฐุง ุตุญูุญ...'\n",
      "   ุงูุฎุฑุฌ:  'ูุงุฐุงุ ูุฐุง ุตุญูุญ.'\n",
      "\n",
      "ุงูุงุฎุชุจุงุฑ 7:\n",
      "   ุงูุฏุฎู:  'ุงููุต   ูุน    ูุณุงูุงุช   ูุซูุฑุฉ'\n",
      "   ุงูุฎุฑุฌ:  'ุงููุต ูุน ูุณุงูุงุช ูุซูุฑุฉ'\n",
      "\n",
      "ุงูุงุฎุชุจุงุฑ 8:\n",
      "   ุงูุฏุฎู:  'ูุนู'\n",
      "   ุงูุฎุฑุฌ:  [ุชูุช ุงูุชุตููุฉ]\n",
      "\n",
      "ุงูุงุฎุชุจุงุฑ 9:\n",
      "   ุงูุฏุฎู:  'ููููุงูู ุฃุญูุฏ: ูุฐุง ููููููู ุฌูุฏููุงู,, ูุงููู!!'\n",
      "   ุงูุฎุฑุฌ:  'ููุงู ุงุญูุฏ: ูุฐุง ููู ุฌุฏุงุ ูุงููู!'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ุงุฎุชุจุงุฑ ุฎุท ุงูุฃูุงุจูุจ ุงููุงูู\n",
    "# ============================================================================\n",
    "\n",
    "logger.section(\"๐งช ุงุฎุชุจุงุฑ ุฎุท ุงูุฃูุงุจูุจ ุงููุงูู\")\n",
    "\n",
    "# ุญุงูุงุช ุงุฎุชุจุงุฑ ุชุบุทู ูุดููุงุช ูุชููุนุฉ\n",
    "test_cases = [\n",
    "    # ุชุดููู\n",
    "    \"ุงูุฃููููู ุงูููุชููุญูุฏูุฉ ููููุธููููุฉ ุฏููููููููุฉ.\",\n",
    "    \n",
    "    # ุชุฑููู ูุฎุชูุท\n",
    "    \"ุฃููุงู, ุซุงููุงู; ุซุงูุซุงู?\",\n",
    "    \n",
    "    # ุฃุดูุงู ุงูุฃูู\n",
    "    \"ุฃุญูุฏ ูุฅุจุฑุงููู ูุขุฏู\",\n",
    "    \n",
    "    # ุฃุฑูุงู\n",
    "    \"ูู ุนุงู 2024 ูุตู ุงูุนุฏุฏ ุฅูู 100\",\n",
    "    \n",
    "    # ูุต ูุงุชููู\n",
    "    \"ุงููุซููุฉ A/47/10 ูุงููุฑุงุฑ UNDP/2024\",\n",
    "    \n",
    "    # ุชุฑููู ูุชุชุงุจุน\n",
    "    \"ูุงุฐุงุุุ ูุฐุง ุตุญูุญ...\",\n",
    "    \n",
    "    # ูุดููุงุช ูุณุงูุงุช\n",
    "    \"ุงููุต   ูุน    ูุณุงูุงุช   ูุซูุฑุฉ\",\n",
    "    \n",
    "    # ุฌููุฉ ูุตูุฑุฉ (ูุฌุจ ุฃู ุชุญุฐู)\n",
    "    \"ูุนู\",\n",
    "    \n",
    "    # ูุดููุงุช ูุฌูุนุฉ\n",
    "    \"ููููุงูู ุฃุญูุฏ: ูุฐุง ููููููู ุฌูุฏููุงู,, ูุงููู!!\",\n",
    "]\n",
    "\n",
    "logger.info(\"ูุนุงูุฌุฉ ุญุงูุงุช ุงูุงุฎุชุจุงุฑ:\\n\")\n",
    "\n",
    "for i, test in enumerate(test_cases, 1):\n",
    "    result = preprocessor.preprocess_line(test, apply_optional=False)\n",
    "    logger.info(f\"ุงูุงุฎุชุจุงุฑ {i}:\")\n",
    "    logger.info(f\"   ุงูุฏุฎู:  '{test}'\")\n",
    "    if result:\n",
    "        logger.info(f\"   ุงูุฎุฑุฌ:  '{result}'\")\n",
    "    else:\n",
    "        logger.info(f\"   ุงูุฎุฑุฌ:  [ุชูุช ุงูุชุตููุฉ]\")\n",
    "    logger.info(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85854011",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. ุงูุฌุฒุก 5: ุงููุญุต ุจุนุฏ ุงููุนุงูุฌุฉ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a07d50b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ุงููุณู 6: ุงููุญุต ุจุนุฏ ุงููุนุงูุฌุฉ\n",
    "# ============================================================================\n",
    "\n",
    "def inspect_preprocessed_data(file_path: str, sample_size: int = 100000) -> Dict:\n",
    "    \"\"\"\n",
    "    ูุญุต ุงูุจูุงูุงุช ุงููุนุงูุฌุฉ ููุชุญูู ูู ุงูุฌูุฏุฉ.\n",
    "    \n",
    "    ุงููุนุงููุงุช:\n",
    "    -----------\n",
    "    file_path : str\n",
    "        ูุณุงุฑ ุงูููู ุงููุนุงูุฌ\n",
    "    sample_size : int\n",
    "        ุนุฏุฏ ุงูุฃุณุทุฑ ูููุญุต\n",
    "        \n",
    "    ุชุฑุฌุน:\n",
    "    --------\n",
    "    Dict\n",
    "        ูุชุงุฆุฌ ุงููุญุต\n",
    "    \"\"\"\n",
    "    logger.section(\"๐ ูุญุต ูุง ุจุนุฏ ุงููุนุงูุฌุฉ\")\n",
    "    logger.info(f\"ุฌุงุฑู ูุญุต: {file_path}\")\n",
    "    \n",
    "    stats = {\n",
    "        'total_lines': 0,\n",
    "        'total_words': 0,\n",
    "        'total_chars': 0,\n",
    "        'word_counts': [],\n",
    "        'remaining_issues': {\n",
    "            'diacritics': 0,\n",
    "            'latin_letters': 0,\n",
    "            'western_numbers': 0,\n",
    "            'latin_punct': 0,\n",
    "            'consecutive_punct': 0,\n",
    "            'alef_variations': 0,\n",
    "        },\n",
    "        'punctuation_dist': Counter(),\n",
    "        'sample_lines': [],\n",
    "    }\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        logger.error(f\"ุงูููู ุบูุฑ ููุฌูุฏ: {file_path}\")\n",
    "        return stats\n",
    "    \n",
    "    # ุฃููุงุท ูููุญุต\n",
    "    diacritics_pattern = re.compile(r'[\\u064B-\\u0652]')\n",
    "    latin_pattern = re.compile(r'[A-Za-z]')\n",
    "    western_num_pattern = re.compile(r'[0-9]')\n",
    "    consecutive_punct_pattern = re.compile(r'[ุุุ.,:;?!]{2,}')\n",
    "    alef_var_pattern = re.compile(r'[ุฃุฅุขูฑ]')\n",
    "    arabic_word_pattern = re.compile(r'[\\u0600-\\u06FF]+')\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i >= sample_size:\n",
    "                break\n",
    "            \n",
    "            line = line.rstrip('\\n')\n",
    "            stats['total_lines'] += 1\n",
    "            stats['total_chars'] += len(line)\n",
    "            \n",
    "            words = arabic_word_pattern.findall(line)\n",
    "            stats['total_words'] += len(words)\n",
    "            stats['word_counts'].append(len(words))\n",
    "            \n",
    "            # ุชุฎุฒูู ุนููุฉ ุฃุณุทุฑ\n",
    "            if len(stats['sample_lines']) < 10:\n",
    "                stats['sample_lines'].append(line)\n",
    "            \n",
    "            # ุงูุชุญูู ูู ุงููุดููุงุช ุงููุชุจููุฉ\n",
    "            if diacritics_pattern.search(line):\n",
    "                stats['remaining_issues']['diacritics'] += 1\n",
    "            if latin_pattern.search(line):\n",
    "                stats['remaining_issues']['latin_letters'] += 1\n",
    "            if western_num_pattern.search(line):\n",
    "                stats['remaining_issues']['western_numbers'] += 1\n",
    "            if consecutive_punct_pattern.search(line):\n",
    "                stats['remaining_issues']['consecutive_punct'] += 1\n",
    "            if alef_var_pattern.search(line):\n",
    "                stats['remaining_issues']['alef_variations'] += 1\n",
    "            \n",
    "            # ุนุฏ ุงูุชุฑููู\n",
    "            for char in line:\n",
    "                if char in VALID_PUNCTUATION:\n",
    "                    stats['punctuation_dist'][char] += 1\n",
    "    \n",
    "    # ุนุฑุถ ุงููุชุงุฆุฌ\n",
    "    logger.subsection(\"ุฅุญุตุงุฆูุงุช ุฃุณุงุณูุฉ\")\n",
    "    logger.info(f\"ุฅุฌูุงูู ุงูุฃุณุทุฑ: {stats['total_lines']:,}\")\n",
    "    logger.info(f\"ุฅุฌูุงูู ุงููููุงุช: {stats['total_words']:,}\")\n",
    "    logger.info(f\"ุฅุฌูุงูู ุงูุญุฑูู: {stats['total_chars']:,}\")\n",
    "    \n",
    "    if stats['word_counts']:\n",
    "        word_arr = np.array(stats['word_counts'])\n",
    "        logger.info(f\"ูุชูุณุท ุงููููุงุช/ุณุทุฑ: {np.mean(word_arr):.2f}\")\n",
    "        logger.info(f\"ุงูุญุฏ ุงูุฃุฏูู: {np.min(word_arr)}\")\n",
    "        logger.info(f\"ุงูุญุฏ ุงูุฃูุตู: {np.max(word_arr)}\")\n",
    "    \n",
    "    logger.subsection(\"ูุญุต ุงููุดููุงุช ุงููุชุจููุฉ\")\n",
    "    total_issues = sum(stats['remaining_issues'].values())\n",
    "    if total_issues == 0:\n",
    "        logger.success(\"ูู ูุชู ุงูุนุซูุฑ ุนูู ูุดููุงุช! ุงูุจูุงูุงุช ูุธููุฉ.\")\n",
    "    else:\n",
    "        logger.warn(f\"ุชู ุงูุนุซูุฑ ุนูู {total_issues} ูุดููุฉ ูุญุชููุฉ:\")\n",
    "        for issue, count in stats['remaining_issues'].items():\n",
    "            if count > 0:\n",
    "                logger.info(f\"   {issue}: {count:,} ุณุทุฑ\")\n",
    "    \n",
    "    logger.subsection(\"ุชูุฒูุน ุงูุชุฑููู\")\n",
    "    for char, count in stats['punctuation_dist'].most_common():\n",
    "        name = ARABIC_PUNCTUATION.get(char, 'ุบูุฑ ูุนุฑูู')\n",
    "        logger.info(f\"   '{char}' ({name}): {count:,}\")\n",
    "    \n",
    "    logger.subsection(\"ุนููุฉ ุฃุณุทุฑ\")\n",
    "    for i, line in enumerate(stats['sample_lines'][:5], 1):\n",
    "        display = line[:80] + \"...\" if len(line) > 80 else line\n",
    "        logger.info(f\"   {i}. {display}\")\n",
    "    \n",
    "    return stats\n",
    "\n",
    "\n",
    "# ุณูุชู ุชุดุบูู ูุฐุง ุจุนุฏ ูุนุงูุฌุฉ ุงูุจูุงูุงุช"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c54c0e",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. ุงูุฌุฒุก 6: ุญูุธ ุงูุจูุงูุงุช ุงููุนุงูุฌุฉ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ad4423a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ุงููุณู 7: ูุนุงูุฌุฉ ูุญูุธ ุงูุจูุงูุงุช\n",
    "# ============================================================================\n",
    "\n",
    "def run_preprocessing_pipeline(\n",
    "    input_dir: str,\n",
    "    output_dir: str,\n",
    "    config: PreprocessingConfig,\n",
    "    create_variants: bool = True,\n",
    "    sample_size: Optional[int] = None\n",
    "):\n",
    "    \"\"\"\n",
    "    ุชุดุบูู ุฎุท ุฃูุงุจูุจ ุงููุนุงูุฌุฉ ุงููุงูู ูุญูุธ ุงููุชุงุฆุฌ.\n",
    "    \n",
    "    ููุดุฆ ุนุฏุฉ ูุชุบูุฑุงุช ูู ุงููุฎุฑุฌุงุช:\n",
    "    1. mandatory_only.txt - ูุนุงูุฌุฉ ุฅูุฒุงููุฉ ููุท\n",
    "    2. with_waw_separation.txt - + ูุตู ุงููุงู\n",
    "    3. with_number_tokens.txt - + ุงุณุชุจุฏุงู ุงูุฃุฑูุงู\n",
    "    4. full_preprocessing.txt - ุฌููุน ุงูุฎุทูุงุช\n",
    "    \n",
    "    ุงููุนุงููุงุช:\n",
    "    -----------\n",
    "    input_dir : str\n",
    "        ูุณุงุฑ ูุฌูุฏ ุงููุฏุฎูุงุช\n",
    "    output_dir : str\n",
    "        ูุณุงุฑ ูุฌูุฏ ุงููุฎุฑุฌุงุช\n",
    "    config : PreprocessingConfig\n",
    "        ูุงุฆู ุงูุฅุนุฏุงุฏุงุช\n",
    "    create_variants : bool\n",
    "        ุฅูุดุงุก ูุชุบูุฑุงุช ูุชุนุฏุฏุฉ ุฃู ูุง\n",
    "    sample_size : Optional[int]\n",
    "        ุญุฏ ุงููุนุงูุฌุฉ (None = ูุงูู)\n",
    "    \"\"\"\n",
    "    logger.section(\"๐ ุชุดุบูู ุฎุท ุฃูุงุจูุจ ุงููุนุงูุฌุฉ\")\n",
    "    \n",
    "    # ุฅูุดุงุก ูุฌูุฏ ุงููุฎุฑุฌุงุช\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # ============================================\n",
    "    # ุงููุชุบูุฑ 1: ุงููุนุงูุฌุฉ ุงูุฅูุฒุงููุฉ ููุท\n",
    "    # ============================================\n",
    "    logger.subsection(\"ุงููุชุบูุฑ 1: ุงููุนุงูุฌุฉ ุงูุฅูุฒุงููุฉ ููุท\")\n",
    "    \n",
    "    output_file_mandatory = os.path.join(output_dir, \"mandatory_only.txt\")\n",
    "    \n",
    "    # ุถูุงู ุฅููุงู ุงูุฎุทูุงุช ุงูุงุฎุชูุงุฑูุฉ\n",
    "    config.separate_waw_conjunction = False\n",
    "    config.replace_numbers_with_token = False\n",
    "    config.remove_foreign_terms = False\n",
    "    \n",
    "    preprocessor = ArabicTextPreprocessor(config)\n",
    "    stats_mandatory = preprocessor.process_dataset(\n",
    "        input_dir, \n",
    "        output_file_mandatory,\n",
    "        apply_optional=False,\n",
    "        sample_size=sample_size\n",
    "    )\n",
    "    \n",
    "    # ุญูุธ ุงูุฅุญุตุงุฆูุงุช\n",
    "    stats_file = os.path.join(output_dir, \"stats_mandatory.json\")\n",
    "    with open(stats_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump({\n",
    "            'total_input': stats_mandatory.total_input_lines,\n",
    "            'total_output': stats_mandatory.total_output_lines,\n",
    "            'empty_removed': stats_mandatory.empty_lines_removed,\n",
    "            'short_removed': stats_mandatory.short_lines_removed,\n",
    "            'long_truncated': stats_mandatory.long_lines_truncated,\n",
    "        }, f, indent=2)\n",
    "    \n",
    "    if not create_variants:\n",
    "        return\n",
    "    \n",
    "    # ============================================\n",
    "    # ุงููุชุบูุฑ 2: ูุน ูุตู ุงููุงู\n",
    "    # ============================================\n",
    "    logger.subsection(\"ุงููุชุบูุฑ 2: ูุน ูุตู ุงููุงู\")\n",
    "    \n",
    "    config.separate_waw_conjunction = True\n",
    "    preprocessor = ArabicTextPreprocessor(config)\n",
    "    \n",
    "    output_file_waw = os.path.join(output_dir, \"with_waw_separation.txt\")\n",
    "    stats_waw = preprocessor.process_dataset(\n",
    "        input_dir,\n",
    "        output_file_waw,\n",
    "        apply_optional=True,\n",
    "        sample_size=sample_size\n",
    "    )\n",
    "    \n",
    "    config.separate_waw_conjunction = False  # ุฅุนุงุฏุฉ ุถุจุท\n",
    "    \n",
    "    # ============================================\n",
    "    # ุงููุชุบูุฑ 3: ูุน ุฑููุฒ ุงูุฃุฑูุงู\n",
    "    # ============================================\n",
    "    logger.subsection(\"ุงููุชุบูุฑ 3: ูุน ุฑููุฒ ุงูุฃุฑูุงู\")\n",
    "    \n",
    "    config.replace_numbers_with_token = True\n",
    "    preprocessor = ArabicTextPreprocessor(config)\n",
    "    \n",
    "    output_file_nums = os.path.join(output_dir, \"with_number_tokens.txt\")\n",
    "    stats_nums = preprocessor.process_dataset(\n",
    "        input_dir,\n",
    "        output_file_nums,\n",
    "        apply_optional=True,\n",
    "        sample_size=sample_size\n",
    "    )\n",
    "    \n",
    "    config.replace_numbers_with_token = False  # ุฅุนุงุฏุฉ ุถุจุท\n",
    "    \n",
    "    # ============================================\n",
    "    # ุงููุชุบูุฑ 4: ุงููุนุงูุฌุฉ ุงููุงููุฉ\n",
    "    # ============================================\n",
    "    logger.subsection(\"ุงููุชุบูุฑ 4: ุงููุนุงูุฌุฉ ุงููุงููุฉ (ูู ุงูุฎูุงุฑุงุช)\")\n",
    "    \n",
    "    config.separate_waw_conjunction = True\n",
    "    config.replace_numbers_with_token = True\n",
    "    config.remove_foreign_terms = True\n",
    "    \n",
    "    preprocessor = ArabicTextPreprocessor(config)\n",
    "    \n",
    "    output_file_full = os.path.join(output_dir, \"full_preprocessing.txt\")\n",
    "    stats_full = preprocessor.process_dataset(\n",
    "        input_dir,\n",
    "        output_file_full,\n",
    "        apply_optional=True,\n",
    "        sample_size=sample_size\n",
    "    )\n",
    "    \n",
    "    logger.section(\"โ ุชูุช ุงููุนุงูุฌุฉ\")\n",
    "    logger.info(f\"ุชู ุญูุธ ุงููููุงุช ูู: {output_dir}\")\n",
    "    logger.info(\"ุงููููุงุช ุงูุชู ุชู ุฅูุดุงุคูุง:\")\n",
    "    logger.info(f\"   1. mandatory_only.txt\")\n",
    "    logger.info(f\"   2. with_waw_separation.txt\")\n",
    "    logger.info(f\"   3. with_number_tokens.txt\")\n",
    "    logger.info(f\"   4. full_preprocessing.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8989d49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "โก ุชูููุฐ ุฎุท ุฃูุงุจูุจ ุงููุนุงูุฌุฉ\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "๐ ุชุดุบูู ุฎุท ุฃูุงุจูุจ ุงููุนุงูุฌุฉ\n",
      "======================================================================\n",
      "\n",
      "--- ุงููุชุบูุฑ 1: ุงููุนุงูุฌุฉ ุงูุฅูุฒุงููุฉ ููุท ---\n",
      "\n",
      "======================================================================\n",
      "๐ ูุนุงูุฌุฉ ูุฌููุนุฉ ุงูุจูุงูุงุช\n",
      "======================================================================\n",
      "ุงููุฏุฎูุงุช: ../SSAC-UNPC\n",
      "ุงููุฎุฑุฌุงุช: preprocessed_data_ar\\mandatory_only.txt\n",
      "ุชุทุจูู ุงูุงุฎุชูุงุฑู: False\n",
      "ูุนุงูุฌุฉ ุนููุฉ ูู 100,000 ุณุทุฑ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ุฌุงุฑู ุงููุนุงูุฌุฉ: 100%|โโโโโโโโโโ| 100000/100000 [00:11<00:00, 8540.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "๐ ุฅุญุตุงุฆูุงุช ุงููุนุงูุฌุฉ\n",
      "======================================================================\n",
      "ุฃุณุทุฑ ุงููุฏุฎูุงุช:  100,000\n",
      "ุฃุณุทุฑ ุงููุฎุฑุฌุงุช:  96,756\n",
      "ูุณุจุฉ ุงูุฅุจูุงุก:   96.76%\n",
      "\n",
      "--- ุฅุญุตุงุฆูุงุช ุงูุชุตููุฉ ---\n",
      "ุฃุณุทุฑ ูุงุฑุบุฉ ูุญุฐููุฉ:     0\n",
      "ุฃุณุทุฑ ูุตูุฑุฉ ูุญุฐููุฉ:     3,244\n",
      "ุฃุณุทุฑ ุทูููุฉ ููุตูุตุฉ:     771\n",
      "\n",
      "--- ุฅุญุตุงุฆูุงุช ุงูุชุทุจูุน ---\n",
      "ุชุดููู ูุญุฐูู:           1,091\n",
      "ุฃูู ููุญุฏุฉ:             0\n",
      "ุชุฑููู ููุญุฏ:            1,296\n",
      "ุฃุฑูุงู ููุญุฏุฉ:           6,829\n",
      "ูุงุชููู ูุญุฐูู:          6,906\n",
      "OOV ูุญุฐูู:             32,548\n",
      "ุชุฑููู ูุชุชุงุจุน ูุตูุญ:     11\n",
      "\n",
      "--- ุงููุชุบูุฑ 2: ูุน ูุตู ุงููุงู ---\n",
      "\n",
      "======================================================================\n",
      "๐ ูุนุงูุฌุฉ ูุฌููุนุฉ ุงูุจูุงูุงุช\n",
      "======================================================================\n",
      "ุงููุฏุฎูุงุช: ../SSAC-UNPC\n",
      "ุงููุฎุฑุฌุงุช: preprocessed_data_ar\\with_waw_separation.txt\n",
      "ุชุทุจูู ุงูุงุฎุชูุงุฑู: True\n",
      "ูุนุงูุฌุฉ ุนููุฉ ูู 100,000 ุณุทุฑ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ุฌุงุฑู ุงููุนุงูุฌุฉ: 100%|โโโโโโโโโโ| 100000/100000 [00:12<00:00, 7828.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "๐ ุฅุญุตุงุฆูุงุช ุงููุนุงูุฌุฉ\n",
      "======================================================================\n",
      "ุฃุณุทุฑ ุงููุฏุฎูุงุช:  100,000\n",
      "ุฃุณุทุฑ ุงููุฎุฑุฌุงุช:  96,813\n",
      "ูุณุจุฉ ุงูุฅุจูุงุก:   96.81%\n",
      "\n",
      "--- ุฅุญุตุงุฆูุงุช ุงูุชุตููุฉ ---\n",
      "ุฃุณุทุฑ ูุงุฑุบุฉ ูุญุฐููุฉ:     0\n",
      "ุฃุณุทุฑ ูุตูุฑุฉ ูุญุฐููุฉ:     3,187\n",
      "ุฃุณุทุฑ ุทูููุฉ ููุตูุตุฉ:     946\n",
      "\n",
      "--- ุฅุญุตุงุฆูุงุช ุงูุชุทุจูุน ---\n",
      "ุชุดููู ูุญุฐูู:           1,091\n",
      "ุฃูู ููุญุฏุฉ:             0\n",
      "ุชุฑููู ููุญุฏ:            1,296\n",
      "ุฃุฑูุงู ููุญุฏุฉ:           6,829\n",
      "ูุงุชููู ูุญุฐูู:          6,906\n",
      "OOV ูุญุฐูู:             32,548\n",
      "ุชุฑููู ูุชุชุงุจุน ูุตูุญ:     11\n",
      "\n",
      "--- ุงููุชุบูุฑ 3: ูุน ุฑููุฒ ุงูุฃุฑูุงู ---\n",
      "\n",
      "======================================================================\n",
      "๐ ูุนุงูุฌุฉ ูุฌููุนุฉ ุงูุจูุงูุงุช\n",
      "======================================================================\n",
      "ุงููุฏุฎูุงุช: ../SSAC-UNPC\n",
      "ุงููุฎุฑุฌุงุช: preprocessed_data_ar\\with_number_tokens.txt\n",
      "ุชุทุจูู ุงูุงุฎุชูุงุฑู: True\n",
      "ูุนุงูุฌุฉ ุนููุฉ ูู 100,000 ุณุทุฑ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ุฌุงุฑู ุงููุนุงูุฌุฉ: 100%|โโโโโโโโโโ| 100000/100000 [00:11<00:00, 8933.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "๐ ุฅุญุตุงุฆูุงุช ุงููุนุงูุฌุฉ\n",
      "======================================================================\n",
      "ุฃุณุทุฑ ุงููุฏุฎูุงุช:  100,000\n",
      "ุฃุณุทุฑ ุงููุฎุฑุฌุงุช:  96,414\n",
      "ูุณุจุฉ ุงูุฅุจูุงุก:   96.41%\n",
      "\n",
      "--- ุฅุญุตุงุฆูุงุช ุงูุชุตููุฉ ---\n",
      "ุฃุณุทุฑ ูุงุฑุบุฉ ูุญุฐููุฉ:     0\n",
      "ุฃุณุทุฑ ูุตูุฑุฉ ูุญุฐููุฉ:     3,586\n",
      "ุฃุณุทุฑ ุทูููุฉ ููุตูุตุฉ:     714\n",
      "\n",
      "--- ุฅุญุตุงุฆูุงุช ุงูุชุทุจูุน ---\n",
      "ุชุดููู ูุญุฐูู:           1,091\n",
      "ุฃูู ููุญุฏุฉ:             0\n",
      "ุชุฑููู ููุญุฏ:            1,296\n",
      "ุฃุฑูุงู ููุญุฏุฉ:           6,829\n",
      "ูุงุชููู ูุญุฐูู:          6,906\n",
      "OOV ูุญุฐูู:             32,548\n",
      "ุชุฑููู ูุชุชุงุจุน ูุตูุญ:     11\n",
      "\n",
      "--- ุงููุชุบูุฑ 4: ุงููุนุงูุฌุฉ ุงููุงููุฉ (ูู ุงูุฎูุงุฑุงุช) ---\n",
      "\n",
      "======================================================================\n",
      "๐ ูุนุงูุฌุฉ ูุฌููุนุฉ ุงูุจูุงูุงุช\n",
      "======================================================================\n",
      "ุงููุฏุฎูุงุช: ../SSAC-UNPC\n",
      "ุงููุฎุฑุฌุงุช: preprocessed_data_ar\\full_preprocessing.txt\n",
      "ุชุทุจูู ุงูุงุฎุชูุงุฑู: True\n",
      "ูุนุงูุฌุฉ ุนููุฉ ูู 100,000 ุณุทุฑ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ุฌุงุฑู ุงููุนุงูุฌุฉ: 100%|โโโโโโโโโโ| 100000/100000 [00:12<00:00, 7978.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "๐ ุฅุญุตุงุฆูุงุช ุงููุนุงูุฌุฉ\n",
      "======================================================================\n",
      "ุฃุณุทุฑ ุงููุฏุฎูุงุช:  100,000\n",
      "ุฃุณุทุฑ ุงููุฎุฑุฌุงุช:  96,486\n",
      "ูุณุจุฉ ุงูุฅุจูุงุก:   96.49%\n",
      "\n",
      "--- ุฅุญุตุงุฆูุงุช ุงูุชุตููุฉ ---\n",
      "ุฃุณุทุฑ ูุงุฑุบุฉ ูุญุฐููุฉ:     0\n",
      "ุฃุณุทุฑ ูุตูุฑุฉ ูุญุฐููุฉ:     3,514\n",
      "ุฃุณุทุฑ ุทูููุฉ ููุตูุตุฉ:     867\n",
      "\n",
      "--- ุฅุญุตุงุฆูุงุช ุงูุชุทุจูุน ---\n",
      "ุชุดููู ูุญุฐูู:           1,091\n",
      "ุฃูู ููุญุฏุฉ:             0\n",
      "ุชุฑููู ููุญุฏ:            1,296\n",
      "ุฃุฑูุงู ููุญุฏุฉ:           6,829\n",
      "ูุงุชููู ูุญุฐูู:          6,906\n",
      "OOV ูุญุฐูู:             32,548\n",
      "ุชุฑููู ูุชุชุงุจุน ูุตูุญ:     11\n",
      "\n",
      "======================================================================\n",
      "โ ุชูุช ุงููุนุงูุฌุฉ\n",
      "======================================================================\n",
      "ุชู ุญูุธ ุงููููุงุช ูู: preprocessed_data_ar\n",
      "ุงููููุงุช ุงูุชู ุชู ุฅูุดุงุคูุง:\n",
      "   1. mandatory_only.txt\n",
      "   2. with_waw_separation.txt\n",
      "   3. with_number_tokens.txt\n",
      "   4. full_preprocessing.txt\n",
      "\n",
      "======================================================================\n",
      "๐ ูุญุต ูุง ุจุนุฏ ุงููุนุงูุฌุฉ\n",
      "======================================================================\n",
      "ุฌุงุฑู ูุญุต: preprocessed_data_ar\\mandatory_only.txt\n",
      "\n",
      "--- ุฅุญุตุงุฆูุงุช ุฃุณุงุณูุฉ ---\n",
      "ุฅุฌูุงูู ุงูุฃุณุทุฑ: 50,000\n",
      "ุฅุฌูุงูู ุงููููุงุช: 1,355,722\n",
      "ุฅุฌูุงูู ุงูุญุฑูู: 8,304,590\n",
      "ูุชูุณุท ุงููููุงุช/ุณุทุฑ: 27.11\n",
      "ุงูุญุฏ ุงูุฃุฏูู: 3\n",
      "ุงูุญุฏ ุงูุฃูุตู: 122\n",
      "\n",
      "--- ูุญุต ุงููุดููุงุช ุงููุชุจููุฉ ---\n",
      "โ๏ธ  ุชุญุฐูุฑ: ุชู ุงูุนุซูุฑ ุนูู 124 ูุดููุฉ ูุญุชููุฉ:\n",
      "   consecutive_punct: 124 ุณุทุฑ\n",
      "\n",
      "--- ุชูุฒูุน ุงูุชุฑููู ---\n",
      "   'ุ' (ูุงุตูุฉ ุนุฑุจูุฉ): 69,042\n",
      "   '.' (ููุทุฉ): 49,973\n",
      "   'ุ' (ูุงุตูุฉ ููููุทุฉ ุนุฑุจูุฉ): 6,760\n",
      "   ':' (ููุทุชุงู ุฑุฃุณูุชุงู): 1,724\n",
      "   'ุ' (ุนูุงูุฉ ุงุณุชููุงู ุนุฑุจูุฉ): 68\n",
      "   '!' (ุนูุงูุฉ ุชุนุฌุจ): 3\n",
      "\n",
      "--- ุนููุฉ ุฃุณุทุฑ ---\n",
      "   1. ูฃ ูุนููุง ุจุทูุจ ุงูุฌูุนูุฉ ุงูุนุงูุฉ ุงููุงุฑุฏ ูู ุงูููุฑุฉ ูฅ ูู ุงููุฑุงุฑ ุงููุฐููุฑ ุงุนูุงูุ ูุฌู ุงูุงู...\n",
      "   2. )ูก( ุงููุซุงุฆู ุงูุฑุณููุฉ ููุฌูุนูุฉ ุงูุนุงูุฉุ ุงูุฏูุฑุฉ ุงูุณุงุจุนุฉ ูุงูุงุฑุจุนููุ ุงูููุญู ุฑูู ูกู (ูคูงูก...\n",
      "   3. )ูข( ูุชุฑุฏ ุงูุถุง ุงูุงุดุงุฑุงุช ุงูู ูุณุงูุฉ ุงูุดุงุก ูุถุงุก ุฌูุงุฆู ุฏููู ูู ุงููุซููุฉ.\n",
      "   4. ูกุ ุงููุณุชูุณุฎ ูููุง ุงูุชุนูููุงุช ูุงูููุงุญุธุงุช ุงูููุฏูุฉ ูู ุงูุญูููุงุช ุจุดุงู ูุดุฑูุน ูุฏููุฉ ุงูุฌุฑุง...\n",
      "   5. ูก ุชูุฏู ุงุณุชุฑุงููุง ุงูุชุนูููุงุช ุงูุชุงููุฉ ุนูู ุชูุฑูุฑ ุงููุฑูู ุงูุนุงูู ุงููุนูู ุจูุณุงูุฉ ุงูุดุงุก ูุถ...\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ุชูููุฐ ุงููุนุงูุฌุฉ\n",
    "# ============================================================================\n",
    "\n",
    "# ุฅุนุฏุงุฏุงุช ุงูุชูููุฐ\n",
    "EXECUTE_FULL_PIPELINE = True  # ุงุฌุนููุง True ูุชูููุฐ ุงููุนุงูุฌุฉ\n",
    "SAMPLE_SIZE_FOR_TEST = 100000  # ุงุฌุนููุง None ูููุนุงูุฌุฉ ุงููุงููุฉ\n",
    "\n",
    "if EXECUTE_FULL_PIPELINE:\n",
    "    logger.section(\"โก ุชูููุฐ ุฎุท ุฃูุงุจูุจ ุงููุนุงูุฌุฉ\")\n",
    "    \n",
    "    # ููุงุฎุชุจุงุฑุ ุงุณุชุฎุฏู ุนููุฉ\n",
    "    sample = SAMPLE_SIZE_FOR_TEST  # ุบูุฑูุง ูู None ูููุนุงูุฌุฉ ุงููุงููุฉ\n",
    "    \n",
    "    run_preprocessing_pipeline(\n",
    "        input_dir=config.input_dir,\n",
    "        output_dir=config.output_dir,\n",
    "        config=config,\n",
    "        create_variants=True,\n",
    "        sample_size=sample\n",
    "    )\n",
    "    \n",
    "    # ูุญุต ุงููุงุชุฌ ุงูุฅูุฒุงูู\n",
    "    mandatory_file = os.path.join(config.output_dir, \"mandatory_only.txt\")\n",
    "    if os.path.exists(mandatory_file):\n",
    "        post_stats = inspect_preprocessed_data(mandatory_file, sample_size=50000)\n",
    "else:\n",
    "    logger.info(\"ุชู ุชุฎุทู ุงูุชูููุฐ. ุงุฌุนู EXECUTE_FULL_PIPELINE = True ููุชูููุฐ.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d70bbb6",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. ุงูููุฎุต ูุงูุชูุตูุงุช"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78f80606",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "๐ ููุฎุต ุงููุนุงูุฌุฉ ูุงูุชูุตูุงุช\n",
      "======================================================================\n",
      "\n",
      "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n",
      "โ                        ููุฎุต ุฎุท ุฃูุงุจูุจ ุงููุนุงูุฌุฉ                                 โ\n",
      "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโฃ\n",
      "โ                                                                              โ\n",
      "โ  ุฎุทูุงุช ุงููุนุงูุฌุฉ ุงูุฅูุฒุงููุฉ (ุชุทุจู ุฏุงุฆูุงู):                                     โ\n",
      "โ  โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ                                      โ\n",
      "โ  โ ุฅุฒุงูุฉ ุงูุชุดููู (ุงูุญุฑูุงุช)                                                  โ\n",
      "โ  โ ุชูุญูุฏ ุฃุดูุงู ุงูุฃูู (ุฃุฅุขูฑ -> ุง)                                            โ\n",
      "โ  โ ุชูุญูุฏ ุงูุฃูู ุงูููุตูุฑุฉ (ู -> ู)                                            โ\n",
      "โ  โ ุฅุฒุงูุฉ ุงูุชุทููู (ู)                                                        โ\n",
      "โ  โ ุชูุญูุฏ ุงูุชุฑููู ููุนุฑุจู (,;? -> ุุุ)                                        โ\n",
      "โ  โ ุชูุญูุฏ ุงูุฃุฑูุงู ููุนุฑุจูุฉ (0-9 -> ู-ูฉ)                                       โ\n",
      "โ  โ ุฅุฒุงูุฉ ุงูุญุฑูู ุงููุงุชูููุฉ                                                   โ\n",
      "โ  โ ุฅุฒุงูุฉ ุงูุญุฑูู ุฎุงุฑุฌ ุงููุทุงู (OOV)                                           โ\n",
      "โ  โ ูุนุงูุฌุฉ ุงูุชุฑููู ุงููุชุชุงุจุน                                                  โ\n",
      "โ  โ ุชูุญูุฏ ุงููุณุงูุงุช                                                           โ\n",
      "โ  โ ุฅุถุงูุฉ ูุณุงูุงุช ุงูุชุฑููู                                                     โ\n",
      "โ  โ ุชุตููุฉ ุงูุฃุณุทุฑ ุงููุงุฑุบุฉ                                                     โ\n",
      "โ  โ ุชุตููุฉ ุงูุฌูู ุงููุตูุฑุฉ (<3 ูููุงุช)                                           โ\n",
      "โ  โ ูุต ุงูุฌูู ุงูุทูููุฉ (>100 ูููุฉ)                                             โ\n",
      "โ                                                                              โ\n",
      "โ  ุฎุทูุงุช ุงููุนุงูุฌุฉ ุงูุงุฎุชูุงุฑูุฉ (ููุชุฌุฑูุจ):                                        โ\n",
      "โ  โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ                                         โ\n",
      "โ  โ๏ธ  ูุตู ูุงู ุงูุนุทู (ู + ูููุฉ -> ู ูููุฉ)                                      โ\n",
      "โ  โ๏ธ  ุงุณุชุจุฏุงู ุงูุฃุฑูุงู ุจุฑูุฒ (<NUM>)                                            โ\n",
      "โ  โ๏ธ  ุฅุฒุงูุฉ ูุฑุงุฌุน ุงููุณุชูุฏุงุช (A/47/10)                                         โ\n",
      "โ  โ๏ธ  ุฅุฒุงูุฉ/ุชูููุฒ ูููุงุช ุงูุชููู                                                โ\n",
      "โ  โ๏ธ  ุงุณุชุจุฏุงู ุงููููุงุช ุงููุงุฏุฑุฉ (<UNK>)                                         โ\n",
      "โ                                                                              โ\n",
      "โ  ุงููููุงุช ุงููุงุชุฌุฉ:                                                            โ\n",
      "โ  โโโโโโโโโโโโโโโ                                                             โ\n",
      "โ  ๐ preprocessed_data/                                                       โ\n",
      "โ     โโโ mandatory_only.txt      (ููุตู ุจู ููุนุธู ุงูุชุฌุงุฑุจ)                      โ\n",
      "โ     โโโ with_waw_separation.txt (ูุงุฎุชุจุงุฑ ุชุฃุซูุฑ ูุตู ุงููุงู)                    โ\n",
      "โ     โโโ with_number_tokens.txt  (ูุงุฎุชุจุงุฑ ุชุฃุซูุฑ ุงุณุชุจุฏุงู ุงูุฃุฑูุงู)              โ\n",
      "โ     โโโ full_preprocessing.txt  (ูู ุงูุฎุทูุงุช ูุทุจูุฉ)                           โ\n",
      "โ                                                                              โ\n",
      "โ  ุงูุชูุตูุงุช:                                                                   โ\n",
      "โ  โโโโโโโโโ                                                                   โ\n",
      "โ  1. ุงุจุฏุฃ ุจู mandatory_only.txt ููุชุฌุงุฑุจ ุงูุฃุณุงุณูุฉ                              โ\n",
      "โ  2. ุงุณุชุฎุฏู with_waw_separation.txt ุฅุฐุง ุณุงุนุฏ ูุตู ุงููุงู                        โ\n",
      "โ  3. ุฌุฑุจ with_number_tokens.txt ุฅุฐุง ุณุจุจุช ุงูุฃุฑูุงู ูุดููุงุช                       โ\n",
      "โ  4. ูุงุฑู ุงููุชุงุฆุฌ ูุชุญุฏูุฏ ุงููุนุงูุฌุฉ ุงูุฃูุซู                                      โ\n",
      "โ                                                                              โ\n",
      "โ  ุงูุฎุทูุงุช ุงูุชุงููุฉ:                                                            โ\n",
      "โ  โโโโโโโโโโโโโโโ                                                             โ\n",
      "โ  1. ุชุฑููุฒ ุงูุจูุงูุงุช ุงููุนุงูุฌุฉ (Tokenization)                                   โ\n",
      "โ  2. ุฅูุดุงุก ุชูุณููุงุช ุงูุชุฏุฑูุจ/ุงูุชุญูู/ุงูุงุฎุชุจุงุฑ                                    โ\n",
      "โ  3. ุชูููุฏ ุงูุชุตูููุงุช (Labels) ููููุฉ ุงูุชุณูุณู-ุฅูู-ุชุณูุณู                         โ\n",
      "โ  4. ุชุฏุฑูุจ ูุชูููู ุงูููุงุฐุฌ                                                     โ\n",
      "โ                                                                              โ\n",
      "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ุงููุณู 8: ุงูููุฎุต ูุงูุชูุตูุงุช\n",
    "# ============================================================================\n",
    "\n",
    "logger.section(\"๐ ููุฎุต ุงููุนุงูุฌุฉ ูุงูุชูุตูุงุช\")\n",
    "\n",
    "summary = \"\"\"\n",
    "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n",
    "โ                        ููุฎุต ุฎุท ุฃูุงุจูุจ ุงููุนุงูุฌุฉ                                 โ\n",
    "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโฃ\n",
    "โ                                                                              โ\n",
    "โ  ุฎุทูุงุช ุงููุนุงูุฌุฉ ุงูุฅูุฒุงููุฉ (ุชุทุจู ุฏุงุฆูุงู):                                     โ\n",
    "โ  โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ                                      โ\n",
    "โ  โ ุฅุฒุงูุฉ ุงูุชุดููู (ุงูุญุฑูุงุช)                                                  โ\n",
    "โ  โ ุชูุญูุฏ ุฃุดูุงู ุงูุฃูู (ุฃุฅุขูฑ -> ุง)                                            โ\n",
    "โ  โ ุชูุญูุฏ ุงูุฃูู ุงูููุตูุฑุฉ (ู -> ู)                                            โ\n",
    "โ  โ ุฅุฒุงูุฉ ุงูุชุทููู (ู)                                                        โ\n",
    "โ  โ ุชูุญูุฏ ุงูุชุฑููู ููุนุฑุจู (,;? -> ุุุ)                                        โ\n",
    "โ  โ ุชูุญูุฏ ุงูุฃุฑูุงู ููุนุฑุจูุฉ (0-9 -> ู-ูฉ)                                       โ\n",
    "โ  โ ุฅุฒุงูุฉ ุงูุญุฑูู ุงููุงุชูููุฉ                                                   โ\n",
    "โ  โ ุฅุฒุงูุฉ ุงูุญุฑูู ุฎุงุฑุฌ ุงููุทุงู (OOV)                                           โ\n",
    "โ  โ ูุนุงูุฌุฉ ุงูุชุฑููู ุงููุชุชุงุจุน                                                  โ\n",
    "โ  โ ุชูุญูุฏ ุงููุณุงูุงุช                                                           โ\n",
    "โ  โ ุฅุถุงูุฉ ูุณุงูุงุช ุงูุชุฑููู                                                     โ\n",
    "โ  โ ุชุตููุฉ ุงูุฃุณุทุฑ ุงููุงุฑุบุฉ                                                     โ\n",
    "โ  โ ุชุตููุฉ ุงูุฌูู ุงููุตูุฑุฉ (<3 ูููุงุช)                                           โ\n",
    "โ  โ ูุต ุงูุฌูู ุงูุทูููุฉ (>100 ูููุฉ)                                             โ\n",
    "โ                                                                              โ\n",
    "โ  ุฎุทูุงุช ุงููุนุงูุฌุฉ ุงูุงุฎุชูุงุฑูุฉ (ููุชุฌุฑูุจ):                                        โ\n",
    "โ  โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ                                         โ\n",
    "โ  โ๏ธ  ูุตู ูุงู ุงูุนุทู (ู + ูููุฉ -> ู ูููุฉ)                                      โ\n",
    "โ  โ๏ธ  ุงุณุชุจุฏุงู ุงูุฃุฑูุงู ุจุฑูุฒ (<NUM>)                                            โ\n",
    "โ  โ๏ธ  ุฅุฒุงูุฉ ูุฑุงุฌุน ุงููุณุชูุฏุงุช (A/47/10)                                         โ\n",
    "โ  โ๏ธ  ุฅุฒุงูุฉ/ุชูููุฒ ูููุงุช ุงูุชููู                                                โ\n",
    "โ  โ๏ธ  ุงุณุชุจุฏุงู ุงููููุงุช ุงููุงุฏุฑุฉ (<UNK>)                                         โ\n",
    "โ                                                                              โ\n",
    "โ  ุงููููุงุช ุงููุงุชุฌุฉ:                                                            โ\n",
    "โ  โโโโโโโโโโโโโโโ                                                             โ\n",
    "โ  ๐ preprocessed_data/                                                       โ\n",
    "โ     โโโ mandatory_only.txt      (ููุตู ุจู ููุนุธู ุงูุชุฌุงุฑุจ)                      โ\n",
    "โ     โโโ with_waw_separation.txt (ูุงุฎุชุจุงุฑ ุชุฃุซูุฑ ูุตู ุงููุงู)                    โ\n",
    "โ     โโโ with_number_tokens.txt  (ูุงุฎุชุจุงุฑ ุชุฃุซูุฑ ุงุณุชุจุฏุงู ุงูุฃุฑูุงู)              โ\n",
    "โ     โโโ full_preprocessing.txt  (ูู ุงูุฎุทูุงุช ูุทุจูุฉ)                           โ\n",
    "โ                                                                              โ\n",
    "โ  ุงูุชูุตูุงุช:                                                                   โ\n",
    "โ  โโโโโโโโโ                                                                   โ\n",
    "โ  1. ุงุจุฏุฃ ุจู mandatory_only.txt ููุชุฌุงุฑุจ ุงูุฃุณุงุณูุฉ                              โ\n",
    "โ  2. ุงุณุชุฎุฏู with_waw_separation.txt ุฅุฐุง ุณุงุนุฏ ูุตู ุงููุงู                        โ\n",
    "โ  3. ุฌุฑุจ with_number_tokens.txt ุฅุฐุง ุณุจุจุช ุงูุฃุฑูุงู ูุดููุงุช                       โ\n",
    "โ  4. ูุงุฑู ุงููุชุงุฆุฌ ูุชุญุฏูุฏ ุงููุนุงูุฌุฉ ุงูุฃูุซู                                      โ\n",
    "โ                                                                              โ\n",
    "โ  ุงูุฎุทูุงุช ุงูุชุงููุฉ:                                                            โ\n",
    "โ  โโโโโโโโโโโโโโโ                                                             โ\n",
    "โ  1. ุชุฑููุฒ ุงูุจูุงูุงุช ุงููุนุงูุฌุฉ (Tokenization)                                   โ\n",
    "โ  2. ุฅูุดุงุก ุชูุณููุงุช ุงูุชุฏุฑูุจ/ุงูุชุญูู/ุงูุงุฎุชุจุงุฑ                                    โ\n",
    "โ  3. ุชูููุฏ ุงูุชุตูููุงุช (Labels) ููููุฉ ุงูุชุณูุณู-ุฅูู-ุชุณูุณู                         โ\n",
    "โ  4. ุชุฏุฑูุจ ูุชูููู ุงูููุงุฐุฌ                                                     โ\n",
    "โ                                                                              โ\n",
    "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n",
    "\"\"\"\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c1249ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "๐ท๏ธ ูุซุงู ุชูููุฏ ุงูุชุตูููุงุช\n",
      "======================================================================\n",
      "ุฎุฑูุทุฉ ุงูุชุตูููุงุช:\n",
      "   0: ูุง ุชุฑููู (O)\n",
      "   1: ููุทุฉ (.)\n",
      "   2: ูุงุตูุฉ (ุ)\n",
      "   3: ุงุณุชููุงู (ุ)\n",
      "   4: ูุงุตูุฉ ููููุทุฉ (ุ)\n",
      "   5: ููุทุชุงู (:)\n",
      "   6: ุชุนุฌุจ (!)\n",
      "\n",
      "ุงููุต: ูุฐุง ูุต ุนุฑุจูุ ูุญุชูู ุนูู ุนูุงูุงุช ุชุฑููู.\n",
      "ุงููููุงุช: ['ูุฐุง', 'ูุต', 'ุนุฑุจูุ', 'ูุญุชูู', 'ุนูู', 'ุนูุงูุงุช', 'ุชุฑููู']\n",
      "ุงูุชุตูููุงุช: [0, 0, 0, 0, 0, 0, 1]\n",
      "\n",
      "ุงููุต: ูุง ูู ุงูุณุคุงูุ\n",
      "ุงููููุงุช: ['ูุง', 'ูู', 'ุงูุณุคุงูุ']\n",
      "ุงูุชุตูููุงุช: [0, 0, 0]\n",
      "\n",
      "ุงููุต: ุฃููุงูุ ุซุงููุงูุ ุซุงูุซุงู.\n",
      "ุงููููุงุช: ['ุฃููุงูุ', 'ุซุงููุงูุ', 'ุซุงูุซุงู']\n",
      "ุงูุชุตูููุงุช: [0, 0, 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ุฃุฏุงุฉ ุชูููุฏ ุงูุชุตูููุงุช (Label Generation)\n",
    "# ============================================================================\n",
    "\n",
    "def generate_labels_for_line(text: str) -> Tuple[List[str], List[int]]:\n",
    "    \"\"\"\n",
    "    ุชูููุฏ ุชุณูุณูุงุช ุงููููุงุช ูุงูุชุตูููุงุช ูุณุทุฑ ูุนุงูุฌ.\n",
    "    \n",
    "    ูุฐุง ูู ุงูุชูุณูู ุงููุทููุจ ูุชุฏุฑูุจ ุงูุชุณูุณู-ุฅูู-ุชุณูุณู.\n",
    "    \n",
    "    ุงููุนุงููุงุช:\n",
    "    -----------\n",
    "    text : str\n",
    "        ุณุทุฑ ูุต ูุนุงูุฌ ูุณุจูุงู\n",
    "        \n",
    "    ุชุฑุฌุน:\n",
    "    --------\n",
    "    Tuple[List[str], List[int]]\n",
    "        (ูููุงุชุ ุชุตูููุงุช) ุญูุซ ุชุดูุฑ ุงูุชุตูููุงุช ููุชุฑููู ุจุนุฏ ูู ูููุฉ\n",
    "        \n",
    "    ุฎุฑูุทุฉ ุงูุชุตูููุงุช:\n",
    "    - 0: ูุง ุชุฑููู (O)\n",
    "    - 1: ููุทุฉ (.)\n",
    "    - 2: ูุงุตูุฉ ุนุฑุจูุฉ (ุ)\n",
    "    - 3: ุนูุงูุฉ ุงุณุชููุงู (ุ)\n",
    "    - 4: ูุงุตูุฉ ููููุทุฉ (ุ)\n",
    "    - 5: ููุทุชุงู ุฑุฃุณูุชุงู (:)\n",
    "    - 6: ุนูุงูุฉ ุชุนุฌุจ (!)\n",
    "    \"\"\"\n",
    "    LABEL_MAP = {\n",
    "        'O': 0,    # ูุง ุชุฑููู\n",
    "        '.': 1,    # ููุทุฉ\n",
    "        'ุ': 2,    # ูุงุตูุฉ ุนุฑุจูุฉ\n",
    "        'ุ': 3,    # ุนูุงูุฉ ุงุณุชููุงู\n",
    "        'ุ': 4,    # ูุงุตูุฉ ููููุทุฉ\n",
    "        ':': 5,    # ููุทุชุงู ุฑุฃุณูุชุงู\n",
    "        '!': 6,    # ุนูุงูุฉ ุชุนุฌุจ\n",
    "    }\n",
    "    \n",
    "    words = []\n",
    "    labels = []\n",
    "    \n",
    "    # ููุท ูููููุงุช ุงูุนุฑุจูุฉ\n",
    "    word_pattern = re.compile(r'[\\u0600-\\u06FFู-ูฉ]+')\n",
    "    \n",
    "    # ุงูุนุซูุฑ ุนูู ุงููููุงุช ูููุงูุนูุง\n",
    "    for match in word_pattern.finditer(text):\n",
    "        word = match.group()\n",
    "        end_pos = match.end()\n",
    "        \n",
    "        # ุงูุจุญุซ ุนู ุชุฑููู ูุจุงุดุฑุฉ ุจุนุฏ ุงููููุฉ\n",
    "        remaining = text[end_pos:].lstrip()\n",
    "        \n",
    "        if remaining and remaining[0] in LABEL_MAP:\n",
    "            label = LABEL_MAP[remaining[0]]\n",
    "        else:\n",
    "            label = LABEL_MAP['O']\n",
    "        \n",
    "        words.append(word)\n",
    "        labels.append(label)\n",
    "    \n",
    "    return words, labels\n",
    "\n",
    "\n",
    "# ุงุฎุชุจุงุฑ ุชูููุฏ ุงูุชุตูููุงุช\n",
    "logger.section(\"๐ท๏ธ ูุซุงู ุชูููุฏ ุงูุชุตูููุงุช\")\n",
    "\n",
    "test_lines = [\n",
    "    \"ูุฐุง ูุต ุนุฑุจูุ ูุญุชูู ุนูู ุนูุงูุงุช ุชุฑููู.\",\n",
    "    \"ูุง ูู ุงูุณุคุงูุ\",\n",
    "    \"ุฃููุงูุ ุซุงููุงูุ ุซุงูุซุงู.\",\n",
    "]\n",
    "\n",
    "logger.info(\"ุฎุฑูุทุฉ ุงูุชุตูููุงุช:\")\n",
    "logger.info(\"   0: ูุง ุชุฑููู (O)\")\n",
    "logger.info(\"   1: ููุทุฉ (.)\")\n",
    "logger.info(\"   2: ูุงุตูุฉ (ุ)\")\n",
    "logger.info(\"   3: ุงุณุชููุงู (ุ)\")\n",
    "logger.info(\"   4: ูุงุตูุฉ ููููุทุฉ (ุ)\")\n",
    "logger.info(\"   5: ููุทุชุงู (:)\")\n",
    "logger.info(\"   6: ุชุนุฌุจ (!)\")\n",
    "logger.info(\"\")\n",
    "\n",
    "for text in test_lines:\n",
    "    words, labels = generate_labels_for_line(text)\n",
    "    logger.info(f\"ุงููุต: {text}\")\n",
    "    logger.info(f\"ุงููููุงุช: {words}\")\n",
    "    logger.info(f\"ุงูุชุตูููุงุช: {labels}\")\n",
    "    logger.info(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "54f456ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "โ ุงูุชูู ุฏูุชุฑ ุงููุนุงูุฌุฉ ุงููุณุจูุฉ\n",
      "======================================================================\n",
      "ุชู ุชุนุฑูู ุฌููุน ุฏูุงู ูุฎุทูุงุช ุงููุนุงูุฌุฉ.\n",
      "ุดุบู ุงูุฎุท ุงููุงูู ุจูุถุน EXECUTE_FULL_PIPELINE = True ููุนุงูุฌุฉ ูุงูู ุงูุจูุงูุงุช.\n"
     ]
    }
   ],
   "source": [
    "logger.section(\"โ ุงูุชูู ุฏูุชุฑ ุงููุนุงูุฌุฉ ุงููุณุจูุฉ\")\n",
    "logger.info(\"ุชู ุชุนุฑูู ุฌููุน ุฏูุงู ูุฎุทูุงุช ุงููุนุงูุฌุฉ.\")\n",
    "logger.info(\"ุดุบู ุงูุฎุท ุงููุงูู ุจูุถุน EXECUTE_FULL_PIPELINE = True ููุนุงูุฌุฉ ูุงูู ุงูุจูุงูุงุช.\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
