{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "59683c7a",
      "metadata": {
        "id": "59683c7a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "MXQw14DuEipp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXQw14DuEipp",
        "outputId": "78d95acb-46dc-4985-f095-534de953f3ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f868a1f1",
      "metadata": {},
      "source": [
        "### هنا سوف اعرف الباثات الاساسية للملفات التي سوف استعملها "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "807e7c95",
      "metadata": {
        "id": "807e7c95"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    # Data\n",
        "    raw_data_dir = \"./Data/SSAC-UNPC\"\n",
        "    ABD_data_dir = \"./Data/ABC\"\n",
        "\n",
        "    cleaned_data_dir = \"./Clean/full-corpus2\"\n",
        "    ABC_cleaned_data_dir = \"./Clean/ABC\"\n",
        "\n",
        "    # Logs\n",
        "    per_file_stats_json_dir = \"./Logs/full-corpus/per_file_stats.json\"\n",
        "    ABC_per_file_stats_json_dir = \"./Logs/ABC/per_file_stats.json\"\n",
        "    corpus_summary_json_dir = \"./Logs/full-corpus/corpus_summary.json\"\n",
        "    run_log_dir = \"./Logs/run.log\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6c64082",
      "metadata": {},
      "source": [
        "### هذا التابع يقوم بعمل فحص كامل للمجلد إعادة الملفات النصية"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2647c45f",
      "metadata": {
        "id": "2647c45f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "def load_data(folder_path):\n",
        "    with os.scandir(folder_path) as entries:\n",
        "        for entry in entries:\n",
        "            if entry.is_file() and entry.name.endswith('.txt'):\n",
        "                try:\n",
        "                    with open(entry.path, 'r', encoding='utf-8', errors='replace') as file:\n",
        "                        content = file.read()\n",
        "                        yield {\n",
        "                            'path': entry.path,\n",
        "                            'filename': entry.name,\n",
        "                            'content': content,\n",
        "                            'size': os.path.getsize(entry.path)\n",
        "                        }\n",
        "                except Exception as e:\n",
        "                    print(f\"Error reading {entry.name}: {e}\")\n",
        "            elif entry.is_dir():\n",
        "                yield from load_data(entry.path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05f89ca2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05f89ca2",
        "outputId": "b5cd43b3-a435-4d20-f92a-def9c35238a0"
      },
      "outputs": [],
      "source": [
        "path = Config.raw_data_dir\n",
        "data = list(load_data(path))\n",
        "\n",
        "for content in data:\n",
        "    print(f\"Filename: {content['filename']}\")\n",
        "    print(f\"Size: {content['size']} bytes\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04dbd8fd",
      "metadata": {
        "id": "04dbd8fd"
      },
      "source": [
        "### تحليل بسيط لعدد المحارف  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc7a0140",
      "metadata": {
        "id": "cc7a0140"
      },
      "outputs": [],
      "source": [
        "def count_chart(data, title='Character Occurrences'):\n",
        "    from collections import Counter\n",
        "    all_text = ''.join([item['content'] for item in data])\n",
        "    char_counts = Counter(all_text)\n",
        "    print(\"Chart Count is\\n\" , char_counts)\n",
        "    chars = list(char_counts.keys())\n",
        "    counts = list(char_counts.values())\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.barplot(x=chars, y=counts)\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Characters')\n",
        "    plt.ylabel('Occurrences')\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc575ba2",
      "metadata": {
        "id": "fc575ba2",
        "outputId": "421ae8bc-efbe-4012-f7e4-879da0b9487d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chart Count is\n",
            " Counter({' ': 201782, 'ا': 119967, 'ل': 98206, 'ي': 61693, 'م': 51613, 'و': 49570, 'ن': 48315, 'ر': 36035, 'ه': 32052, 'ت': 31442, 'ب': 31135, 'ع': 29169, 'ف': 24362, 'د': 21952, 'أ': 21074, 'ة': 20306, 'ق': 18561, 'ك': 18232, 'س': 18160, 'َ': 17743, '.': 14984, 'ح': 14958, 'ج': 11823, '،': 10859, 'إ': 8378, 'ى': 8151, 'ذ': 8148, 'ص': 7743, '\\n': 7459, 'ط': 7283, 'خ': 7031, 'ش': 7020, 'ِ': 6610, 'ُ': 6213, 'ث': 5652, 'ض': 5503, 'ّ': 5379, 'ْ': 5191, 'ً': 4736, 'ز': 4393, 'غ': 3753, 'ء': 3515, '\\t': 3296, 'ئ': 3130, ':': 2510, 'ظ': 2268, '\"': 1335, 'آ': 1167, '«': 1145, '»': 1123, '—': 964, 'ٍ': 835, 'ؤ': 830, ')': 712, '(': 672, '؟': 528, 'ٌ': 520, '١': 507, '!': 423, '؛': 395, '-': 383, '2': 365, '٢': 335, '1': 262, '٣': 234, 'e': 221, '٤': 216, '٨': 211, '•': 207, '٥': 199, '٩': 199, 'a': 184, '٠': 173, '٦': 172, '٧': 159, 'o': 156, 'i': 153, '0': 153, '\\xa0': 152, 'n': 143, 'r': 139, 's': 136, 't': 122, '…': 116, '3': 108, '8': 96, '5': 95, '–': 88, 'l': 87, '9': 87, '6': 85, '7': 81, '4': 78, 'h': 75, 'm': 67, 'پ': 66, 'u': 59, 'ﻫ': 59, 'c': 58, 'ﷺ': 57, 'd': 49, '\\ufeff': 46, '/': 43, 'ـ': 42, 'b': 38, '=': 37, 'p': 36, 'C': 35, 'y': 32, 'A': 30, ',': 29, 'T': 29, 'f': 29, 'g': 29, 'ٔ': 26, '{': 25, '}': 25, '[': 24, ']': 24, 'M': 22, 'B': 21, 'L': 21, 'S': 18, 'P': 16, 'ﺑ': 16, '*': 15, '×': 15, 'K': 15, 'G': 14, 'J': 13, 'H': 13, 'W': 13, 'D': 12, 'R': 12, 'V': 12, 'w': 11, 'ٕ': 9, '“': 8, 'E': 8, 'k': 8, 'q': 8, 'N': 8, 'v': 7, 'O': 7, 'é': 7, '”': 6, '−': 6, 'F': 5, 'ۖ': 5, '’': 5, '‘': 5, 'ﱠ': 5, 'I': 4, 'ﻟ': 4, '\\u2009': 4, 'x': 3, 'ٰ': 3, 'z': 3, 'U': 2, 'è': 2, 'Y': 2, 'ڨ': 2, 'Q': 2, '+': 2, 'ﱢ': 2, 'à': 1, '\\u200e': 1, '\\u200f': 1, '&': 1, 'ۚ': 1, 'X': 1, '٫': 1, '>': 1, 'ω': 1, 'μ': 1, \"'\": 1, 'j': 1, 'Z': 1, 'ٓ': 1, '°': 1})\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 9 (\t) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 65018 (\\N{ARABIC LIGATURE SALLALLAHOU ALAYHE WASALLAM}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 1754 (\\N{ARABIC SMALL HIGH JEEM}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Matplotlib currently does not support Arabic natively.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 1750 (\\N{ARABIC SMALL HIGH LIGATURE SAD WITH LAM WITH ALEF MAKSURA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 64608 (\\N{ARABIC LIGATURE SHADDA WITH FATHA ISOLATED FORM}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 64610 (\\N{ARABIC LIGATURE SHADDA WITH KASRA ISOLATED FORM}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "count_chart(data, title='Character Occurrences in Arabic Punctuation Dataset')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c61d1b20",
      "metadata": {},
      "source": [
        "### هنا نجد ان هناك كمية محارف ضخمة يجب ان تزال"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8396428b",
      "metadata": {},
      "source": [
        "سأقوم بتجميع توابع تحليل الداتا على مستوى الاحرف في الكلاس التالي"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39457bc7",
      "metadata": {
        "id": "39457bc7",
        "outputId": "2e3e31fc-c846-4d1a-bced-add47aa66bd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Least Common Characters: [('à', 1), ('\\u200e', 1), ('\\u200f', 1), ('&', 1), ('ۚ', 1), ('X', 1), ('٫', 1), ('>', 1), ('ω', 1), ('μ', 1), (\"'\", 1), ('j', 1), ('Z', 1), ('ٓ', 1), ('°', 1), ('U', 2), ('è', 2), ('Y', 2), ('ڨ', 2), ('Q', 2), ('+', 2), ('ﱢ', 2), ('x', 3), ('ٰ', 3), ('z', 3), ('I', 4), ('ﻟ', 4), ('\\u2009', 4), ('F', 5), ('ۖ', 5), ('’', 5), ('‘', 5), ('ﱠ', 5), ('”', 6), ('−', 6), ('v', 7), ('O', 7), ('é', 7), ('“', 8), ('E', 8)]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from collections import Counter, defaultdict\n",
        "import string\n",
        "\n",
        "class CharacterAnalyzer:\n",
        "    def __init__(self, text: str):\n",
        "        self.text = text\n",
        "        self.char_counts = self._count_all_chars()\n",
        "\n",
        "    def _count_all_chars(self) -> dict:\n",
        "        \n",
        "        return dict(Counter(self.text))\n",
        "\n",
        "    def get_sorted_counts(self, descending: bool = True) -> list:\n",
        "        return sorted(\n",
        "            self.char_counts.items(),\n",
        "            key=lambda x: x[1],\n",
        "            reverse=descending\n",
        "        )\n",
        "\n",
        "    def get_char_frequency(self, char: str) -> int:\n",
        "        return self.char_counts.get(char, 0)\n",
        "\n",
        "    def get_total_chars(self) -> int:\n",
        "        return len(self.text)\n",
        "\n",
        "    def get_most_common(self, n: int = 10) -> list:\n",
        "        sorted_counts = self.get_sorted_counts(descending=True)\n",
        "        return sorted_counts[:n]\n",
        "\n",
        "    def get_least_common(self, n: int = 10) -> list:\n",
        "        sorted_counts = self.get_sorted_counts(descending=False)\n",
        "        return sorted_counts[:n]\n",
        "    def get_number_of_unique_chars(self) -> int:\n",
        "        return len(self.char_counts)\n",
        "    def get_char_stats(self) -> dict:\n",
        "        total = self.get_total_chars()\n",
        "        unique = self.get_number_of_unique_chars()\n",
        "\n",
        "        return {\n",
        "            'total_characters': total,\n",
        "            'unique_characters': unique,\n",
        "            'most_common': self.get_most_common(5),\n",
        "            'least_common': self.get_least_common(5)\n",
        "        }\n",
        "\n",
        "    def visualize_counts(self, top_n: int = 20, title: str = 'Character Frequency Visualization'):\n",
        "        counter = Counter(self.text)\n",
        "        most_common = counter.most_common(top_n)\n",
        "        chars, counts = zip(*most_common)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        sns.barplot(x=chars, y=counts)\n",
        "        plt.title(title)\n",
        "        plt.xlabel('Characters')\n",
        "        plt.ylabel('Occurrences')\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "# Usage\n",
        "text = ''.join([item['content'] for item in data])\n",
        "\n",
        "analyzer = CharacterAnalyzer(text)\n",
        "\n",
        "print(\"Least Common Characters:\", analyzer.get_least_common(40))\n",
        "analyzer.visualize_counts(top_n=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ce82bef",
      "metadata": {
        "id": "1ce82bef"
      },
      "source": [
        "### مثل ما راينا في البلوت السابق، هناك العديد من المحارف التي لا تفيد في عملية التعلم"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85e0d7e1",
      "metadata": {},
      "source": [
        "### يجب ان نقوم بتجميع المحارف التي يجب ادراجها في الداتا وغير ذلك يجب ان نقوم بازالتها"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a0c66fb",
      "metadata": {
        "id": "9a0c66fb"
      },
      "outputs": [],
      "source": [
        "# Arabic Alphabet (Modern Standard Arabic)\n",
        "ARABIC_LETTERS = [\n",
        "    # Arabic Alphabet\n",
        "    'ا', 'ب', 'ت', 'ث', 'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'س', 'ش', 'ص',\n",
        "    'ض', 'ط', 'ظ', 'ع', 'غ', 'ف', 'ق', 'ك', 'ل', 'م', 'ن', 'ه', 'و', 'ي',\n",
        "\n",
        "    # Hamza forms and variations\n",
        "    'أ', 'إ', 'آ', 'ؤ', 'ئ', 'ء',\n",
        "\n",
        "    # Ta Marbuta\n",
        "    'ة',\n",
        "\n",
        "    # Alif Maqsura\n",
        "    'ى',\n",
        "\n",
        "    # Lam-Alif\n",
        "    'لا',\n",
        "\n",
        "    # Additional letters used in various Arabic dialects\n",
        "    'پ', 'چ', 'ژ', 'گ', 'ڤ',  # Used in some dialects/regions\n",
        "]\n",
        "\n",
        "# Arabic Numbers (Eastern Arabic numerals)\n",
        "ARABIC_NUMERALS = [\n",
        "    '٠', '١', '٢', '٣', '٤', '٥', '٦', '٧', '٨', '٩'  # 0-9\n",
        "]\n",
        "\n",
        "# Standard Western Numbers (also commonly used)\n",
        "WESTERN_NUMBERS = [\n",
        "    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9'\n",
        "]\n",
        "\n",
        "# Arabic Punctuation and Diacritics\n",
        "ARABIC_PUNCTUATION = [\n",
        "    '،',  # Arabic comma\n",
        "    '؛',  # Arabic semicolon\n",
        "    '؟',  # Arabic question mark\n",
        "    '!',  # Exclamation mark\n",
        "    '.',  # Full Stop\n",
        "    ':',  # Colon\n",
        "]\n",
        "LATIN_PUNCTUATION = [\n",
        "    ',', # Latin comma\n",
        "    ';', # Latin semicolon\n",
        "    '?', # Latin question mark\n",
        " ]\n",
        "\n",
        "LATIN_TO_ARABIC_PUNCTUATION = {\n",
        "    ',': '،',\n",
        "    ';': '؛',\n",
        "    '?': '؟',\n",
        "}\n",
        "LATIN_TO_ARABIC_NUMBERS = {\n",
        "    '0': '٠',\n",
        "    '1': '١',\n",
        "    '2': '٢',\n",
        "    '3': '٣',\n",
        "    '4': '٤',\n",
        "    '5': '٥',\n",
        "    '6': '٦',\n",
        "    '7': '٧',\n",
        "    '8': '٨',\n",
        "    '9': '٩'\n",
        "}\n",
        "# Arabic Diacritics\n",
        "ARABIC_DIACRITICS = [\n",
        "    # Short vowels\n",
        "    # 'َ',  # Fatha\n",
        "    # 'ُ',  # Damma\n",
        "    # 'ِ',  # Kasra\n",
        "\n",
        "    # # Tanween (nunation)\n",
        "    # 'ً',  # Fathatan\n",
        "    # 'ٌ',  # Dammatan\n",
        "    # 'ٍ',  # Kasratan\n",
        "\n",
        "    # # Sukun\n",
        "    # 'ْ',  # Sukun\n",
        "\n",
        "    # Shadda\n",
        "    'ّ',  # Shadda (gemination)\n",
        "]\n",
        "\n",
        "# Combine everything\n",
        "ARABIC_VOCABULARY = (\n",
        "    ARABIC_LETTERS +\n",
        "    ARABIC_NUMERALS +\n",
        "    WESTERN_NUMBERS +\n",
        "    ARABIC_PUNCTUATION +\n",
        "    LATIN_PUNCTUATION +\n",
        "    ARABIC_DIACRITICS\n",
        ")\n",
        "\n",
        "# Or create separate lists for different purposes\n",
        "CHART_SETS = {\n",
        "    'letters': ARABIC_LETTERS,\n",
        "    'arabic_numerals': ARABIC_NUMERALS,\n",
        "    'western_numbers': WESTERN_NUMBERS,\n",
        "    'punctuation': ARABIC_PUNCTUATION,\n",
        "    'diacritics': ARABIC_DIACRITICS,\n",
        "    'all': ARABIC_VOCABULARY,\n",
        "}\n",
        "\n",
        "# Create a dictionary with character indices\n",
        "def create_arabic_vocab_dict(include_special_tokens: bool = True) -> dict:\n",
        "    \"\"\"\n",
        "    Create a complete Arabic vocabulary dictionary with indices\n",
        "    \"\"\"\n",
        "    # Base vocabulary\n",
        "    base_vocab = ARABIC_VOCABULARY.copy()\n",
        "\n",
        "    # Add special tokens if requested\n",
        "    special_tokens = []\n",
        "    if include_special_tokens:\n",
        "        special_tokens = ['[PAD]', '[UNK]', '[BOS]', '[EOS]', '[MASK]', '[SEP]', '[CLS]']\n",
        "        base_vocab = special_tokens + base_vocab\n",
        "\n",
        "    # Create mapping dictionaries\n",
        "    char_to_idx = {char: idx for idx, char in enumerate(base_vocab)}\n",
        "    idx_to_char = {idx: char for char, idx in char_to_idx.items()}\n",
        "\n",
        "    return {\n",
        "        'char_to_idx': char_to_idx,\n",
        "        'idx_to_char': idx_to_char,\n",
        "        'vocabulary': base_vocab,\n",
        "        'vocab_size': len(base_vocab),\n",
        "        'special_tokens': special_tokens if include_special_tokens else [],\n",
        "        'stats': {\n",
        "            'letters': len(ARABIC_LETTERS),\n",
        "            'arabic_numerals': len(ARABIC_NUMERALS),\n",
        "            'western_numbers': len(WESTERN_NUMBERS),\n",
        "            'punctuation': len(ARABIC_PUNCTUATION),\n",
        "            'diacritics': len(ARABIC_DIACRITICS),\n",
        "        }\n",
        "    }\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "293c54e9",
      "metadata": {
        "id": "293c54e9"
      },
      "outputs": [],
      "source": [
        "def cleanData(text: str) -> str:\n",
        "    \"\"\"Clean text by removing unwanted characters\"\"\"\n",
        "    allowed_chars = set(ARABIC_VOCABULARY + list(string.whitespace))\n",
        "    cleaned_text = ''.join([char for char in text if char in allowed_chars])\n",
        "    return cleaned_text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b66946e",
      "metadata": {},
      "source": [
        "الأحصائيات قبل التنظيف\n",
        "\n",
        "الداتا المستعملة هي ال ABC وليس الداتا كاملة "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd25d50e",
      "metadata": {
        "id": "bd25d50e",
        "outputId": "f21ba3eb-9215-49df-d2db-b520a1374db5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'total_characters': 1145591, 'unique_characters': 180, 'most_common': [(' ', 201782), ('ا', 119967), ('ل', 98206), ('ي', 61693), ('م', 51613)], 'least_common': [('à', 1), ('\\u200e', 1), ('\\u200f', 1), ('&', 1), ('ۚ', 1)]}\n"
          ]
        }
      ],
      "source": [
        "print(analyzer.get_char_stats())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de0f8745",
      "metadata": {
        "id": "de0f8745"
      },
      "source": [
        "### بعد التنظيف"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abfdaa93",
      "metadata": {
        "id": "abfdaa93",
        "outputId": "6f2e7ae2-1bbe-4b66-885c-b1cdaf4d2fa7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'total_characters': 1094115, 'unique_characters': 68, 'most_common': [(' ', 201782), ('ا', 119967), ('ل', 98206), ('ي', 61693), ('م', 51613)], 'least_common': [(',', 29), ('پ', 66), ('4', 78), ('7', 81), ('6', 85)]}\n"
          ]
        }
      ],
      "source": [
        "cleaned_data = cleanData(text)\n",
        "new_analyzer = CharacterAnalyzer(cleaned_data)\n",
        "print(new_analyzer.get_char_stats())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bc69abd",
      "metadata": {
        "id": "6bc69abd",
        "outputId": "61c60ebc-a2b6-4242-e9a5-ffca7862ea8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4\n"
          ]
        }
      ],
      "source": [
        "print(len(ARABIC_VOCABULARY) - new_analyzer.get_number_of_unique_chars())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45bd76d7",
      "metadata": {
        "id": "45bd76d7"
      },
      "outputs": [],
      "source": [
        "def get_not_presented_charters(vocabulary: list, analyzer: CharacterAnalyzer) -> list:\n",
        "    \"\"\"Get characters from vocabulary not present in the analyzed text\"\"\"\n",
        "    not_presented = [char for char in vocabulary if analyzer.get_char_frequency(char) == 0]\n",
        "    return not_presented"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80681dbf",
      "metadata": {
        "id": "80681dbf",
        "outputId": "f64d9a73-ba5e-4a40-8805-2b58b9ff6c3c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['لا', 'چ', 'ژ', 'گ', 'ڤ', ';', '?']"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_not_presented_charters(ARABIC_VOCABULARY, new_analyzer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bd743f7",
      "metadata": {},
      "source": [
        "### هذا الكلاس هو من اهم الكلاسات المستعملة فهو يحوي على جميع عمليات التنظيف المسبق للداتا التي اريد ان استعملها"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8b2a6e8",
      "metadata": {
        "id": "d8b2a6e8"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import re\n",
        "from typing import Dict, Iterable, List, Tuple, Sequence\n",
        "\n",
        "\n",
        "class ArabicPunctuationProcessor:\n",
        "    \"\"\"\n",
        "    معالج نص عربي لمهمة استعادة علامات الترقيم (Sequence Labeling):\n",
        "    - يقوم بالتنظيف والتطبيع والتقسيم (tokenization) وفصل علامات الترقيم\n",
        "    - يستخرج (words, labels) بحيث يمثل label علامة الترقيم التي تأتي بعد الكلمة\n",
        "    \"\"\"\n",
        "\n",
        "    # =========================\n",
        "    # 1) ثوابت الحروف والأرقام\n",
        "    # =========================\n",
        "    ARABIC_LETTERS: Sequence[str] = (\n",
        "        \"ا\", \"ب\", \"ت\", \"ث\", \"ج\", \"ح\", \"خ\", \"د\", \"ذ\", \"ر\", \"ز\", \"س\", \"ش\", \"ص\",\n",
        "        \"ض\", \"ط\", \"ظ\", \"ع\", \"غ\", \"ف\", \"ق\", \"ك\", \"ل\", \"م\", \"ن\", \"ه\", \"و\", \"ي\",\n",
        "        \"أ\", \"إ\", \"آ\", \"ؤ\", \"ئ\", \"ء\",\n",
        "        \"ة\", \"ى\",\n",
        "        \"پ\", \"چ\", \"ژ\", \"گ\", \"ڤ\",\n",
        "    )\n",
        "\n",
        "    ARABIC_NUMERALS: Sequence[str] = (\"٠\", \"١\", \"٢\", \"٣\", \"٤\", \"٥\", \"٦\", \"٧\", \"٨\", \"٩\")\n",
        "    WESTERN_NUMBERS: Sequence[str] = (\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\")\n",
        "\n",
        "    # =========================\n",
        "    # 2) علامات الترقيم المستهدفة\n",
        "    # =========================\n",
        "    ARABIC_PUNCTUATION: Sequence[str] = (\"،\", \"؛\", \"؟\", \"!\", \".\", \":\")\n",
        "    LATIN_PUNCTUATION: Sequence[str] = (\",\", \";\", \"?\")\n",
        "\n",
        "    LATIN_TO_ARABIC_PUNCTUATION: Dict[str, str] = {\",\": \"،\", \";\": \"؛\", \"?\": \"؟\"}\n",
        "    LATIN_TO_ARABIC_NUMBERS: Dict[str, str] = {\n",
        "        \"0\": \"٠\", \"1\": \"١\", \"2\": \"٢\", \"3\": \"٣\", \"4\": \"٤\",\n",
        "        \"5\": \"٥\", \"6\": \"٦\", \"7\": \"٧\", \"8\": \"٨\", \"9\": \"٩\",\n",
        "    }\n",
        "\n",
        "    # =========================\n",
        "    # 3) مساحة الوسوم\n",
        "    # =========================\n",
        "    CLASS_TO_PUNCTUATION: Dict[int, str] = {\n",
        "        0: \"\",\n",
        "        1: \"،\",\n",
        "        2: \"؛\",\n",
        "        3: \":\",\n",
        "        4: \".\",\n",
        "        5: \"؟\",\n",
        "        6: \"!\",\n",
        "    }\n",
        "    PUNCTUATION_TO_CLASS: Dict[str, int] = {\n",
        "        \"\": 0,\n",
        "        \"،\": 1,\n",
        "        \"؛\": 2,\n",
        "        \":\": 3,\n",
        "        \".\": 4,\n",
        "        \"؟\": 5,\n",
        "        \"!\": 6,\n",
        "    }\n",
        "\n",
        "    # =========================\n",
        "    # 4) Special Tokens\n",
        "    # =========================\n",
        "    SPECIAL_TOKENS = {\n",
        "        \"LINE\": \"[LINE]\",\n",
        "        \"NUM\": \"[NUM]\",\n",
        "        \"URL\": \"[URL]\",\n",
        "        \"EMAIL\": \"[EMAIL]\",\n",
        "        \"DATE\": \"[DATE]\",\n",
        "        \"TIME\": \"[TIME]\",\n",
        "    }\n",
        "\n",
        "    # =========================\n",
        "    # 5) Regex: الوقت/الرابط/البريد/الأرقام/التواريخ\n",
        "    # =========================\n",
        "    TIME_RE = re.compile(\n",
        "        r\"\"\"\n",
        "        \\b\n",
        "        (?:\n",
        "            (?:[01]?\\d|2[0-3])           # ساعات بالأرقام الغربية 0-23\n",
        "          | (?:[٠١]?[٠-٩]|٢[٠-٣])        # ساعات بالأرقام العربية الشرقية ٠-٢٣\n",
        "        )\n",
        "        :\n",
        "        (?:\n",
        "            [0-5]\\d                      # دقائق بالأرقام الغربية 00-59\n",
        "          | [٠-٥][٠-٩]                   # دقائق بالأرقام العربية الشرقية ٠٠-٥٩\n",
        "        )\n",
        "        (?:\\s*(?:ص|م|am|pm|AM|PM))?      # اختياري: ص/م أو AM/PM\n",
        "        \\b\n",
        "        \"\"\",\n",
        "        re.VERBOSE,\n",
        "    )\n",
        "\n",
        "    URL_RE = re.compile(\n",
        "        r\"\"\"(?ix)\n",
        "        \\b(\n",
        "            https?://[^\\s]+\n",
        "            |\n",
        "            www\\.[^\\s]+\n",
        "        )\\b\n",
        "        \"\"\"\n",
        "    )\n",
        "    EMAIL_RE = re.compile(r\"\"\"\n",
        "    \\b\n",
        "    [0-9A-Z\\u0600-\\u06FF._%+\\-]+      # local-part: لاتيني + عربي + أرقام + رموز مسموحة\n",
        "    @\n",
        "    [0-9A-Z\\u0600-\\u06FF.\\-]+         # domain\n",
        "    \\.\n",
        "    [0-9A-Z\\u0600-\\u06FF]{2,}         # TLD: قد يكون لاتيني أو عربي\n",
        "    \\b\n",
        "    \"\"\", re.VERBOSE | re.IGNORECASE)\n",
        "\n",
        "\n",
        "    # Arabic-Indic + Western digits, decimals with . , ٫\n",
        "    NUM_RE = re.compile(\n",
        "        r\"\"\"\n",
        "        (?:\n",
        "            [0-9٠-٩]+\n",
        "            (?:[.,٫][0-9٠-٩]+)*\n",
        "        )\n",
        "        \"\"\",\n",
        "        re.VERBOSE,\n",
        "    )\n",
        "\n",
        "    DATE_NUMERIC_RE = re.compile(\n",
        "        r\"\"\"\n",
        "        \\b\n",
        "        (\n",
        "            [0-9٠-٩]{1,4}\n",
        "            [\\/\\-\\.]\n",
        "            [0-9٠-٩]{1,2}\n",
        "            [\\/\\-\\.]\n",
        "            [0-9٠-٩]{1,4}\n",
        "        )\n",
        "        \\b\n",
        "        \"\"\",\n",
        "        re.VERBOSE,\n",
        "    )\n",
        "\n",
        "    # =========================\n",
        "    # 6) أولوية حل تعدد الترقيم\n",
        "    # =========================\n",
        "    MULTI_PUNCT_PRIORITY: Sequence[str] = (\"؟\", \"!\", \".\", \"،\", \"؛\", \":\")\n",
        "\n",
        "    # =========================\n",
        "    # 7) Regex للحركات ومحارف التحكم\n",
        "    # =========================\n",
        "    ARABIC_DIACRITICS_RE = re.compile(r\"[\\u064B-\\u065F\\u0670\\u06D6-\\u06ED]\")\n",
        "    CONTROL_CHARS_RE = re.compile(r\"[\\u0000-\\u001F\\u007F-\\u009F]\")\n",
        "\n",
        "    # =========================\n",
        "    # 8) Translation tables\n",
        "    # =========================\n",
        "    _PUNCT_TRANSLATION = str.maketrans(LATIN_TO_ARABIC_PUNCTUATION)\n",
        "    _NUM_TRANSLATION = str.maketrans(LATIN_TO_ARABIC_NUMBERS)\n",
        "\n",
        "    # =========================\n",
        "    # 9) مجموعة الترقيم المستهدف\n",
        "    # =========================\n",
        "    PUNCT_SET = set([\"،\", \"؛\", \":\", \".\", \"؟\", \"!\"])\n",
        "\n",
        "    # =========================\n",
        "    # 10) أشهر عربية للتاريخ النصي\n",
        "    # =========================\n",
        "    _MONTHS_LIST = (\n",
        "        \"يناير|كانون\\\\s*الثاني|يناير\",\n",
        "        \"فبراير|شباط\",\n",
        "        \"مارس|آذار\",\n",
        "        \"أبريل|ابريل|نيسان\",\n",
        "        \"مايو|أيار\",\n",
        "        \"يونيو|حزيران\",\n",
        "        \"يوليو|تموز\",\n",
        "        \"أغسطس|اغسطس|آب\",\n",
        "        \"سبتمبر|أيلول\",\n",
        "        \"أكتوبر|اكتوبر|تشرين\\\\s*الأول\",\n",
        "        \"نوفمبر|تشرين\\\\s*الثاني\",\n",
        "        \"ديسمبر|كانون\\\\s*الأول|دجنبر\",\n",
        "    )\n",
        "    ARABIC_MONTHS = \"|\".join(_MONTHS_LIST)\n",
        "\n",
        "    DATE_TEXTUAL_RE = re.compile(\n",
        "        rf\"\"\"\n",
        "        \\b\n",
        "        [0-9٠-٩]{{1,2}}\n",
        "        \\s+\n",
        "        (?:{ARABIC_MONTHS})\n",
        "        \\s+\n",
        "        [0-9٠-٩]{{2,4}}\n",
        "        \\b\n",
        "        \"\"\",\n",
        "        re.VERBOSE,\n",
        "    )\n",
        "\n",
        "    # =========================\n",
        "    # 11) Vocabulary \n",
        "    # =========================\n",
        "    ARABIC_CHART_VOCABULARY: Sequence[str] = tuple(\n",
        "        list(ARABIC_LETTERS)\n",
        "        + list(ARABIC_NUMERALS)\n",
        "        + list(WESTERN_NUMBERS)\n",
        "        + list(ARABIC_PUNCTUATION)\n",
        "        + list(LATIN_PUNCTUATION)\n",
        "    )\n",
        "    ARABIC_CHAR_VOCABULARY: Sequence[str] = ARABIC_CHART_VOCABULARY\n",
        "\n",
        "    PUNCTUATION_SET = set(ARABIC_PUNCTUATION)\n",
        "    \n",
        "    # =========================\n",
        "    # 12) منطق حذف الرموز/الترقيم غير المرغوب\n",
        "    # =========================\n",
        "    \n",
        "    # إزالة أي محرف ليس عربي/أرقام/٪ أو جزء من special token [..]\n",
        "    _SCRUB_IN_TOKEN_RE = re.compile(r\"[^\\u0600-\\u06FF0-9٠-٩%\\u066A\\u066B\\u066C\\[\\]]+\")\n",
        "\n",
        "    def __init__(self, remove_diacritics: bool = True):\n",
        "        self.remove_diacritics = remove_diacritics\n",
        "\n",
        "        # فصل علامات الترقيم المستهدفة بمسافات\n",
        "        punct_escaped = \"\".join(re.escape(p) for p in self.ARABIC_PUNCTUATION)\n",
        "        self._PUNCT_SEP_RE = re.compile(f\"([{punct_escaped}])\")\n",
        "        self._WS_RE = re.compile(r\"\\s+\")\n",
        "\n",
        "\n",
        "    # =========================\n",
        "    # Helpers داخلية\n",
        "    # =========================\n",
        "    def _strip_control_chars(self, text: str) -> str:\n",
        "        return self.CONTROL_CHARS_RE.sub(\"\", text)\n",
        "\n",
        "    def _normalize_punctuation(self, text: str) -> str:\n",
        "        return text.translate(self._PUNCT_TRANSLATION)\n",
        "\n",
        "    def _normalize_numbers(self, text: str) -> str:\n",
        "        return text.translate(self._NUM_TRANSLATION)\n",
        "\n",
        "    def _remove_diacritics_fn(self, text: str) -> str:\n",
        "        if self.remove_diacritics:\n",
        "            return self.ARABIC_DIACRITICS_RE.sub(\"\", text)\n",
        "        return text\n",
        "\n",
        "    def _separate_punctuation(self, text: str) -> str:\n",
        "        \"\"\"\n",
        "        إضافة مسافة قبل/بعد علامات الترقيم المستهدفة فقط\n",
        "        \"\"\"\n",
        "        text = self._PUNCT_SEP_RE.sub(r\" \\1 \", text)\n",
        "        return self._WS_RE.sub(\" \", text).strip()\n",
        "\n",
        "    def tokenize_arabic_words(self, text: str) -> List[str]:\n",
        "        \"\"\"تقسيم النص المنظّف إلى توكنز بناءً على المسافات.\"\"\"\n",
        "        return text.split()\n",
        "\n",
        "    # =========================\n",
        "    # منطق تنظيف الرموز غير المرغوبة\n",
        "    # =========================\n",
        "    def _scrub_unwanted_inside_token(self, tok: str) -> str:\n",
        "        \"\"\"\n",
        "        حذف الرموز غير المرغوبة داخل التوكن نفسه.\n",
        "        مثال: «سنصدر -> سنصدر\n",
        "        ملاحظة:\n",
        "        - لا نمس special tokens مثل [DATE]\n",
        "        - نحذف التطويل \"ـ\" حتى لو كان داخل نطاق العربية\n",
        "        \"\"\"\n",
        "        # إذا كان special token نتركه كما هو\n",
        "        if tok.startswith(\"[\") and tok.endswith(\"]\"):\n",
        "            return tok\n",
        "\n",
        "        # أولاً: تنظيف عام (حذف كل ما ليس عربي/أرقام/٪/%/[ ])\n",
        "        cleaned = self._SCRUB_IN_TOKEN_RE.sub(\"\", tok)\n",
        "\n",
        "        # ثانياً: حذف التطويل صراحة لأنه قد يبقى ضمن نطاق العربية\n",
        "        cleaned = cleaned.replace(\"ـ\", \"\")\n",
        "\n",
        "        return cleaned\n",
        "\n",
        "\n",
        "    def normalize_tokens_remove_unwanted(\n",
        "        self,\n",
        "        text: str,\n",
        "        remove_inside_token: bool = True,\n",
        "        drop_empty: bool = True,\n",
        "    ) -> str:\n",
        "        \"\"\"\n",
        "        حذف/تنظيف الرموز غير المستهدفة بعد أن يصبح النص tokenized بالمسافات.\n",
        "        - يبقي special tokens كما هي\n",
        "        - يبقي علامات الترقيم المستهدفة فقط (PUNCT_SET)\n",
        "        - ينظف الرموز الملتصقة داخل الكلمات (اختياري)\n",
        "        - يحذف التوكن إذا أصبح فارغاً أو لا يحوي أي حرف/رقم\n",
        "        \"\"\"\n",
        "        toks = text.split()\n",
        "        out: List[str] = []\n",
        "\n",
        "        for tok in toks:\n",
        "            if tok == \"ـ\":\n",
        "                continue\n",
        "            # حافظ على special tokens\n",
        "            if tok in self.SPECIAL_TOKENS.values():\n",
        "                out.append(tok)\n",
        "                continue\n",
        "\n",
        "            # حافظ على علامات الترقيم المستهدفة\n",
        "            if tok in self.PUNCT_SET:\n",
        "                out.append(tok)\n",
        "                continue\n",
        "\n",
        "            scrubbed = tok\n",
        "            if remove_inside_token:\n",
        "                scrubbed = self._scrub_unwanted_inside_token(tok)\n",
        "\n",
        "            if drop_empty and scrubbed == \"\":\n",
        "                continue\n",
        "\n",
        "            # إذا تحول إلى ترقيم مستهدف نعيده\n",
        "            if scrubbed in self.PUNCT_SET:\n",
        "                out.append(scrubbed)\n",
        "                continue\n",
        "\n",
        "            # إذا لا يحوي أي حرف عربي أو رقم بعد التنظيف => نعدّه رموزاً ونحذفه\n",
        "            if not any(\n",
        "                (\"\\u0600\" <= ch <= \"\\u06FF\") or (\"0\" <= ch <= \"9\") or (\"٠\" <= ch <= \"٩\")\n",
        "                for ch in scrubbed\n",
        "            ):\n",
        "                continue\n",
        "\n",
        "            out.append(scrubbed)\n",
        "\n",
        "        return \" \".join(out)\n",
        "\n",
        "    # =========================\n",
        "    # تنظيف النص المدخل\n",
        "    # =========================\n",
        "    def preprocess_text(self, text: str) -> str:\n",
        "        \"\"\"\n",
        "        خط أنابيب المعالجة المسبقة:\n",
        "        1) توحيد الأسطر الجديدة واستبدالها بـ [LINE]\n",
        "        2) إزالة محارف التحكم\n",
        "        3) توحيد علامات الترقيم اللاتينية إلى العربية\n",
        "        4) توحيد الأرقام (الغربية -> العربية الشرقية)\n",
        "        5) إزالة الحركات (إن كان الخيار مفعلاً)\n",
        "        6) استبدال EMAIL و URL برموز خاصة\n",
        "        7) استبدال DATE (نصي + رقمي) برمز [DATE]\n",
        "        8) استبدال TIME برمز [TIME]\n",
        "        9) استبدال بقية الأرقام بـ [NUM]\n",
        "        10) فصل علامات الترقيم المستهدفة بمسافات\n",
        "        11) توحيد المسافات وإزالة الزوائد\n",
        "        12) (جديد) حذف/تنظيف الرموز غير المرغوبة داخل/كـ توكنز\n",
        "        \"\"\"\n",
        "\n",
        "        # 1) توحيد شكل الأسطر الجديدة وتحويلها إلى [LINE]\n",
        "        text = text.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
        "        text = text.replace(\"\\n\", f\" {self.SPECIAL_TOKENS['LINE']} \")\n",
        "\n",
        "        # 2) إزالة محارف التحكم\n",
        "        text = self._strip_control_chars(text)\n",
        "\n",
        "        # 3) توحيد علامات الترقيم (لاتيني -> عربي)\n",
        "        text = self._normalize_punctuation(text)\n",
        "\n",
        "        # 4) توحيد الأرقام (غربي -> عربي شرقي)\n",
        "        text = self._normalize_numbers(text)\n",
        "\n",
        "        # 5) إزالة الحركات\n",
        "        text = self._remove_diacritics_fn(text)\n",
        "\n",
        "        # 6) حماية البريد والروابط قبل فصل الترقيم\n",
        "        text = self.EMAIL_RE.sub(f\" {self.SPECIAL_TOKENS['EMAIL']} \", text)\n",
        "        text = self.URL_RE.sub(f\" {self.SPECIAL_TOKENS['URL']} \", text)\n",
        "\n",
        "        # 7) التواريخ: نصية ثم رقمية\n",
        "        text = self.DATE_TEXTUAL_RE.sub(f\" {self.SPECIAL_TOKENS['DATE']} \", text)\n",
        "        text = self.DATE_NUMERIC_RE.sub(f\" {self.SPECIAL_TOKENS['DATE']} \", text)\n",
        "\n",
        "        # 8) الوقت قبل الأرقام\n",
        "        text = self.TIME_RE.sub(f\" {self.SPECIAL_TOKENS['TIME']} \", text)\n",
        "\n",
        "        # 9) بقية الأرقام\n",
        "        text = self.NUM_RE.sub(f\" {self.SPECIAL_TOKENS['NUM']} \", text)\n",
        "\n",
        "        # 10) فصل علامات الترقيم المستهدفة\n",
        "        text = self._separate_punctuation(text)\n",
        "\n",
        "        # 11) توحيد المسافات\n",
        "        text = re.sub(r\"[ \\t\\f\\v]+\", \" \", text)\n",
        "        text = re.sub(r\" +\", \" \", text).strip()\n",
        "\n",
        "        # 12) (جديد) حذف/تنظيف الرموز غير المرغوبة (مثل « » … - وغيرها)\n",
        "        text = self.normalize_tokens_remove_unwanted(text, remove_inside_token=True, drop_empty=True)\n",
        "\n",
        "        # إعادة توحيد المسافات بعد الحذف\n",
        "        text = re.sub(r\" +\", \" \", text).strip()\n",
        "        return text\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def punctuations_to_class(punctuation_tokens: Iterable[str]) -> int:\n",
        "        \"\"\"حل تعدد علامات الترقيم بعد كلمة واحدة وفق الأولوية.\"\"\"\n",
        "        tokens = set(punctuation_tokens)\n",
        "        for punct in ArabicPunctuationProcessor.MULTI_PUNCT_PRIORITY:\n",
        "            if punct in tokens:\n",
        "                return ArabicPunctuationProcessor.PUNCTUATION_TO_CLASS[punct]\n",
        "        return 0\n",
        "\n",
        "    def split_tokens_labels(self, text: str, preprocess: bool = False) -> Tuple[List[str], List[int]]:\n",
        "        \"\"\"\n",
        "        تقسيم النص إلى (words, labels)\n",
        "        - كل توكن غير ترقيم يعتبر \"word token\" بما فيها [LINE]\n",
        "        - label يمثل الترقيم التالي للتوكن\n",
        "        - [LINE] يأخذ -100 (مستبعد من الخسارة والتقييم)\n",
        "        \"\"\"\n",
        "        if preprocess:\n",
        "            text = self.preprocess_text(text)\n",
        "\n",
        "        words: List[str] = []\n",
        "        labels: List[int] = []\n",
        "        pending_punctuations: List[str] = []\n",
        "\n",
        "        for token in self.tokenize_arabic_words(text):\n",
        "            # تجميع علامات الترقيم\n",
        "            if token in self.PUNCTUATION_SET:\n",
        "                pending_punctuations.append(token)\n",
        "                continue\n",
        "\n",
        "            # تطبيق الترقيم المعلّق على آخر توكن (إن لم يكن [LINE])\n",
        "            if pending_punctuations and labels:\n",
        "                if labels[-1] != -100:\n",
        "                    labels[-1] = ArabicPunctuationProcessor.punctuations_to_class(pending_punctuations)\n",
        "                pending_punctuations.clear()\n",
        "\n",
        "            words.append(token)\n",
        "\n",
        "            # وسم [LINE] = -100\n",
        "            if token == self.SPECIAL_TOKENS[\"LINE\"]:\n",
        "                labels.append(-100)\n",
        "            else:\n",
        "                labels.append(0)\n",
        "\n",
        "        # ترقيم في النهاية\n",
        "        if pending_punctuations and labels:\n",
        "            if labels[-1] != -100:\n",
        "                labels[-1] = ArabicPunctuationProcessor.punctuations_to_class(pending_punctuations)\n",
        "\n",
        "        return words, labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6bfd05c",
      "metadata": {},
      "source": [
        "تجريب التنظيف فيما اذا كان يعمل او لا"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "037b5bf6",
      "metadata": {
        "id": "037b5bf6",
        "outputId": "c25196cd-5de3-47db-9762-b36cd81144ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cleaned Text: [LINE] السلام عليكم ورحمة الله وبركاته ! [LINE] في يوم [DATE] و [DATE] و [DATE] و [DATE] و [DATE] ، أعلنت الشركة ، : سنصدر التقرير في الساعة [TIME] و [TIME] و [TIME] ! . [LINE] للتفاصيل زر : [URL] أو [URL] . [LINE] راسلنا على [EMAIL] أو [EMAIL] [LINE] النسبة [NUM] و [NUM] ٪ و [NUM] ، [NUM] و [NUM] ٬ [NUM] و [NUM] و [NUM] ، [NUM] . [LINE] هذا سطر جديد [LINE] وهذا سطر آخر [LINE] [LINE] هذا يجب أن يبقى كما هو ولا يعاد توليده . [LINE] رموز غير مستهدفة يجب حذفها : ؛ ؛ ؟ ؟ ! ! . . . ، ، ، . . [LINE] وهل تفهم هذا ؟ ! نعم . . . لا ، ربما ؛ لكن : انتبه ! ! [LINE] [LINE]\n",
            "Tokenized Words: ['[LINE]', 'السلام', 'عليكم', 'ورحمة', 'الله', 'وبركاته', '!', '[LINE]', 'في', 'يوم', '[DATE]', 'و', '[DATE]', 'و', '[DATE]', 'و', '[DATE]', 'و', '[DATE]', '،', 'أعلنت', 'الشركة', '،', ':', 'سنصدر', 'التقرير', 'في', 'الساعة', '[TIME]', 'و', '[TIME]', 'و', '[TIME]', '!', '.', '[LINE]', 'للتفاصيل', 'زر', ':', '[URL]', 'أو', '[URL]', '.', '[LINE]', 'راسلنا', 'على', '[EMAIL]', 'أو', '[EMAIL]', '[LINE]', 'النسبة', '[NUM]', 'و', '[NUM]', '٪', 'و', '[NUM]', '،', '[NUM]', 'و', '[NUM]', '٬', '[NUM]', 'و', '[NUM]', 'و', '[NUM]', '،', '[NUM]', '.', '[LINE]', 'هذا', 'سطر', 'جديد', '[LINE]', 'وهذا', 'سطر', 'آخر', '[LINE]', '[LINE]', 'هذا', 'يجب', 'أن', 'يبقى', 'كما', 'هو', 'ولا', 'يعاد', 'توليده', '.', '[LINE]', 'رموز', 'غير', 'مستهدفة', 'يجب', 'حذفها', ':', '؛', '؛', '؟', '؟', '!', '!', '.', '.', '.', '،', '،', '،', '.', '.', '[LINE]', 'وهل', 'تفهم', 'هذا', '؟', '!', 'نعم', '.', '.', '.', 'لا', '،', 'ربما', '؛', 'لكن', ':', 'انتبه', '!', '!', '[LINE]', '[LINE]']\n",
            "words are ['[LINE]', 'السلام', 'عليكم', 'ورحمة', 'الله', 'وبركاته', '[LINE]', 'في', 'يوم', '[DATE]', 'و', '[DATE]', 'و', '[DATE]', 'و', '[DATE]', 'و', '[DATE]', 'أعلنت', 'الشركة', 'سنصدر', 'التقرير', 'في', 'الساعة', '[TIME]', 'و', '[TIME]', 'و', '[TIME]', '[LINE]', 'للتفاصيل', 'زر', '[URL]', 'أو', '[URL]', '[LINE]', 'راسلنا', 'على', '[EMAIL]', 'أو', '[EMAIL]', '[LINE]', 'النسبة', '[NUM]', 'و', '[NUM]', '٪', 'و', '[NUM]', '[NUM]', 'و', '[NUM]', '٬', '[NUM]', 'و', '[NUM]', 'و', '[NUM]', '[NUM]', '[LINE]', 'هذا', 'سطر', 'جديد', '[LINE]', 'وهذا', 'سطر', 'آخر', '[LINE]', '[LINE]', 'هذا', 'يجب', 'أن', 'يبقى', 'كما', 'هو', 'ولا', 'يعاد', 'توليده', '[LINE]', 'رموز', 'غير', 'مستهدفة', 'يجب', 'حذفها', '[LINE]', 'وهل', 'تفهم', 'هذا', 'نعم', 'لا', 'ربما', 'لكن', 'انتبه', '[LINE]', '[LINE]']\n",
            "labels are [-100, 0, 0, 0, 0, 6, -100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 6, -100, 0, 3, 0, 0, 4, -100, 0, 0, 0, 0, 0, -100, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 4, -100, 0, 0, 0, -100, 0, 0, 0, -100, -100, 0, 0, 0, 0, 0, 0, 0, 0, 4, -100, 0, 0, 0, 0, 5, -100, 0, 0, 5, 4, 1, 2, 3, 6, -100, -100]\n",
            "Word: [LINE] , class : -100 , punctuation : MASKED\n",
            "Word: السلام , class : 0 , punctuation : \n",
            "Word: عليكم , class : 0 , punctuation : \n",
            "Word: ورحمة , class : 0 , punctuation : \n",
            "Word: الله , class : 0 , punctuation : \n",
            "Word: وبركاته , class : 6 , punctuation : !\n",
            "Word: [LINE] , class : -100 , punctuation : MASKED\n",
            "Word: في , class : 0 , punctuation : \n",
            "Word: يوم , class : 0 , punctuation : \n",
            "Word: [DATE] , class : 0 , punctuation : \n",
            "Word: و , class : 0 , punctuation : \n",
            "Word: [DATE] , class : 0 , punctuation : \n",
            "Word: و , class : 0 , punctuation : \n",
            "Word: [DATE] , class : 0 , punctuation : \n",
            "Word: و , class : 0 , punctuation : \n",
            "Word: [DATE] , class : 0 , punctuation : \n",
            "Word: و , class : 0 , punctuation : \n",
            "Word: [DATE] , class : 1 , punctuation : ،\n",
            "Word: أعلنت , class : 0 , punctuation : \n",
            "Word: الشركة , class : 1 , punctuation : ،\n",
            "Word: سنصدر , class : 0 , punctuation : \n",
            "Word: التقرير , class : 0 , punctuation : \n",
            "Word: في , class : 0 , punctuation : \n",
            "Word: الساعة , class : 0 , punctuation : \n",
            "Word: [TIME] , class : 0 , punctuation : \n",
            "Word: و , class : 0 , punctuation : \n",
            "Word: [TIME] , class : 0 , punctuation : \n",
            "Word: و , class : 0 , punctuation : \n",
            "Word: [TIME] , class : 6 , punctuation : !\n",
            "Word: [LINE] , class : -100 , punctuation : MASKED\n",
            "Word: للتفاصيل , class : 0 , punctuation : \n",
            "Word: زر , class : 3 , punctuation : :\n",
            "Word: [URL] , class : 0 , punctuation : \n",
            "Word: أو , class : 0 , punctuation : \n",
            "Word: [URL] , class : 4 , punctuation : .\n",
            "Word: [LINE] , class : -100 , punctuation : MASKED\n",
            "Word: راسلنا , class : 0 , punctuation : \n",
            "Word: على , class : 0 , punctuation : \n",
            "Word: [EMAIL] , class : 0 , punctuation : \n",
            "Word: أو , class : 0 , punctuation : \n",
            "Word: [EMAIL] , class : 0 , punctuation : \n",
            "Word: [LINE] , class : -100 , punctuation : MASKED\n",
            "Word: النسبة , class : 0 , punctuation : \n",
            "Word: [NUM] , class : 0 , punctuation : \n",
            "Word: و , class : 0 , punctuation : \n",
            "Word: [NUM] , class : 0 , punctuation : \n",
            "Word: ٪ , class : 0 , punctuation : \n",
            "Word: و , class : 0 , punctuation : \n",
            "Word: [NUM] , class : 1 , punctuation : ،\n",
            "Word: [NUM] , class : 0 , punctuation : \n",
            "Word: و , class : 0 , punctuation : \n",
            "Word: [NUM] , class : 0 , punctuation : \n",
            "Word: ٬ , class : 0 , punctuation : \n",
            "Word: [NUM] , class : 0 , punctuation : \n",
            "Word: و , class : 0 , punctuation : \n",
            "Word: [NUM] , class : 0 , punctuation : \n",
            "Word: و , class : 0 , punctuation : \n",
            "Word: [NUM] , class : 1 , punctuation : ،\n",
            "Word: [NUM] , class : 4 , punctuation : .\n",
            "Word: [LINE] , class : -100 , punctuation : MASKED\n",
            "Word: هذا , class : 0 , punctuation : \n",
            "Word: سطر , class : 0 , punctuation : \n",
            "Word: جديد , class : 0 , punctuation : \n",
            "Word: [LINE] , class : -100 , punctuation : MASKED\n",
            "Word: وهذا , class : 0 , punctuation : \n",
            "Word: سطر , class : 0 , punctuation : \n",
            "Word: آخر , class : 0 , punctuation : \n",
            "Word: [LINE] , class : -100 , punctuation : MASKED\n",
            "Word: [LINE] , class : -100 , punctuation : MASKED\n",
            "Word: هذا , class : 0 , punctuation : \n",
            "Word: يجب , class : 0 , punctuation : \n",
            "Word: أن , class : 0 , punctuation : \n",
            "Word: يبقى , class : 0 , punctuation : \n",
            "Word: كما , class : 0 , punctuation : \n",
            "Word: هو , class : 0 , punctuation : \n",
            "Word: ولا , class : 0 , punctuation : \n",
            "Word: يعاد , class : 0 , punctuation : \n",
            "Word: توليده , class : 4 , punctuation : .\n",
            "Word: [LINE] , class : -100 , punctuation : MASKED\n",
            "Word: رموز , class : 0 , punctuation : \n",
            "Word: غير , class : 0 , punctuation : \n",
            "Word: مستهدفة , class : 0 , punctuation : \n",
            "Word: يجب , class : 0 , punctuation : \n",
            "Word: حذفها , class : 5 , punctuation : ؟\n",
            "Word: [LINE] , class : -100 , punctuation : MASKED\n",
            "Word: وهل , class : 0 , punctuation : \n",
            "Word: تفهم , class : 0 , punctuation : \n",
            "Word: هذا , class : 5 , punctuation : ؟\n",
            "Word: نعم , class : 4 , punctuation : .\n",
            "Word: لا , class : 1 , punctuation : ،\n",
            "Word: ربما , class : 2 , punctuation : ؛\n",
            "Word: لكن , class : 3 , punctuation : :\n",
            "Word: انتبه , class : 6 , punctuation : !\n",
            "Word: [LINE] , class : -100 , punctuation : MASKED\n",
            "Word: [LINE] , class : -100 , punctuation : MASKED\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:1: SyntaxWarning: invalid escape sequence '\\ '\n",
            "<>:1: SyntaxWarning: invalid escape sequence '\\ '\n",
            "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_24952\\4034308780.py:1: SyntaxWarning: invalid escape sequence '\\ '\n",
            "  text = \"\"\"\n"
          ]
        }
      ],
      "source": [
        "text = \"\"\"\n",
        "السَّلامُ عَلَيْكُمْ ورحمةُ اللهِ وبركاتُهُ!\n",
        "في يوم 12/05/2023 و ١٥-٠٨-٢٠٢٢ و 7.3.21 و ٣١ ديسمبر ٢٠٢٠ و 1 يناير 2024، أعلَنَتِ الشَّركة،: «سنُصدِرُ التَّقرير في الساعة 14:30 و ٢:٣٠ م و 09:05AM!».\n",
        "للتفاصيل… زر: https://Example.com/path?a=1&b=2 أو www.test-site.org/صفحة.\n",
        "راسلنا على Test.Email+x99@domain.co.uk أو support@مثال.com\n",
        "النِّسبة 12.5% و ١٢٫٥٪ و 1,234.56 و ١٬٢٣٤٫٥٦ و ٣٠٠٠٠ و 30,000.\n",
        "هذا سطرٌ جديد\n",
        "وهذا سطرٌ آخر\twith tabs   and   extra   spaces\n",
        "[LINE] هذا يجب أن يبقى كما هو ولا يُعاد توليده.\n",
        "رموز غير مستهدفة يجب حذفها: ( ) [ ] { } « » “ ” ' \" … — – - ـ / \\ | @ # $ ^ & * _ + = ~ ` ؛؛؟؟!!...،،,..\n",
        "وهل تفهم هذا ؟! نعم... لا، ربما؛ لكن: انتبه!!\n",
        "\n",
        "\"\"\"\n",
        "processor = ArabicPunctuationProcessor(remove_diacritics=True)\n",
        "\n",
        "\n",
        "\n",
        "# print(\"Original Text:\", text2)\n",
        "\n",
        "cleaned = processor.preprocess_text(text)\n",
        "print(\"Cleaned Text:\", processor.preprocess_text(text))\n",
        "print(\"Tokenized Words:\", processor.tokenize_arabic_words(cleaned))\n",
        "\n",
        "words, labels = processor.split_tokens_labels(cleaned)\n",
        "print(\"words are\" , words)\n",
        "print(\"labels are\" , labels)\n",
        "\n",
        "for idx, word in enumerate(words):\n",
        "    print(f\"Word: {word} , class : {labels[idx]} , punctuation : {list(processor.PUNCTUATION_TO_CLASS.keys())[labels[idx]] if labels[idx] != -100 else 'MASKED'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a93cf31",
      "metadata": {},
      "source": [
        "ملاحظة:\n",
        "\n",
        "ظهر لي ايرور مسبقا بسبب امتلاء الرام ولكن قمت بحذف الخلية عن طريق الخطا"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_qGTDp2-N6WD",
      "metadata": {
        "id": "_qGTDp2-N6WD"
      },
      "source": [
        "# نظرا لحجم الداتا الضخم، فاننا لا نتسطيع تحميل البيانات كلها للرام، لذلك سوف نقوم بمعالجة الملفات ملف ملف وتخزينهم على الرام\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ce2d8eb",
      "metadata": {
        "id": "7ce2d8eb"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import json\n",
        "import os\n",
        "import logging\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "from typing import Callable, Dict, Optional, Tuple\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class CleanStats:\n",
        "    files_seen: int = 0\n",
        "    files_processed: int = 0\n",
        "    lines_processed: int = 0\n",
        "    chars_in: int = 0\n",
        "    chars_out: int = 0\n",
        "    errors: int = 0\n",
        "\n",
        "\n",
        "def _labels_from_preprocessed(processor, preprocessed_text: str) -> Counter:\n",
        "    \"\"\"\n",
        "    هذا التابع مطابق لتابع فصل النص الى كلمات ووسوم في ال\n",
        "    processor\n",
        "\n",
        "    \"\"\"\n",
        "    punct_set = set(processor.ARABIC_PUNCTUATION)\n",
        "    label_counts = Counter()\n",
        "\n",
        "    pending_punct = []\n",
        "    have_prev_word = False\n",
        "    prev_label = 0 \n",
        "\n",
        "    for tok in preprocessed_text.split():\n",
        "        if tok in punct_set:\n",
        "            pending_punct.append(tok)\n",
        "            continue\n",
        "\n",
        "        if have_prev_word:\n",
        "            if pending_punct:\n",
        "                prev_label = processor.punctuations_to_class(pending_punct)\n",
        "                pending_punct.clear()\n",
        "            else:\n",
        "                prev_label = 0\n",
        "            label_counts[processor.CLASS_TO_PUNCTUATION.get(prev_label)] += 1\n",
        "        else:\n",
        "            have_prev_word = True\n",
        "\n",
        "\n",
        "    if have_prev_word:\n",
        "        if pending_punct:\n",
        "            prev_label = processor.punctuations_to_class(pending_punct)\n",
        "        else:\n",
        "            prev_label = 0\n",
        "        label_counts[processor.CLASS_TO_PUNCTUATION.get(prev_label)] += 1\n",
        "\n",
        "    return label_counts\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def clean_corpus_with_stats(\n",
        "    input_dir: str | Path,\n",
        "    output_dir: str | Path,\n",
        "    processor,\n",
        "    *,\n",
        "    pattern: str = \"*.txt\",\n",
        "    recursive: bool = False,\n",
        "    encoding: str = \"utf-8\",\n",
        "    read_errors: str = \"replace\",\n",
        "    newline: str = \"\\n\",\n",
        "    per_file_stats_jsonl: str | Path = \"per_file_stats.jsonl\",\n",
        "    corpus_summary_json: str | Path = \"corpus_summary.json\",\n",
        "    run_log_path: Optional[str | Path] = \"run.log\",\n",
        "    resume: bool = True,  # <-- NEW\n",
        ") -> Tuple[CleanStats, Counter]:\n",
        "\n",
        "    \"\"\"\n",
        "    هذا التابع يقوم بتنظيف الداتا الموجودة ضمن مجلد، ولا يقوم بتظيف داتا مرسلة ضمن الباراميترات\n",
        "    كالمطلوب ضمن الملف\n",
        "    \"\"\"\n",
        "    logger = logging.getLogger(\"clean_corpus_with_stats\")\n",
        "    logger.setLevel(logging.INFO)\n",
        "    logger.handlers.clear()\n",
        "    if run_log_path is not None:\n",
        "        run_log_path = Path(run_log_path)\n",
        "        run_log_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "        fh = logging.FileHandler(run_log_path, encoding=\"utf-8\")\n",
        "        fh.setFormatter(logging.Formatter(\"%(asctime)s %(levelname)s: %(message)s\"))\n",
        "        logger.addHandler(fh)\n",
        "\n",
        "    in_root = Path(input_dir)\n",
        "    out_root = Path(output_dir)\n",
        "    out_root.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    per_file_stats_path = Path(per_file_stats_jsonl)\n",
        "    per_file_stats_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    corpus_summary_path = Path(corpus_summary_json)\n",
        "    corpus_summary_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    files = sorted(in_root.rglob(pattern) if recursive else in_root.glob(pattern))\n",
        "    stats = CleanStats(files_seen=len(files))\n",
        "\n",
        "    global_label_counts = Counter()\n",
        "\n",
        "    stats_mode = \"a\" if (resume and per_file_stats_path.exists()) else \"w\"\n",
        "\n",
        "    with per_file_stats_path.open(stats_mode, encoding=\"utf-8\") as stats_out:\n",
        "        for file in files:\n",
        "            if not file.is_file():\n",
        "                continue\n",
        "\n",
        "            rel = file.relative_to(in_root)\n",
        "            out_path = out_root / rel\n",
        "            out_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "            tmp_out = out_path.with_suffix(out_path.suffix + \".tmp\")\n",
        "\n",
        "            if resume:\n",
        "                if tmp_out.exists():\n",
        "                    try:\n",
        "                        tmp_out.unlink()\n",
        "                        logger.info(\"Removed stale tmp: %s\", tmp_out)\n",
        "                    except Exception:\n",
        "                        logger.exception(\"Could not remove tmp: %s\", tmp_out)\n",
        "\n",
        "                if out_path.exists() and out_path.stat().st_size > 0:\n",
        "\n",
        "                    stats.files_processed += 1\n",
        "                    continue\n",
        "\n",
        "            file_label_counts = Counter()\n",
        "            file_lines = 0\n",
        "            file_chars_in = 0\n",
        "            file_chars_out = 0\n",
        "\n",
        "            try:\n",
        "                with file.open(\"r\", encoding=encoding, errors=read_errors) as fin, \\\n",
        "                     tmp_out.open(\"w\", encoding=\"utf-8\", newline=newline) as fout:\n",
        "\n",
        "                    for line in fin:\n",
        "                        file_lines += 1\n",
        "                        stats.lines_processed += 1\n",
        "\n",
        "                        file_chars_in += len(line)\n",
        "                        stats.chars_in += len(line)\n",
        "\n",
        "                        cleaned = processor.preprocess_text(line)\n",
        "\n",
        "                        # إذا أردت الحفاظ على حدود الأسطر كـ [LINE] فالأفضل ألا تضيف \" \"\n",
        "                        # لكن أبقيت سلوكك كما هو لتفادي لصق الكلمات\n",
        "                        if line.endswith(\"\\n\") and not cleaned.endswith(\"\\n\"):\n",
        "                            cleaned += \" \"\n",
        "\n",
        "                        file_chars_out += len(cleaned)\n",
        "                        stats.chars_out += len(cleaned)\n",
        "\n",
        "                        fout.write(cleaned)\n",
        "\n",
        "                        line_counts = _labels_from_preprocessed(processor, cleaned.strip())\n",
        "                        file_label_counts.update(line_counts)\n",
        "                        global_label_counts.update(line_counts)\n",
        "\n",
        "                os.replace(tmp_out, out_path)\n",
        "                stats.files_processed += 1\n",
        "\n",
        "                classes_present = sorted([str(c) for c, n in file_label_counts.items() if n > 0])\n",
        "                record = {\n",
        "                    \"file\": str(rel),\n",
        "                    \"lines\": file_lines,\n",
        "                    \"chars_in\": file_chars_in,\n",
        "                    \"chars_out\": file_chars_out,\n",
        "                    \"num_classes_present\": len(classes_present),\n",
        "                    \"classes_present\": classes_present,\n",
        "                    \"class_counts\": {str(k): int(v) for k, v in file_label_counts.items()},\n",
        "                }\n",
        "                stats_out.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "            except Exception:\n",
        "                stats.errors += 1\n",
        "                logger.exception(\"Failed processing: %s\", file)\n",
        "\n",
        "                try:\n",
        "                    if tmp_out.exists():\n",
        "                        tmp_out.unlink()\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "                err_record = {\"file\": str(rel), \"error\": \"processing_failed\"}\n",
        "                stats_out.write(json.dumps(err_record, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "    corpus_summary = {\n",
        "        \"files_seen\": stats.files_seen,\n",
        "        \"files_processed\": stats.files_processed,\n",
        "        \"lines_processed\": stats.lines_processed,\n",
        "        \"chars_in\": stats.chars_in,\n",
        "        \"chars_out\": stats.chars_out,\n",
        "        \"errors\": stats.errors,\n",
        "        \"global_class_counts\": {str(k): int(v) for k, v in global_label_counts.items()},\n",
        "        \"classes_present\": sorted([str(k) for k, v in global_label_counts.items() if v > 0]),\n",
        "    }\n",
        "    corpus_summary_path.write_text(json.dumps(corpus_summary, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "\n",
        "    return stats, global_label_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "L7sqs_0e1VO_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7sqs_0e1VO_",
        "outputId": "83f859a7-5e3c-43e7-8e93-a78fba3bb1c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(CleanStats(files_seen=79, files_processed=79, lines_processed=11731360, chars_in=1924651569, chars_out=2048748357, errors=0),\n",
              " Counter({'': 292642180,\n",
              "          '،': 14614673,\n",
              "          '.': 11708631,\n",
              "          '؛': 1536882,\n",
              "          ':': 546474,\n",
              "          '؟': 53844,\n",
              "          '!': 733}))"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "processor = ArabicPunctuationProcessor(remove_diacritics=True)\n",
        "clean_corpus_with_stats(\n",
        "    input_dir = Config.raw_data_dir,\n",
        "    output_dir = Config.cleaned_data_dir ,\n",
        "    processor = processor,\n",
        "    per_file_stats_jsonl= Config.per_file_stats_json_dir,\n",
        "    corpus_summary_json= Config.corpus_summary_json_dir,\n",
        "    run_log_path=Config.run_log_dir,\n",
        "    resume=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae3a944f",
      "metadata": {},
      "source": [
        "هنا نلاحظ ان هناك تفاوت ضخم جدا بين نسب الكلاسات \n",
        "\n",
        "فإشارة التعجب شبه معدومة \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbe14a3c",
      "metadata": {},
      "source": [
        "# بناء بعض النماذج المرجعية"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f01442a3",
      "metadata": {},
      "source": [
        "### التوابع الأساسية لتحميل الداتا\n",
        "\n",
        "#### `iter_cleaned_files`:\n",
        "- هذا التابع يستقبل الباث الذي يحتوي على ملفات الداتا.\n",
        "- عوضاً عن ترجيع كامل باثات الملفات، نقوم بترجيعهم باستخدام تعليمة **`Yield`** للحفاظ على الذاكرة.\n",
        "\n",
        "#### `iter_tokens_from_file`:\n",
        "- هذا التابع يعيد الكلمات من الملف بنفس الطريقة السابقة.\n",
        "- نعيد كلمة كلمة عوضاً عن تحميل الملف كاملاً للذاكرة.\n",
        "\n",
        "#### `split_tokens_labels_from_tokens`:\n",
        "- هذا التابع يستقبل مصفوفة من التوكينز (خرج التابع السابق).\n",
        "- يقوم بارجاع مصفوفتين:\n",
        "  - الأولى تحتوي على **الكلمات**.\n",
        "  - الثانية تحتوي على **الوسوم** لكل كلمة.\n",
        "\n",
        "### `load_tokens_labels_from_file`: \n",
        "- هذا التابع يستقبل باث الملف \n",
        "- يقوم بتحويل الملف لتوكينر باستدعاء التابع الثاني\n",
        "- يعيد مصفوفتين توكينز وليبيلز من التابع السابق"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7276b082",
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "import os\n",
        "import glob\n",
        "import math\n",
        "import random\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, Iterable, Iterator, List, Optional, Sequence, Tuple\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# sklearn\n",
        "from sklearn.feature_extraction import FeatureHasher\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import f1_score, classification_report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "adcba193",
      "metadata": {},
      "outputs": [],
      "source": [
        "def iter_cleaned_files(cleaned_dir: str, pattern: str = \"*.txt\") -> Iterator[str]:\n",
        "    \"\"\"\n",
        "    هذا التابع يعيد الباث لكل ملف ضمن مجلد \n",
        "    \"\"\"\n",
        "    paths = sorted(glob.glob(os.path.join(cleaned_dir, pattern)))\n",
        "    for p in paths:\n",
        "        if os.path.isfile(p):\n",
        "            yield p\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f4140971",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "./Clean/full-corpus2\\UNPC_Sentences_1.txt\n",
            "./Clean/full-corpus2\\UNPC_Sentences_10.txt\n",
            "./Clean/full-corpus2\\UNPC_Sentences_11.txt\n",
            "./Clean/full-corpus2\\UNPC_Sentences_12.txt\n",
            "./Clean/full-corpus2\\UNPC_Sentences_13.txt\n",
            "./Clean/full-corpus2\\UNPC_Sentences_14.txt\n",
            "./Clean/full-corpus2\\UNPC_Sentences_15.txt\n",
            "./Clean/full-corpus2\\UNPC_Sentences_16.txt\n",
            "./Clean/full-corpus2\\UNPC_Sentences_17.txt\n",
            "./Clean/full-corpus2\\UNPC_Sentences_18.txt\n",
            "79\n"
          ]
        }
      ],
      "source": [
        "files = iter_cleaned_files(cleaned_dir=Config.cleaned_data_dir)\n",
        "cnt = 0 \n",
        "for file in files:\n",
        "    print(file)\n",
        "    cnt += 1 \n",
        "    if cnt == 10 : \n",
        "        break\n",
        "print(len(list(iter_cleaned_files(cleaned_dir=Config.cleaned_data_dir))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "9f036f2d",
      "metadata": {},
      "outputs": [],
      "source": [
        "def iter_tokens_from_file(path: str) -> Iterator[str]:\n",
        "    \"\"\"\n",
        "    هذا التابع يعيد التوكنز من ملف نصي\n",
        "    \"\"\"\n",
        "    with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            for tok in line.split():\n",
        "                yield tok\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "da64179c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "البلاغات\n",
            "الوطنية\n",
            "المقدمة\n",
            "من\n",
            "الاطراف\n",
            "المدرجة\n",
            "في\n",
            "المرفق\n",
            "الاول\n",
            "بالاتفاقية\n",
            ".\n",
            "[LINE]\n",
            "انشطة\n",
            "الامانة\n",
            "لتيسير\n",
            "تقديم\n",
            "الدعم\n",
            "المالي\n",
            "والتقني\n",
            ".\n"
          ]
        }
      ],
      "source": [
        "tokens = iter_tokens_from_file(next(files))\n",
        "for _ in range(20):\n",
        "    print(next(tokens))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6d3818a",
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_tokens_labels_from_tokens(tokens: Sequence[str]) -> Tuple[List[str], List[int]]:\n",
        "    \"\"\"\n",
        "    هذا التابع يقسم التوكنز الى كلمات ووسوم\n",
        "    0-6 للفواصل، -100 لـ [LINE]\n",
        "    \n",
        "    نضع -100 لـ [LINE] لكي لا تؤثر على خسارة الموديل اثناء التدريب\n",
        "    \n",
        "    \"\"\"\n",
        "    words: List[str] = []\n",
        "    labels: List[int] = []\n",
        "    pending_punct: List[str] = []\n",
        "    LINE_TOKEN = ArabicPunctuationProcessor.SPECIAL_TOKENS[\"LINE\"]\n",
        "    for tok in tokens:\n",
        "        if tok in ArabicPunctuationProcessor.PUNCT_SET:\n",
        "            pending_punct.append(tok)\n",
        "            continue\n",
        "\n",
        "        if pending_punct and labels:\n",
        "            if labels[-1] != -100:\n",
        "                labels[-1] = ArabicPunctuationProcessor.punctuations_to_class(pending_punct)\n",
        "            pending_punct.clear()\n",
        "\n",
        "        words.append(tok)\n",
        "        if tok == LINE_TOKEN:\n",
        "            labels.append(-100)  \n",
        "        else:\n",
        "            labels.append(0)\n",
        "\n",
        "    if pending_punct and labels:\n",
        "        if labels[-1] != -100:\n",
        "            labels[-1] = ArabicPunctuationProcessor.punctuations_to_class(pending_punct)\n",
        "\n",
        "    return words, labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "03adfcf9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Text: [LINE] السلام عليكم ورحمة الله وبركاته . [LINE] في يوم [DATE] ، أعلنت الشركة : سنصدر التقرير في الساعة [TIME] ! . [LINE] [LINE] ثم أضاف المدير : هل سيكون الاجتماع يوم [DATE] أم [DATE] ؟ [LINE] الإيرادات بلغت [NUM] مليار دولار ، ونسبة النمو [NUM] ، وقيمة المؤشر [NUM] . [LINE] [LINE] للتفاصيل زر : [LINE] [URL] [LINE] أو راسلنا على [EMAIL] ، أو [EMAIL] . [LINE] [LINE] ملاحظة : [LINE] الرجاء التواصل السريع عبر [URL] [LINE] واحذر : هل تفهم هذا ؟ ! نعم . . . وإن شئت فاسألني . [LINE]\n",
            "Word: [LINE] , Label: MASKED\n",
            "Word: السلام , Label: \n",
            "Word: عليكم , Label: \n",
            "Word: ورحمة , Label: \n",
            "Word: الله , Label: \n",
            "Word: وبركاته , Label: .\n",
            "Word: [LINE] , Label: MASKED\n",
            "Word: في , Label: \n",
            "Word: يوم , Label: \n",
            "Word: [DATE] , Label: ،\n",
            "Word: أعلنت , Label: \n",
            "Word: الشركة , Label: :\n",
            "Word: سنصدر , Label: \n",
            "Word: التقرير , Label: \n",
            "Word: في , Label: \n",
            "Word: الساعة , Label: \n",
            "Word: [TIME] , Label: !\n",
            "Word: [LINE] , Label: MASKED\n",
            "Word: [LINE] , Label: MASKED\n",
            "Word: ثم , Label: \n",
            "Word: أضاف , Label: \n",
            "Word: المدير , Label: :\n",
            "Word: هل , Label: \n",
            "Word: سيكون , Label: \n",
            "Word: الاجتماع , Label: \n",
            "Word: يوم , Label: \n",
            "Word: [DATE] , Label: \n",
            "Word: أم , Label: \n",
            "Word: [DATE] , Label: ؟\n",
            "Word: [LINE] , Label: MASKED\n",
            "Word: الإيرادات , Label: \n",
            "Word: بلغت , Label: \n",
            "Word: [NUM] , Label: \n",
            "Word: مليار , Label: \n",
            "Word: دولار , Label: ،\n",
            "Word: ونسبة , Label: \n",
            "Word: النمو , Label: \n",
            "Word: [NUM] , Label: ،\n",
            "Word: وقيمة , Label: \n",
            "Word: المؤشر , Label: \n",
            "Word: [NUM] , Label: .\n",
            "Word: [LINE] , Label: MASKED\n",
            "Word: [LINE] , Label: MASKED\n",
            "Word: للتفاصيل , Label: \n",
            "Word: زر , Label: :\n",
            "Word: [LINE] , Label: MASKED\n",
            "Word: [URL] , Label: \n",
            "Word: [LINE] , Label: MASKED\n",
            "Word: أو , Label: \n",
            "Word: راسلنا , Label: \n",
            "Word: على , Label: \n",
            "Word: [EMAIL] , Label: ،\n",
            "Word: أو , Label: \n",
            "Word: [EMAIL] , Label: .\n",
            "Word: [LINE] , Label: MASKED\n",
            "Word: [LINE] , Label: MASKED\n",
            "Word: ملاحظة , Label: :\n",
            "Word: [LINE] , Label: MASKED\n",
            "Word: الرجاء , Label: \n",
            "Word: التواصل , Label: \n",
            "Word: السريع , Label: \n",
            "Word: عبر , Label: \n",
            "Word: [URL] , Label: \n",
            "Word: [LINE] , Label: MASKED\n",
            "Word: واحذر , Label: :\n",
            "Word: هل , Label: \n",
            "Word: تفهم , Label: \n",
            "Word: هذا , Label: ؟\n",
            "Word: نعم , Label: .\n",
            "Word: وإن , Label: \n",
            "Word: شئت , Label: \n",
            "Word: فاسألني , Label: .\n",
            "Word: [LINE] , Label: MASKED\n"
          ]
        }
      ],
      "source": [
        "processor = ArabicPunctuationProcessor(remove_diacritics=True)\n",
        "text2 = \"\"\"\n",
        "السَّلامُ عَلَيْكُمْ وَرَحْمَةُ اللهِ وَبَرَكَاتُهُ.\n",
        "فِي يَوْمِ ١٢ مَايُو ٢٠٢٤، أَعْلَنَتِ الشَّرِكَةُ: «سَنُصْدِرُ التَّقْرِيرَ فِي السَّاعَةِ 14:30!».\n",
        "\n",
        "ثُمَّ أَضَافَ المُدِيرُ: هَلْ سَيَكُونُ الِاجْتِمَاعُ يَوْمَ 2023/03/15 أَمْ ١٥/٠٦/٢٠٢٤؟\n",
        "الإِيرَادَاتُ بَلَغَتْ 3.75 مِلْيَارَ دُولَارٍ، وَنِسْبَةُ النُّمُوِّ 12.5%، وَقِيمَةُ المُؤَشِّرِ ٧.٢٥%.\n",
        "\n",
        "لِلتَّفَاصِيلِ زُرْ:\n",
        "https://www.example.com/reports/2024/Q1?lang=ar\n",
        "أَوْ رَاسِلْنَا عَلَى info@example.com، أَوْ support@service.co.uk.\n",
        "\n",
        "مُلَاحَظَةٌ:\n",
        "- الرَّجَاءُ التَّوَاصُلُ السَّرِيعُ عَبْرَ www.contact-us.org\n",
        "- وَاحْذَرْ: هَلْ تَفْهَمُ هٰذَا؟! نَعَمْ... وَإِنْ شِئْتَ فَاسْأَلْنِي.\n",
        "\"\"\"\n",
        "text2 = processor.preprocess_text(text2)\n",
        "print(\"Original Text:\", text2)\n",
        "\n",
        "words, labels = split_tokens_labels_from_tokens(text2.split())\n",
        "\n",
        "for i in range(len(words)):\n",
        "    print(f\"Word: {words[i]} , Label: {ArabicPunctuationProcessor.CLASS_TO_PUNCTUATION.get(labels[i], 'MASKED')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "5e137eab",
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_tokens_labels_from_file(path: str, max_tokens: Optional[int] = None) -> Tuple[List[str], List[int]]:\n",
        "    \"\"\"\n",
        "    تابع لتحميل التوكنز من ملف وتقسيمها الى كلمات ووسوم\n",
        "    \"\"\"\n",
        "    toks = []\n",
        "    for i, tok in enumerate(iter_tokens_from_file(path)):\n",
        "        toks.append(tok)\n",
        "        if max_tokens is not None and (i + 1) >= max_tokens:\n",
        "            break\n",
        "    return split_tokens_labels_from_tokens(toks)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e741634",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sequence from file: ./Clean/full-corpus2\\UNPC_Sentences_1.txt\n",
            "Word: [NUM] , Label: \n",
            "Word: وعملا , Label: \n",
            "Word: بطلب , Label: \n",
            "Word: الجمعية , Label: \n",
            "Word: العامة , Label: \n",
            "Word: الوارد , Label: \n",
            "Word: في , Label: \n",
            "Word: الفقرة , Label: \n",
            "Word: [NUM] , Label: \n",
            "Word: من , Label: \n",
            "Word: القرار , Label: \n",
            "Word: المذكور , Label: \n",
            "Word: اعلاه , Label: ،\n",
            "Word: وجه , Label: \n",
            "Word: الامين , Label: \n",
            "Word: العام , Label: \n",
            "Word: رسالة , Label: \n",
            "Word: معممة , Label: \n",
            "Word: الى , Label: \n",
            "Word: الحكومات , Label: \n",
            "Word: بتاريخ , Label: \n",
            "Word: [NUM] , Label: \n",
            "Word: كانون , Label: \n",
            "Word: الاولديسمبر , Label: \n",
            "Word: [NUM] , Label: ،\n",
            "Word: داعيا , Label: \n",
            "Word: اياها , Label: \n",
            "Word: الى , Label: \n",
            "Word: تقديم , Label: \n",
            "Word: تعليقاتها , Label: \n",
            "Word: الكتابية , Label: ،\n",
            "Word: قبل , Label: \n",
            "Word: الدورة , Label: \n",
            "Word: الخامسة , Label: \n",
            "Word: والاربعين , Label: \n",
            "Word: للجنة , Label: \n",
            "Word: القانون , Label: \n",
            "Word: الدولي , Label: \n",
            "Word: قدر , Label: \n",
            "Word: الامكان , Label: .\n",
            "Word: [LINE] , Label: MASKED\n",
            "Word: [NUM] , Label: \n",
            "Word: الوثائق , Label: \n",
            "Word: الرسمية , Label: \n",
            "Word: للجمعية , Label: \n",
            "Word: العامة , Label: \n"
          ]
        }
      ],
      "source": [
        "file_path = next(iter_cleaned_files(cleaned_dir=Config.cleaned_data_dir))\n",
        "seq = load_tokens_labels_from_file(file_path, max_tokens=50)\n",
        "print(\"Loaded sequence from file:\", file_path)\n",
        "for i in range(len(seq[0])):\n",
        "    print(f\"Word: {seq[0][i]} , Label: {ArabicPunctuationProcessor.CLASS_TO_PUNCTUATION.get(seq[1][i], 'MASKED')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8ccda2e",
      "metadata": {},
      "source": [
        "### في هذا القسم سوف نقوم ببناء بعض الموديلات المرجعية"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "6ebbb93b",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "@dataclass\n",
        "class EvalResult:\n",
        "    macro_f1_1_6: float\n",
        "    per_class_f1: Dict[int, float]\n",
        "    binary_f1_punct: float\n",
        "    support: Dict[int, int]\n",
        "\n",
        "\n",
        "def evaluate_predictions(y_true: Sequence[int], y_pred: Sequence[int]) -> EvalResult:\n",
        "    \"\"\"\n",
        "    المقاييس:\n",
        "  - متوسط F1 الكلي (Macro-F1) عبر الفئات من 1 إلى 6 (مع تجاهل القيم 0 و-100)\n",
        "  - درجة F1 لكل فئة على حدة للفئات من 1 إلى 6\n",
        "  - درجة F1 الثنائية (علامات الترقيم مقابل عدم وجودها)، مع تجاهل القيمة -100\n",
        "\n",
        "    \"\"\"\n",
        "    y_true = np.asarray(y_true, dtype=np.int64)\n",
        "    y_pred = np.asarray(y_pred, dtype=np.int64)\n",
        "\n",
        "    mask = (y_true != -100)\n",
        "    yt = y_true[mask]\n",
        "    yp = y_pred[mask]\n",
        "\n",
        "    # macro over classes 1..6\n",
        "    labels_1_6 = [1, 2, 3, 4, 5, 6]\n",
        "    macro = f1_score(yt, yp, labels=labels_1_6, average=\"macro\", zero_division=0)\n",
        "\n",
        "    per = {}\n",
        "    for c in labels_1_6:\n",
        "        per[c] = f1_score(yt, yp, labels=[c], average=\"macro\", zero_division=0)\n",
        "\n",
        "    # support counts (true)\n",
        "    sup = {c: int((yt == c).sum()) for c in labels_1_6}\n",
        "\n",
        "    # binary punct-vs-none\n",
        "    yt_bin = (yt != 0).astype(np.int64)\n",
        "    yp_bin = (yp != 0).astype(np.int64)\n",
        "    bin_f1 = f1_score(yt_bin, yp_bin, average=\"binary\", zero_division=0)\n",
        "\n",
        "    return EvalResult(\n",
        "        macro_f1_1_6=float(macro),\n",
        "        per_class_f1=per,\n",
        "        binary_f1_punct=float(bin_f1),\n",
        "        support=sup,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a28e80df",
      "metadata": {},
      "source": [
        "## الموديل الأول هو موديل بسيط\n",
        "\n",
        "سيقوم فقط بتوقّع علامة الترقيم (**نقطة** أو **إشارة استفهام**) عند نهاية الجملة فقط.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "id": "9ddcb7d6",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import List, Sequence, Set, Dict\n",
        "\n",
        "LINE_TOKEN = ArabicPunctuationProcessor.SPECIAL_TOKENS[\"LINE\"]\n",
        "\n",
        "\n",
        "# كلمات استفهامية شائعة في العربية الفصحى\n",
        "QUESTION_CUES: Set[str] = {\n",
        "    \"هل\", \"أ\", \"أَ\", \"ألا\", \"أليس\", \"ألم\",\n",
        "    \"ماذا\", \"لماذا\", \"لمَ\", \"كيف\", \"متى\", \"أين\", \"أينما\",\n",
        "    \"من\", \"كم\", \"أي\", \"أية\", \"أيّ\", \"أياً\",\n",
        "    \"ما\", \"لِمَ\", \"بماذا\", \"إلام\", \"إلى\",  # بعض هذه قد تكثر كأدوات عامة\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "TERMINAL_LOOKBACK = 12\n",
        "\n",
        "def predict_terminal(tokens: Sequence[str]) -> List[int]:\n",
        "    \"\"\"\n",
        "    الخط الأساس الاستدلالي: \n",
        "\n",
        "    يتنبأ فقط بعلامات الترقيم الختامية على الرمز الذي يسبق [LINE]\n",
        "\n",
        "    يختار بين «.» و«؟» باستخدام مؤشرات بسيطة من السطر الحالي\n",
        "    \"\"\"\n",
        "    y_pred: List[int] = []\n",
        "    n = len(tokens)\n",
        "\n",
        "   \n",
        "   \n",
        "    line_start = 0\n",
        "\n",
        "    for i, tok in enumerate(tokens):\n",
        "        if tok == LINE_TOKEN:\n",
        "            y_pred.append(-100)\n",
        "            line_start = i + 1\n",
        "            continue\n",
        "\n",
        "        next_tok = tokens[i + 1] if (i + 1) < n else None\n",
        "        is_terminal_pos = (next_tok is None) or (next_tok == LINE_TOKEN)\n",
        "\n",
        "        if not is_terminal_pos:\n",
        "            y_pred.append(0)\n",
        "            continue\n",
        "\n",
        "        # نقوم هنا بتطبيق ما يدعى النافذة المنزلقة على السطر الحالي\n",
        "        \n",
        "        line_tokens = tokens[line_start:i+1]\n",
        "\n",
        "        \n",
        "        tail = line_tokens[-TERMINAL_LOOKBACK:] if len(line_tokens) > TERMINAL_LOOKBACK else line_tokens\n",
        "\n",
        "        # حساب احتمال ان يكون السطر الحالي سؤال\n",
        "        q_phrase = False\n",
        "\n",
        "        # ايجاد كلمات استفهامية شائعة\n",
        "        for w in tail:\n",
        "            if w in QUESTION_CUES:\n",
        "                q_phrase = True\n",
        "                \n",
        "\n",
        "        if q_phrase:\n",
        "            y_pred.append(ArabicPunctuationProcessor.PUNCTUATION_TO_CLASS[\"؟\"])\n",
        "        else:\n",
        "            y_pred.append(ArabicPunctuationProcessor.PUNCTUATION_TO_CLASS[\".\"])\n",
        "\n",
        "    return y_pred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e839170",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed file 1 / 79: ./Clean/full-corpus2\\UNPC_Sentences_1.txt\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[70], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m cnt \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[1;32m----> 8\u001b[0m     words, labels \u001b[38;5;241m=\u001b[39m \u001b[43mload_sequence_from_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     preds \u001b[38;5;241m=\u001b[39m predict_terminal(words)\n\u001b[0;32m     10\u001b[0m     y_trues\u001b[38;5;241m.\u001b[39mextend(labels)\n",
            "Cell \u001b[1;32mIn[20], line 10\u001b[0m, in \u001b[0;36mload_sequence_from_file\u001b[1;34m(path, max_tokens)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m max_tokens \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m max_tokens:\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msplit_tokens_labels_from_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoks\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[17], line 30\u001b[0m, in \u001b[0;36msplit_tokens_labels_from_tokens\u001b[1;34m(tokens)\u001b[0m\n\u001b[0;32m     28\u001b[0m         labels\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m)  \u001b[38;5;66;03m# mask [LINE]\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 30\u001b[0m         labels\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# trailing punctuation applies to last non-[LINE] token\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pending_punct \u001b[38;5;129;01mand\u001b[39;00m labels:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "files = iter_cleaned_files(cleaned_dir=Config.cleaned_data_dir)\n",
        "files = list(files)\n",
        "\n",
        "y_preds, y_trues = [], [] \n",
        "\n",
        "cnt = 1 \n",
        "for file in files:\n",
        "    words, labels = load_tokens_labels_from_file(file)\n",
        "    preds = predict_terminal(words)\n",
        "    y_trues.extend(labels)\n",
        "    y_preds.extend(preds)\n",
        "    print(f\"Processed file {cnt} / {len(files)}: {file}\")\n",
        "    cnt += 1\n",
        "eval_result = evaluate_predictions(y_trues, y_preds)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39cfae39",
      "metadata": {},
      "source": [
        "### هنا نلاحظ ان هذه الطريقة غير فعالة، لذلك من اجل كل ملف، سنقوم بحساب التقييم له، وتحديث التقييم العام لكل الملفات\n",
        "\n",
        "تم تشغيل الخلية السابقة عن طريق الخطا وذهب رسالة خطا ان الرام قد امتلأت"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "879cec4e",
      "metadata": {},
      "source": [
        "# حساب أداء النموذج التراكمي\n",
        "\n",
        "سوف نقوم بإنشاء عدة توابع أساسية لحساب أداء الموديل **تراكمياً** وليس عن طريق تجميع كل اللتوكنز مع الليبلات الخاصة بهل لجميع الملفات وبعد ذلك حساب الاداء\n",
        "\n",
        "##  الطريقة التراكمية\n",
        "\n",
        "إذا نظرنا لطريقة حسابنا للخطأ، فهي تعتمد كلياً فقط على **Confusion Matrix** (مصفوفة الارتباك).  \n",
        "منها نستطيع حساب كل شيء، لأنها تحتوي:\n",
        "\n",
        "- **عدد مرات** توقع النموذج توقعاً صحيحاً\n",
        "- **عدد التوقعات** الخاطئة\n",
        "- **أنواع** الأخطاء\n",
        "\n",
        "##  التابع الأساسي: `update_confusion`\n",
        "\n",
        "### مهمته:\n",
        "- استقبال **المصفوفة** (Confusion Matrix)\n",
        "- **توقعات النموذج** (predictions)\n",
        "- **الإجابات الصحيحة** (ground truth labels)\n",
        "- ثم يقوم **بتحديث القيم** في المصفوفة مباشرةً\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "05c109b2",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from typing import Sequence, Tuple, Dict\n",
        "\n",
        "NUM_CLASSES = 7\n",
        "IGNORE = -100\n",
        "\n",
        "def update_confusion(cm: np.ndarray, y_true: Sequence[int], y_pred: Sequence[int]) -> None:\n",
        "    \n",
        "    for yt, yp in zip(y_true, y_pred):\n",
        "        if yt == IGNORE:\n",
        "            continue\n",
        "        if yt < 0 or yt >= NUM_CLASSES:\n",
        "            continue\n",
        "        if yp < 0 or yp >= NUM_CLASSES:\n",
        "            continue\n",
        "        cm[yt, yp] += 1\n",
        "\n",
        "\n",
        "def f1_from_confusion(cm: np.ndarray, cls: int) -> float:\n",
        "    tp = cm[cls, cls]\n",
        "    fp = cm[:, cls].sum() - tp\n",
        "    fn = cm[cls, :].sum() - tp\n",
        "    denom = (2 * tp + fp + fn)\n",
        "    return float((2 * tp) / denom) if denom > 0 else 0.0\n",
        "\n",
        "\n",
        "def macro_f1_1_6_from_confusion(cm: np.ndarray) -> float:\n",
        "    f1s = [f1_from_confusion(cm, c) for c in range(1, 7)]\n",
        "    return float(np.mean(f1s))\n",
        "\n",
        "\n",
        "def binary_f1_from_confusion(cm: np.ndarray) -> float:\n",
        "    \"\"\"\n",
        "    حساب f1\n",
        "    اذا اردنا فقط توقع هل يوجد علامة ترقيم ام لا \n",
        "    \"\"\"\n",
        "    tp = cm[1:, 1:].sum()\n",
        "    fp = cm[0, 1:].sum()\n",
        "    fn = cm[1:, 0].sum()\n",
        "    denom = (2 * tp + fp + fn)\n",
        "    return float((2 * tp) / denom) if denom > 0 else 0.0\n",
        "\n",
        "\n",
        "def summarize_confusion(cm: np.ndarray) -> Dict:\n",
        "    per_class = {c: f1_from_confusion(cm, c) for c in range(1, 7)}\n",
        "    support = {c: int(cm[c, :].sum()) for c in range(1, 7)}\n",
        "    return {\n",
        "        \"macro_f1_1_6\": macro_f1_1_6_from_confusion(cm),\n",
        "        \"binary_f1_punct\": binary_f1_from_confusion(cm),\n",
        "        \"per_class_f1\": per_class,\n",
        "        \"support\": support,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1984aea7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[50/79] MacroF1=0.1434 BinF1=0.5886\n",
            "FINAL Macro-F1(1..6): 0.143\n",
            "FINAL Binary F1: 0.5834\n",
            "Support: {1: 14626987, 2: 1539716, 3: 555014, 4: 11708519, 5: 53822, 6: 731}\n",
            "Per-class F1: {1: 0.0, 2: 0.0, 3: 0.0, 4: 0.8513, 5: 0.0067, 6: 0.0}\n"
          ]
        }
      ],
      "source": [
        "cm = np.zeros((7, 7), dtype=np.int64)\n",
        "\n",
        "files = list(iter_cleaned_files(cleaned_dir=Config.cleaned_data_dir))\n",
        "\n",
        "for idx, file in enumerate(files, start=1):\n",
        "    words, labels = load_tokens_labels_from_file(file)\n",
        "    preds = predict_terminal(words)\n",
        "    update_confusion(cm, labels, preds)\n",
        "\n",
        "    if idx % 50 == 0:\n",
        "        s = summarize_confusion(cm)\n",
        "        print(f\"[{idx}/{len(files)}] MacroF1={s['macro_f1_1_6']:.4f} BinF1={s['binary_f1_punct']:.4f}\")\n",
        "\n",
        "final = summarize_confusion(cm)\n",
        "print(\"FINAL Macro-F1(1..6):\", round(final[\"macro_f1_1_6\"], 4))\n",
        "print(\"FINAL Binary F1:\", round(final[\"binary_f1_punct\"], 4))\n",
        "print(\"Support:\", final[\"support\"])\n",
        "print(\"Per-class F1:\", {k: round(v, 4) for k, v in final[\"per_class_f1\"].items()})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0cf2c6a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FINAL Macro-F1(1..6): 0.143\n",
            "FINAL Binary F1: 0.5834\n",
            "Support: {'،': 14626987, '؛': 1539716, ':': 555014, '.': 11708519, '؟': 53822, '!': 731}\n",
            "Per-class F1: {'،': 0.0, '؛': 0.0, ':': 0.0, '.': 0.8513, '؟': 0.0067, '!': 0.0}\n"
          ]
        }
      ],
      "source": [
        "print(\"FINAL Macro-F1(1..6):\", round(final[\"macro_f1_1_6\"], 4))\n",
        "print(\"FINAL Binary F1:\", round(final[\"binary_f1_punct\"], 4))\n",
        "print(\"Support:\", {ArabicPunctuationProcessor.CLASS_TO_PUNCTUATION[k]: v for k, v in final[\"support\"].items()})\n",
        "print(\"Per-class F1:\", {ArabicPunctuationProcessor.CLASS_TO_PUNCTUATION[k]: round(v, 4) for k, v in final[\"per_class_f1\"].items()})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1833ebf",
      "metadata": {},
      "source": [
        "### ملخص نتائج خطّ الأساس الاستدلالي (Heuristic Terminal Baseline)\n",
        "\n",
        "- **Macro-F1 (للفئات 1..6) = 0.143**  \n",
        "  هذا الرقم منخفض لأنه يقيس متوسط الأداء عبر جميع علامات الترقيم الست (، ؛ : . ؟ !). وبما أنّ النموذج الحالي يتنبأ عمليًا بالنقطة فقط عند نهاية السطر ويتجاهل بقية العلامات، فإن متوسط الـF1 ينخفض حتى لو كانت النقطة وحدها ممتازة.\n",
        "\n",
        "- **Binary F1 (ترقيم vs لا ترقيم) = 0.5834**  \n",
        "  هذه النتيجة متوسطة وتعني أنّ النموذج قادر نسبيًا على اكتشاف “وجود ترقيم” مقابل “لا يوجد ترقيم” خصوصًا عند نهايات الأسطر، لكنه يفشل في التقاط كثير من مواقع الترقيم داخل السطر (مثل الفواصل والنقطتين) مما يرفع الأخطاء (False Negatives).\n",
        "\n",
        "---\n",
        "\n",
        "### دعم الفئات (Support) — حجم البيانات الحقيقي لكل علامة\n",
        "- **، الفاصلة:** 14,626,987  \n",
        "- **؛ الفاصلة المنقوطة:** 1,539,716  \n",
        "- **: النقطتان:** 555,014  \n",
        "- **. النقطة:** 11,708,519  \n",
        "- **؟ علامة الاستفهام:** 53,822  \n",
        "- **! علامة التعجب:** 731  \n",
        "\n",
        "هذا يوضح أن البيانات كبيرة جدًا، وأن الفاصلة والنقطة هما الأكثر حضورًا، بينما `؟` وخصوصًا `!` نادرتان جدًا.\n",
        "\n",
        "---\n",
        "\n",
        "### الأداء لكل فئة (Per-class F1)\n",
        "- **. النقطة: 0.8513 (مرتفع جدًا)**  \n",
        "  السبب: الخطّ الاستدلالي يضع الترقيم عند نهاية السطر، وهذا يتطابق كثيرًا مع مواضع النقطة في نصوص الأخبار (الجمل غالبًا تنتهي مع `[LINE]`).\n",
        "\n",
        "- **؟ الاستفهام: 0.0067 (ضعيف جدًا)**  \n",
        "  رغم وجود مؤشرات استفهام، إلا أن النموذج يحدد الاستفهام فقط عند نهاية السطر، وغالبًا لا يلتقط أسئلة كثيرة أو يخطئ في أسطر غير استفهامية، ومع ندرة `؟` تصبح الـF1 حساسة جدًا لأي خطأ.\n",
        "\n",
        "- **، ؛ : ! كلها = 0.0**  \n",
        "  هذا متوقع لأن النموذج لا يتنبأ بهذه العلامات أصلًا (أي أن الاسترجاع Recall = 0)، وبالتالي تكون F1 = 0.\n",
        "\n",
        "---\n",
        "\n",
        "### الخلاصة العملية\n",
        "هذا الخطّ الأساسي **ليس نموذج ترقيم عام**؛ بل هو عمليًا **محدد لنهايات الجمل** ويبرع فقط في **التنبؤ بالنقطة** عند نهاية السطر. لذلك:\n",
        "- يحقق **F1 ممتاز للنقطة**،\n",
        "- لكنه **يفشل تمامًا** في علامات الترقيم داخل السطر (خصوصًا الفاصلة والنقطتين)،\n",
        "- ونتيجة ذلك يظهر **Macro-F1 منخفض** رغم أن جزءًا واحدًا من المهمة (النقطة) جيد جدًا.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f564ab19",
      "metadata": {},
      "source": [
        "## النموذج الثاني سيكون موديل خطي على مرحلتين\n",
        "\n",
        "- **المرحلة الأولى:** التنبؤ بوجود علامة ترقيم من عدمه.  \n",
        "- **المرحلة الثانية:** تحديد ماهية علامة الترقيم المتوقعة.  \n",
        "\n",
        "كما سنقوم ببناء الـ **features** اعتمادًا على الإحصائيات التي قمنا بحسابها.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "bccad3ec",
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, Iterable, Iterator, List, Optional, Sequence, Tuple\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.feature_extraction import FeatureHasher\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import f1_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78d7591e",
      "metadata": {},
      "source": [
        " ### **في الخلية التالية سنقوم باستخراج قاموس مزايا لكل كلمة**\n",
        " \n",
        "\n",
        "\n",
        "### 1 **ميزات الهوية والموقع**\n",
        "- **الهوية الأساسية**:  `w0=<التوكن نفسه>`\n",
        "- **النوع الشكلي**: `shape0=<نوع التوكن مثل كلمة، سطر او توكن مميز>`\n",
        "- **موقع في السطر**: `posbucket=<الموقع>`\n",
        "  - `POS_EARLY`: أول كلمتين في السطر\n",
        "  - `POS_MID`: من الكلمة 3 إلى 10\n",
        "  - `POS_LATE`: بعد الكلمة 10\n",
        "\n",
        "\n",
        "### 2 **ميزة تنبؤ النقاط**\n",
        "- **`next_is_LINE`**: تدل إذا كان التوكن التالي هو نهاية سطر (مفيد جدًا لتوقع علامات الترقيم النهائية)\n",
        "\n",
        "### 3 **ميزات سياق الكلمات**\n",
        "يتم استخراج سياق الكلمات بناءً على حجم النافذة المحدد:\n",
        "- **الكلمات السابقة**: `w-1=<الكلمة>`, `w-2=<الكلمة>`\n",
        "- **الكلمات اللاحقة**: `w+1=<الكلمة>`, `w+2=<الكلمة>`\n",
        "- **النوع الشكلي للسياق**: `shape-1=<النوع>`, `shape+1=<النوع>`\n",
        "\n",
        "### 4 **ميزات الكلمات المركبة (N-Grams)**\n",
        "- **Bigram السابقة**: `bg_prev=<الكلمة السابقة>_<الكلمة الحالية>`\n",
        "- **Bigram اللاحقة**: `bg_next=<الكلمة الحالية>_<الكلمة اللاحقة>`\n",
        "- **Trigram الوسط**: `tg_mid=<سابقة>_<حالية>_<لاحقة>` (إذا كان التوكن في الوسط)\n",
        "- **Trigram السابقة**: `tg_prev=<سابقة2>_<سابقة1>_<حالية>`\n",
        "\n",
        "\n",
        "### 5 **ميزات الحروف (Character N-Grams)**\n",
        "للتغلب على مشكلة الكلمات النادرة (hapax)، يتم استخراج n-grams على مستوى الحروف:\n",
        "- يتم تضمين التوكن بين علامتين `<` و `>`\n",
        "- يتم استخراج n-grams بأطوال من `char_ngram_min` إلى `char_ngram_max`\n",
        "- مثال: للكلمة \"الجلسة\" مع n=3 → `<الجلسة>` → `ch3=<ال`, `ch3=الـ`, `ch3=لجل`, إلخ.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "4f19fe04",
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class FeatureConfig:\n",
        "    window: int = 2                # نافذة السياق ±2\n",
        "    use_word_ngrams: bool = True   # ميزات bi/tri-gram على مستوى الكلمات\n",
        "    use_char_ngrams: bool = True   # ميزات n-gram على مستوى الحروف (مفيد جدًا مع hapax)\n",
        "    char_ngram_min: int = 3\n",
        "    char_ngram_max: int = 5\n",
        "    char_max_len: int = 24\n",
        "\n",
        "LINE_TOKEN = ArabicPunctuationProcessor.SPECIAL_TOKENS[\"LINE\"]\n",
        "class FeatureExtractor:\n",
        "    \"\"\"\n",
        "    مستخرج ميزات بسيط:\n",
        "    - unigram سياق ±window\n",
        "    - word bigram/trigram\n",
        "    - char n-grams (اختياري)\n",
        "    - ميزات بنيوية حول [LINE]\n",
        "    \"\"\"\n",
        "    def __init__(self, cfg: FeatureConfig):\n",
        "        self.cfg = cfg\n",
        "\n",
        "    @staticmethod\n",
        "    def _is_special(tok: str) -> bool:\n",
        "        return tok.startswith(\"[\") and tok.endswith(\"]\")\n",
        "\n",
        "    def _shape(self, tok: str) -> str:\n",
        "        \"\"\"ميزة بسيطة تصف نوع التوكن بدل الاعتماد فقط على الهوية.\"\"\"\n",
        "        if tok == LINE_TOKEN:\n",
        "            return \"LINE\"\n",
        "        if self._is_special(tok):\n",
        "            return \"SPECIAL\"\n",
        "        return \"WORD\"\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_line_positions(tokens: Sequence[str]) -> List[int]:\n",
        "        \"\"\"حساب موضع التوكن داخل السطر (يعاد للصفر بعد [LINE]).\"\"\"\n",
        "        pos = []\n",
        "        i = 0\n",
        "        for t in tokens:\n",
        "            if t == LINE_TOKEN:\n",
        "                pos.append(0)\n",
        "                i = 0\n",
        "            else:\n",
        "                pos.append(i)\n",
        "                i += 1\n",
        "        return pos\n",
        "\n",
        "    @staticmethod\n",
        "    def pos_bucket(p: int) -> str:\n",
        "        if p <= 2:\n",
        "            return \"POS_EARLY\"\n",
        "        if p <= 10:\n",
        "            return \"POS_MID\"\n",
        "        return \"POS_LATE\"\n",
        "\n",
        "    def _add_char_ngrams(self, feats: Dict[str, float], tok: str) -> None:\n",
        "        \"\"\"إضافة char n-grams لتقليل أثر الكلمات النادرة (hapax).\"\"\"\n",
        "        if not self.cfg.use_char_ngrams:\n",
        "            return\n",
        "        if self._is_special(tok):\n",
        "            return\n",
        "\n",
        "        t = tok[: self.cfg.char_max_len]\n",
        "        t = f\"<{t}>\"\n",
        "        for n in range(self.cfg.char_ngram_min, self.cfg.char_ngram_max + 1):\n",
        "            for j in range(0, len(t) - n + 1):\n",
        "                feats[f\"ch{n}={t[j:j+n]}\"] = 1.0\n",
        "\n",
        "    def make_features(self, tokens: Sequence[str], i: int, line_pos: Sequence[int]) -> Dict[str, float]:\n",
        "        \"\"\"بناء قاموس ميزات للتوكن i.\"\"\"\n",
        "        cfg = self.cfg\n",
        "        tok = tokens[i]\n",
        "        feats: Dict[str, float] = {}\n",
        "\n",
        "        # هوية التوكن ونوعه وموقعه داخل السطر\n",
        "        feats[f\"w0={tok}\"] = 1.0\n",
        "        feats[f\"shape0={self._shape(tok)}\"] = 1.0\n",
        "        feats[f\"posbucket={self.pos_bucket(line_pos[i])}\"] = 1.0\n",
        "\n",
        "        # هل التوكن التالي هو [LINE] (ميزة قوية للنقطة)\n",
        "        next_tok = tokens[i + 1] if (i + 1) < len(tokens) else None\n",
        "        feats[\"next_is_LINE\"] = 1.0 if (next_tok is None or next_tok == LINE_TOKEN) else 0.0\n",
        "\n",
        "        # unigram سياق ±window\n",
        "        for k in range(1, cfg.window + 1):\n",
        "            if i - k >= 0:\n",
        "                feats[f\"w-{k}={tokens[i-k]}\"] = 1.0\n",
        "                feats[f\"shape-{k}={self._shape(tokens[i-k])}\"] = 1.0\n",
        "            if i + k < len(tokens):\n",
        "                feats[f\"w+{k}={tokens[i+k]}\"] = 1.0\n",
        "                feats[f\"shape+{k}={self._shape(tokens[i+k])}\"] = 1.0\n",
        "\n",
        "        # word n-grams\n",
        "        if cfg.use_word_ngrams:\n",
        "            if i - 1 >= 0:\n",
        "                feats[f\"bg_prev={tokens[i-1]}_{tok}\"] = 1.0\n",
        "            if i + 1 < len(tokens):\n",
        "                feats[f\"bg_next={tok}_{tokens[i+1]}\"] = 1.0\n",
        "            if i - 1 >= 0 and i + 1 < len(tokens):\n",
        "                feats[f\"tg_mid={tokens[i-1]}_{tok}_{tokens[i+1]}\"] = 1.0\n",
        "            if i - 2 >= 0:\n",
        "                feats[f\"tg_prev={tokens[i-2]}_{tokens[i-1]}_{tok}\"] = 1.0\n",
        "\n",
        "        # char n-grams\n",
        "        self._add_char_ngrams(feats, tok)\n",
        "\n",
        "        return feats\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "b8e2d77c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "word: [LINE] , features:{'w0=[LINE]': 1.0, 'shape0=LINE': 1.0, 'posbucket=POS_EARLY': 1.0, 'next_is_LINE': 0.0, 'w+1=السلام': 1.0, 'shape+1=WORD': 1.0, 'w+2=عليكم': 1.0, 'shape+2=WORD': 1.0, 'w+3=ورحمة': 1.0, 'shape+3=WORD': 1.0, 'bg_next=[LINE]_السلام': 1.0}\n",
            "word: السلام , features:{'w0=السلام': 1.0, 'shape0=WORD': 1.0, 'posbucket=POS_EARLY': 1.0, 'next_is_LINE': 0.0, 'w-1=[LINE]': 1.0, 'shape-1=LINE': 1.0, 'w+1=عليكم': 1.0, 'shape+1=WORD': 1.0, 'w+2=ورحمة': 1.0, 'shape+2=WORD': 1.0, 'w+3=الله': 1.0, 'shape+3=WORD': 1.0, 'bg_prev=[LINE]_السلام': 1.0, 'bg_next=السلام_عليكم': 1.0, 'tg_mid=[LINE]_السلام_عليكم': 1.0, 'ch3=<ال': 1.0, 'ch3=الس': 1.0, 'ch3=لسل': 1.0, 'ch3=سلا': 1.0, 'ch3=لام': 1.0, 'ch3=ام>': 1.0, 'ch4=<الس': 1.0, 'ch4=السل': 1.0, 'ch4=لسلا': 1.0, 'ch4=سلام': 1.0, 'ch4=لام>': 1.0, 'ch5=<السل': 1.0, 'ch5=السلا': 1.0, 'ch5=لسلام': 1.0, 'ch5=سلام>': 1.0}\n",
            "word: عليكم , features:{'w0=عليكم': 1.0, 'shape0=WORD': 1.0, 'posbucket=POS_EARLY': 1.0, 'next_is_LINE': 0.0, 'w-1=السلام': 1.0, 'shape-1=WORD': 1.0, 'w+1=ورحمة': 1.0, 'shape+1=WORD': 1.0, 'w-2=[LINE]': 1.0, 'shape-2=LINE': 1.0, 'w+2=الله': 1.0, 'shape+2=WORD': 1.0, 'w+3=وبركاته': 1.0, 'shape+3=WORD': 1.0, 'bg_prev=السلام_عليكم': 1.0, 'bg_next=عليكم_ورحمة': 1.0, 'tg_mid=السلام_عليكم_ورحمة': 1.0, 'tg_prev=[LINE]_السلام_عليكم': 1.0, 'ch3=<عل': 1.0, 'ch3=علي': 1.0, 'ch3=ليك': 1.0, 'ch3=يكم': 1.0, 'ch3=كم>': 1.0, 'ch4=<علي': 1.0, 'ch4=عليك': 1.0, 'ch4=ليكم': 1.0, 'ch4=يكم>': 1.0, 'ch5=<عليك': 1.0, 'ch5=عليكم': 1.0, 'ch5=ليكم>': 1.0}\n",
            "word: ورحمة , features:{'w0=ورحمة': 1.0, 'shape0=WORD': 1.0, 'posbucket=POS_EARLY': 1.0, 'next_is_LINE': 0.0, 'w-1=عليكم': 1.0, 'shape-1=WORD': 1.0, 'w+1=الله': 1.0, 'shape+1=WORD': 1.0, 'w-2=السلام': 1.0, 'shape-2=WORD': 1.0, 'w+2=وبركاته': 1.0, 'shape+2=WORD': 1.0, 'w-3=[LINE]': 1.0, 'shape-3=LINE': 1.0, 'w+3=[LINE]': 1.0, 'shape+3=LINE': 1.0, 'bg_prev=عليكم_ورحمة': 1.0, 'bg_next=ورحمة_الله': 1.0, 'tg_mid=عليكم_ورحمة_الله': 1.0, 'tg_prev=السلام_عليكم_ورحمة': 1.0, 'ch3=<ور': 1.0, 'ch3=ورح': 1.0, 'ch3=رحم': 1.0, 'ch3=حمة': 1.0, 'ch3=مة>': 1.0, 'ch4=<ورح': 1.0, 'ch4=ورحم': 1.0, 'ch4=رحمة': 1.0, 'ch4=حمة>': 1.0, 'ch5=<ورحم': 1.0, 'ch5=ورحمة': 1.0, 'ch5=رحمة>': 1.0}\n",
            "word: الله , features:{'w0=الله': 1.0, 'shape0=WORD': 1.0, 'posbucket=POS_MID': 1.0, 'next_is_LINE': 0.0, 'w-1=ورحمة': 1.0, 'shape-1=WORD': 1.0, 'w+1=وبركاته': 1.0, 'shape+1=WORD': 1.0, 'w-2=عليكم': 1.0, 'shape-2=WORD': 1.0, 'w+2=[LINE]': 1.0, 'shape+2=LINE': 1.0, 'w-3=السلام': 1.0, 'shape-3=WORD': 1.0, 'w+3=في': 1.0, 'shape+3=WORD': 1.0, 'bg_prev=ورحمة_الله': 1.0, 'bg_next=الله_وبركاته': 1.0, 'tg_mid=ورحمة_الله_وبركاته': 1.0, 'tg_prev=عليكم_ورحمة_الله': 1.0, 'ch3=<ال': 1.0, 'ch3=الل': 1.0, 'ch3=لله': 1.0, 'ch3=له>': 1.0, 'ch4=<الل': 1.0, 'ch4=الله': 1.0, 'ch4=لله>': 1.0, 'ch5=<الله': 1.0, 'ch5=الله>': 1.0}\n",
            "word: وبركاته , features:{'w0=وبركاته': 1.0, 'shape0=WORD': 1.0, 'posbucket=POS_MID': 1.0, 'next_is_LINE': 1.0, 'w-1=الله': 1.0, 'shape-1=WORD': 1.0, 'w+1=[LINE]': 1.0, 'shape+1=LINE': 1.0, 'w-2=ورحمة': 1.0, 'shape-2=WORD': 1.0, 'w+2=في': 1.0, 'shape+2=WORD': 1.0, 'w-3=عليكم': 1.0, 'shape-3=WORD': 1.0, 'w+3=يوم': 1.0, 'shape+3=WORD': 1.0, 'bg_prev=الله_وبركاته': 1.0, 'bg_next=وبركاته_[LINE]': 1.0, 'tg_mid=الله_وبركاته_[LINE]': 1.0, 'tg_prev=ورحمة_الله_وبركاته': 1.0, 'ch3=<وب': 1.0, 'ch3=وبر': 1.0, 'ch3=برك': 1.0, 'ch3=ركا': 1.0, 'ch3=كات': 1.0, 'ch3=اته': 1.0, 'ch3=ته>': 1.0, 'ch4=<وبر': 1.0, 'ch4=وبرك': 1.0, 'ch4=بركا': 1.0, 'ch4=ركات': 1.0, 'ch4=كاته': 1.0, 'ch4=اته>': 1.0, 'ch5=<وبرك': 1.0, 'ch5=وبركا': 1.0, 'ch5=بركات': 1.0, 'ch5=ركاته': 1.0, 'ch5=كاته>': 1.0}\n",
            "word: [LINE] , features:{'w0=[LINE]': 1.0, 'shape0=LINE': 1.0, 'posbucket=POS_EARLY': 1.0, 'next_is_LINE': 0.0, 'w-1=وبركاته': 1.0, 'shape-1=WORD': 1.0, 'w+1=في': 1.0, 'shape+1=WORD': 1.0, 'w-2=الله': 1.0, 'shape-2=WORD': 1.0, 'w+2=يوم': 1.0, 'shape+2=WORD': 1.0, 'w-3=ورحمة': 1.0, 'shape-3=WORD': 1.0, 'w+3=[DATE]': 1.0, 'shape+3=SPECIAL': 1.0, 'bg_prev=وبركاته_[LINE]': 1.0, 'bg_next=[LINE]_في': 1.0, 'tg_mid=وبركاته_[LINE]_في': 1.0, 'tg_prev=الله_وبركاته_[LINE]': 1.0}\n",
            "word: في , features:{'w0=في': 1.0, 'shape0=WORD': 1.0, 'posbucket=POS_EARLY': 1.0, 'next_is_LINE': 0.0, 'w-1=[LINE]': 1.0, 'shape-1=LINE': 1.0, 'w+1=يوم': 1.0, 'shape+1=WORD': 1.0, 'w-2=وبركاته': 1.0, 'shape-2=WORD': 1.0, 'w+2=[DATE]': 1.0, 'shape+2=SPECIAL': 1.0, 'w-3=الله': 1.0, 'shape-3=WORD': 1.0, 'w+3=أعلنت': 1.0, 'shape+3=WORD': 1.0, 'bg_prev=[LINE]_في': 1.0, 'bg_next=في_يوم': 1.0, 'tg_mid=[LINE]_في_يوم': 1.0, 'tg_prev=وبركاته_[LINE]_في': 1.0, 'ch3=<في': 1.0, 'ch3=في>': 1.0, 'ch4=<في>': 1.0}\n",
            "word: يوم , features:{'w0=يوم': 1.0, 'shape0=WORD': 1.0, 'posbucket=POS_EARLY': 1.0, 'next_is_LINE': 0.0, 'w-1=في': 1.0, 'shape-1=WORD': 1.0, 'w+1=[DATE]': 1.0, 'shape+1=SPECIAL': 1.0, 'w-2=[LINE]': 1.0, 'shape-2=LINE': 1.0, 'w+2=أعلنت': 1.0, 'shape+2=WORD': 1.0, 'w-3=وبركاته': 1.0, 'shape-3=WORD': 1.0, 'w+3=الشركة': 1.0, 'shape+3=WORD': 1.0, 'bg_prev=في_يوم': 1.0, 'bg_next=يوم_[DATE]': 1.0, 'tg_mid=في_يوم_[DATE]': 1.0, 'tg_prev=[LINE]_في_يوم': 1.0, 'ch3=<يو': 1.0, 'ch3=يوم': 1.0, 'ch3=وم>': 1.0, 'ch4=<يوم': 1.0, 'ch4=يوم>': 1.0, 'ch5=<يوم>': 1.0}\n",
            "word: [DATE] , features:{'w0=[DATE]': 1.0, 'shape0=SPECIAL': 1.0, 'posbucket=POS_EARLY': 1.0, 'next_is_LINE': 0.0, 'w-1=يوم': 1.0, 'shape-1=WORD': 1.0, 'w+1=أعلنت': 1.0, 'shape+1=WORD': 1.0, 'w-2=في': 1.0, 'shape-2=WORD': 1.0, 'w+2=الشركة': 1.0, 'shape+2=WORD': 1.0, 'w-3=[LINE]': 1.0, 'shape-3=LINE': 1.0, 'w+3=سنصدر': 1.0, 'shape+3=WORD': 1.0, 'bg_prev=يوم_[DATE]': 1.0, 'bg_next=[DATE]_أعلنت': 1.0, 'tg_mid=يوم_[DATE]_أعلنت': 1.0, 'tg_prev=في_يوم_[DATE]': 1.0}\n"
          ]
        }
      ],
      "source": [
        "cfg = FeatureConfig(\n",
        "    window=3,\n",
        "    use_word_ngrams=True,\n",
        "    use_char_ngrams=True,\n",
        "    char_ngram_min=3,\n",
        "    char_ngram_max=5,\n",
        "    char_max_len=24,\n",
        ")\n",
        "\n",
        "extractor = FeatureExtractor(cfg)\n",
        "words, labels = ArabicPunctuationProcessor().split_tokens_labels(text2, preprocess=True)\n",
        "for i in range(0 , 10):\n",
        "    print(f\"word: {words[i]} , features:{extractor.make_features(words, i, extractor.compute_line_positions(words))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab0b1de3",
      "metadata": {},
      "source": [
        "#  نموذج التصنيف ثنائي المراحل\n",
        "\n",
        "يقوم النموذج بتوقع علامات الترقيم في خطوتين متتاليتين:\n",
        "\n",
        "### المرحلة الأولى: **التصنيف الثنائي**\n",
        "- **المهمة**: تحديد هل يحتوي الموضع على علامة ترقيم أم لا\n",
        "- **المخرجات**: `0` = لا يوجد ترقيم، `1` = يوجد ترقيم\n",
        "\n",
        "### المرحلة الثانية: **التصنيف المتعدد**\n",
        "- **المهمة**: تحديد نوع علامة الترقيم (فقط للمواضع التي تنبأت المرحلة الأولى بوجود ترقيم فيها)\n",
        "- **المخرجات**: الأرقام `1` إلى `6` تمثل أنواع علامات الترقيم المختلفة"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "b8a085d0",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class TwoStageLinearWithNgrams:\n",
        "    \"\"\"\n",
        "    موديل خط أساس:\n",
        "    - المرحلة 1: هل يوجد ترقيم؟ (binary)\n",
        "    - المرحلة 2: ما نوع الترقيم؟ (multiclass 1..6) فقط عندما المرحلة 1 تقول \"يوجد ترقيم\"\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        extractor: FeatureExtractor,\n",
        "        n_features: int = 2**20,\n",
        "        alpha: float = 1e-5,\n",
        "        random_state: int = 13,\n",
        "    ):\n",
        "        self.extractor = extractor\n",
        "        self.hasher = FeatureHasher(n_features=n_features, input_type=\"dict\", alternate_sign=False)\n",
        "\n",
        "        # المرحلة الأولى: تصنيف ثنائي\n",
        "        self.clf_bin = SGDClassifier(\n",
        "            loss=\"log_loss\",\n",
        "            alpha=alpha,\n",
        "            random_state=random_state,\n",
        "        )\n",
        "\n",
        "        # المرحلة الثانية: تصنيف متعدد للفئات 1..6\n",
        "        self.clf_mc = SGDClassifier(\n",
        "            loss=\"log_loss\",\n",
        "            alpha=alpha,\n",
        "            random_state=random_state,\n",
        "        )\n",
        "\n",
        "        self._bin_init = False\n",
        "        self._mc_init = False\n",
        "\n",
        "        # عتبة قرار المرحلة الأولى: إذا P(punct) >= tau => نرسل للمرحلة الثانية\n",
        "        self.tau = 0.5\n",
        "\n",
        "    def partial_fit_file(self, tokens: Sequence[str], labels: Sequence[int], batch_size: int = 4096) -> None:\n",
        "        \"\"\"تدريب تزايدي على ملف واحد.\"\"\"\n",
        "        line_pos = self.extractor.compute_line_positions(tokens)\n",
        "\n",
        "        Xb, yb = [], []\n",
        "        Xm, ym = [], []\n",
        "\n",
        "        def flush():\n",
        "            nonlocal Xb, yb, Xm, ym\n",
        "\n",
        "            if Xb:\n",
        "                Xh = self.hasher.transform(Xb)\n",
        "                y = np.asarray(yb, dtype=np.int64)\n",
        "                if not self._bin_init:\n",
        "                    self.clf_bin.partial_fit(Xh, y, classes=np.array([0, 1], dtype=np.int64))\n",
        "                    self._bin_init = True\n",
        "                else:\n",
        "                    self.clf_bin.partial_fit(Xh, y)\n",
        "                Xb, yb = [], []\n",
        "\n",
        "            if Xm:\n",
        "                Xh = self.hasher.transform(Xm)\n",
        "                y = np.asarray(ym, dtype=np.int64)\n",
        "                if not self._mc_init:\n",
        "                    self.clf_mc.partial_fit(Xh, y, classes=np.array([1, 2, 3, 4, 5, 6], dtype=np.int64))\n",
        "                    self._mc_init = True\n",
        "                else:\n",
        "                    self.clf_mc.partial_fit(Xh, y)\n",
        "                Xm, ym = [], []\n",
        "\n",
        "        for i, (tok, y) in enumerate(zip(tokens, labels)):\n",
        "            if y == -100:\n",
        "                continue  # تجاهل [LINE]\n",
        "\n",
        "            feats = self.extractor.make_features(tokens, i, line_pos)\n",
        "\n",
        "            # بيانات المرحلة الأولى (binary)\n",
        "            Xb.append(feats)\n",
        "            yb.append(1 if y != 0 else 0)\n",
        "\n",
        "            # بيانات المرحلة الثانية (multiclass) فقط عندما يوجد ترقيم فعلاً\n",
        "            if y != 0:\n",
        "                Xm.append(feats)\n",
        "                ym.append(int(y))\n",
        "\n",
        "            if len(Xb) >= batch_size:\n",
        "                flush()\n",
        "\n",
        "        flush()\n",
        "\n",
        "    def predict(self, tokens: Sequence[str]) -> List[int]:\n",
        "        \"\"\"تنبؤ على تسلسل توكنز واحد.\"\"\"\n",
        "        if not (self._bin_init and self._mc_init):\n",
        "            raise RuntimeError(\"الموديل غير مدرّب بعد.\")\n",
        "\n",
        "        line_pos = self.extractor.compute_line_positions(tokens)\n",
        "        X = [self.extractor.make_features(tokens, i, line_pos) for i in range(len(tokens))]\n",
        "        Xh = self.hasher.transform(X)\n",
        "\n",
        "        # المرحلة الأولى باستخدام احتمالات + عتبة tau\n",
        "        proba = self.clf_bin.predict_proba(Xh)  # [N,2]\n",
        "        punct_mask = proba[:, 1] >= self.tau\n",
        "\n",
        "        y_pred = np.zeros(len(tokens), dtype=np.int64)\n",
        "\n",
        "        # محاذاة [LINE]\n",
        "        for i, t in enumerate(tokens):\n",
        "            if t == LINE_TOKEN:\n",
        "                y_pred[i] = -100\n",
        "                punct_mask[i] = False\n",
        "\n",
        "        # تطبيق المرحلة الثانية فقط على المواضع التي قالت المرحلة الأولى أنها تحتاج ترقيم\n",
        "        idx = np.where(punct_mask)[0].tolist()\n",
        "        if idx:\n",
        "            y_mc = self.clf_mc.predict(Xh[idx])\n",
        "            for ii, cls in zip(idx, y_mc):\n",
        "                y_pred[ii] = int(cls)\n",
        "\n",
        "        return y_pred.tolist()\n",
        "\n",
        "    \n",
        "    def predict_streaming(self, tokens: Sequence[str], *, batch_size: int = 50000) -> List[int]:\n",
        "        \"\"\" \n",
        "           \n",
        "             الفرق بين هذا التابع والتابع السابق اننا هنا لا نقوم باستخرام الميزات لكل التوكنز في وقت واحد\n",
        "             عوضا عن ذلك، فاننا نقوم باستخراج المزايا لعدد معين من التوكنز\n",
        "             وبعد ذلك نتوقع على هذه الدفعة\n",
        "             ثم نعيد العملية\n",
        "             \n",
        "             الفرق الجوهري في الاداء ان تابع الهاش للنموذج يستهلك الكثير من الذاكرة \n",
        "             عند تمرير عدد كبير من التوكنز دفعة واحدة\n",
        "             \n",
        "        \"\"\"\n",
        "        if not (self._bin_init and self._mc_init):\n",
        "            raise RuntimeError(\"Model is not trained yet.\")\n",
        "\n",
        "        n = len(tokens)\n",
        "        y_pred = np.zeros(n, dtype=np.int64)\n",
        "\n",
        "        for i, t in enumerate(tokens):\n",
        "            if t == LINE_TOKEN:\n",
        "                y_pred[i] = -100\n",
        "\n",
        "        line_pos = self.extractor.compute_line_positions(tokens)\n",
        "\n",
        "        start = 0\n",
        "        while start < n:\n",
        "            end = min(n, start + batch_size)\n",
        "\n",
        "            X = []\n",
        "            idx_map = []\n",
        "\n",
        "            for i in range(start, end):\n",
        "                if tokens[i] == LINE_TOKEN:\n",
        "                    continue\n",
        "                X.append(self.extractor.make_features(tokens, i, line_pos))\n",
        "                idx_map.append(i)\n",
        "\n",
        "            if X:\n",
        "                Xh = self.hasher.transform(X)\n",
        "\n",
        "                # stage 1\n",
        "                proba = self.clf_bin.predict_proba(Xh)[:, 1]\n",
        "                punct_mask = proba >= self.tau\n",
        "                # stage 2 only where punct_mask True\n",
        "                if np.any(punct_mask):\n",
        "                    idx2 = np.where(punct_mask)[0]\n",
        "                    y2 = self.clf_mc.predict(Xh[idx2])\n",
        "                    for local_j, cls in zip(idx2.tolist(), y2.tolist()):\n",
        "                        y_pred[idx_map[local_j]] = int(cls)\n",
        "\n",
        "            start = end\n",
        "\n",
        "        return y_pred.tolist()\n",
        "\n",
        "    def tune_tau(self, dev_files: Sequence[str], taus: Sequence[float], objective: str = \"macro\") -> float:\n",
        "        \"\"\"\n",
        "        ضبط tau على مجموعة التطوير:\n",
        "        objective:\n",
        "          - 'macro': تعظيم Macro-F1 للفئات 1..6\n",
        "          - 'binary': تعظيم F1 الثنائي (ترقيم/لا ترقيم)\n",
        "        \"\"\"\n",
        "        best_tau = self.tau\n",
        "        best_score = -1.0\n",
        "\n",
        "        cached = []\n",
        "        for fp in dev_files:\n",
        "            toks, y = load_tokens_labels_from_file(fp)\n",
        "            cached.append((toks, y))\n",
        "\n",
        "        for tau in taus:\n",
        "            self.tau = float(tau)\n",
        "            cm = np.zeros((7, 7), dtype=np.int64)\n",
        "            for toks, y in cached:\n",
        "                yp = self.predict(toks)\n",
        "                update_confusion(cm, y, yp)\n",
        "            s = summarize_confusion(cm)\n",
        "            score = s[\"macro_f1_1_6\"] if objective == \"macro\" else s[\"binary_f1\"]\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_tau = tau\n",
        "            print(f\"tau={tau:.3f} => {objective} F1={score:.4f}\")\n",
        "\n",
        "        self.tau = float(best_tau)\n",
        "        return self.tau\n",
        "    \n",
        "    def tune_tau_optimized(\n",
        "        self,\n",
        "        dev_files: Sequence[str],\n",
        "        taus: Sequence[float],\n",
        "        objective: str = \"macro\",\n",
        "        *,\n",
        "        batch_size: int = 4096,\n",
        "        max_tokens_per_file: Optional[int] = None,\n",
        "    ) -> float:\n",
        "\n",
        "        \"\"\"\n",
        "        التحسين في هذا التابع هو نفس التحسين الذي قمت به في تابع التوقع\n",
        "        \"\"\"\n",
        "        def _predict_streaming(tokens: Sequence[str]) -> List[int]:\n",
        "            if not (self._bin_init and self._mc_init):\n",
        "                raise RuntimeError(\"الموديل غير مدرّب بعد.\")\n",
        "\n",
        "            n = len(tokens)\n",
        "            y_pred = np.zeros(n, dtype=np.int64)\n",
        "\n",
        "            # ضع -100 في أماكن [LINE] مبكراً\n",
        "            for i, t in enumerate(tokens):\n",
        "                if t == LINE_TOKEN:\n",
        "                    y_pred[i] = -100\n",
        "\n",
        "            line_pos = self.extractor.compute_line_positions(tokens)\n",
        "\n",
        "            start = 0\n",
        "            while start < n:\n",
        "                end = min(n, start + batch_size)\n",
        "\n",
        "                X: List[Dict[str, float]] = []\n",
        "                idx_map: List[int] = []\n",
        "\n",
        "                for i in range(start, end):\n",
        "                    if tokens[i] == LINE_TOKEN:\n",
        "                        continue\n",
        "                    X.append(self.extractor.make_features(tokens, i, line_pos))\n",
        "                    idx_map.append(i)\n",
        "\n",
        "                if X:\n",
        "                    Xh = self.hasher.transform(X)\n",
        "\n",
        "                    # المرحلة الأولى: P(punct)\n",
        "                    proba_punct = self.clf_bin.predict_proba(Xh)[:, 1]\n",
        "                    punct_mask = proba_punct >= self.tau\n",
        "\n",
        "                    if np.any(punct_mask):\n",
        "                        idx2 = np.where(punct_mask)[0]\n",
        "                        y2 = self.clf_mc.predict(Xh[idx2])\n",
        "                        for local_j, cls in zip(idx2.tolist(), y2.tolist()):\n",
        "                            y_pred[idx_map[local_j]] = int(cls)\n",
        "\n",
        "                start = end\n",
        "\n",
        "            return y_pred.tolist()\n",
        "\n",
        "        best_tau = float(self.tau)\n",
        "        best_score = -1.0\n",
        "\n",
        "        for tau in taus:\n",
        "            self.tau = float(tau)\n",
        "            cm = np.zeros((7, 7), dtype=np.int64)\n",
        "\n",
        "            for fp in dev_files:\n",
        "                toks, y = load_tokens_labels_from_file(fp, max_tokens=max_tokens_per_file)\n",
        "                yp = _predict_streaming(toks)\n",
        "                update_confusion(cm, y, yp)\n",
        "\n",
        "            s = summarize_confusion(cm)\n",
        "            score = s[\"macro_f1_1_6\"] if objective == \"macro\" else s[\"binary_f1_punct\"]\n",
        "\n",
        "            if score > best_score:\n",
        "                best_score = float(score)\n",
        "            best_tau = float(tau)\n",
        "            print(f\"tau={tau:.3f} => {objective} F1={score:.4f}\")\n",
        "\n",
        "        self.tau = float(best_tau)\n",
        "        return self.tau\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84fb7cbe",
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_dev_split(paths: Sequence[str], dev_ratio: float = 0.1, seed: int = 13) -> Tuple[List[str], List[str]]:\n",
        "    paths = list(paths)\n",
        "    rnd = random.Random(seed)\n",
        "    rnd.shuffle(paths)\n",
        "    n_dev = max(1, int(len(paths) * dev_ratio))\n",
        "    return paths[n_dev:], paths[:n_dev]\n",
        "\n",
        "\n",
        "def train_and_evaluate_two_stage(\n",
        "    cleaned_dir: str,\n",
        "    dev_ratio: float = 0.1,\n",
        "    n_features: int = 2**20,\n",
        "    window: int = 2,\n",
        "    alpha: float = 1e-5,\n",
        "    tune_tau: bool = True,\n",
        "    checkpoint_dir: str = \"linear_model_checkpoints\",  \n",
        "    checkpoint_frequency: int = 10,  \n",
        ") -> TwoStageLinearWithNgrams:\n",
        "\n",
        "    import os\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "    \n",
        "    files = list(iter_cleaned_files(cleaned_dir))\n",
        "    train_files, dev_files = train_dev_split(files, dev_ratio=dev_ratio)\n",
        "\n",
        "    cfg = FeatureConfig(window=window, use_word_ngrams=True, use_char_ngrams=True)\n",
        "    extractor = FeatureExtractor(cfg)\n",
        "    model = TwoStageLinearWithNgrams(extractor, n_features=n_features, alpha=alpha)\n",
        "\n",
        "    # تدريب تزايدي على ملفات التدريب\n",
        "    for k, fp in enumerate(train_files, start=1):\n",
        "        toks, y = load_tokens_labels_from_file(fp)\n",
        "        model.partial_fit_file(toks, y)\n",
        "        print(f\"تم تدريب {k}/{len(train_files)} ملف\")\n",
        "        \n",
        "        if k % checkpoint_frequency == 0:\n",
        "            checkpoint_path = os.path.join(checkpoint_dir, f\"model_checkpoint_{k}.pkl\")\n",
        "            \n",
        "            import pickle\n",
        "            with open(checkpoint_path, 'wb') as f:\n",
        "                pickle.dump(model, f)\n",
        "            print(f\"✓ تم حفظ النموذج في: {checkpoint_path}\")\n",
        "            \n",
        "            metadata = {\n",
        "                'files_trained': k,\n",
        "                'total_files': len(train_files),\n",
        "                'checkpoint_number': k // checkpoint_frequency,\n",
        "                'timestamp': time.time() if 'time' in locals() else None,\n",
        "            }\n",
        "            metadata_path = os.path.join(checkpoint_dir, f\"metadata_{k}.pkl\")\n",
        "            with open(metadata_path, 'wb') as f:\n",
        "                pickle.dump(metadata, f)\n",
        "    \n",
        "    final_checkpoint = os.path.join(checkpoint_dir, \"model_final.pkl\")\n",
        "    import pickle\n",
        "    with open(final_checkpoint, 'wb') as f:\n",
        "        pickle.dump(model, f)\n",
        "    print(f\"✓ تم حفظ النموذج النهائي في: {final_checkpoint}\")\n",
        "\n",
        "\n",
        "    if tune_tau:\n",
        "        taus = [0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50,\n",
        "                0.55, 0.60, 0.65, 0.70, 0.75, 0.80]\n",
        "        best_tau = model.tune_tau(dev_files, taus=taus, objective=\"macro\")\n",
        "        print(f\"أفضل tau على dev = {best_tau:.2f}\")\n",
        "        \n",
        "        tuned_checkpoint = os.path.join(checkpoint_dir, \"model_tuned.pkl\")\n",
        "        with open(tuned_checkpoint, 'wb') as f:\n",
        "            pickle.dump(model, f)\n",
        "        print(f\"✓ تم حفظ النموذج بعد ضبط tau في: {tuned_checkpoint}\")\n",
        "\n",
        "    # تقييم على dev باستخدام مصفوفة الالتباس\n",
        "    cm = np.zeros((7, 7), dtype=np.int64)\n",
        "    for fp in dev_files:\n",
        "        toks, y = load_tokens_labels_from_file(fp)\n",
        "        yp = model.predict(toks)\n",
        "        update_confusion(cm, y, yp)\n",
        "\n",
        "    summary = summarize_confusion(cm)\n",
        "    print(\"نتائج dev:\")\n",
        "    print(\"Macro-F1(1..6):\", round(summary[\"macro_f1_1_6\"], 4))\n",
        "    print(\"Binary F1:\", round(summary[\"binary_f1\"], 4))\n",
        "    print(\"Support:\", summary[\"support\"])\n",
        "    print(\"Per-class F1:\", {k: round(v, 4) for k, v in summary[\"per_class_f1\"].items()})\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba7cc515",
      "metadata": {},
      "source": [
        "### هنا فقط توابع مساعدة لتحميل وحفظ النموذج"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "c441ddd7",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import joblib\n",
        "\n",
        "def save_model(model: TwoStageLinearWithNgrams, path: str) -> None:\n",
        "    \"\"\"حفظ الموديل (المرحلتين + الهاشر + الإعدادات).\"\"\"\n",
        "    payload = {\n",
        "        \"tau\": model.tau,\n",
        "        \"hasher\": model.hasher,\n",
        "        \"clf_bin\": model.clf_bin,\n",
        "        \"clf_mc\": model.clf_mc,\n",
        "        \"bin_init\": model._bin_init,\n",
        "        \"mc_init\": model._mc_init,\n",
        "        \"feature_cfg\": model.extractor.cfg,\n",
        "    }\n",
        "    joblib.dump(payload, path)\n",
        "\n",
        "def load_model(path: str) -> TwoStageLinearWithNgrams:\n",
        "    obj = joblib.load(path)\n",
        "\n",
        "    # الحالة 1: الملف يحتوي الموديل مباشرة\n",
        "    if isinstance(obj, TwoStageLinearWithNgrams):\n",
        "        return obj\n",
        "\n",
        "    # الحالة 2: الملف يحتوي payload dict\n",
        "    if isinstance(obj, dict):\n",
        "        cfg = obj[\"feature_cfg\"]\n",
        "        extractor = FeatureExtractor(cfg)\n",
        "        model = TwoStageLinearWithNgrams(extractor, n_features=obj[\"hasher\"].n_features)\n",
        "        model.tau = obj[\"tau\"]\n",
        "        model.hasher = obj[\"hasher\"]\n",
        "        model.clf_bin = obj[\"clf_bin\"]\n",
        "        model.clf_mc = obj[\"clf_mc\"]\n",
        "        model._bin_init = obj[\"bin_init\"]\n",
        "        model._mc_init = obj[\"mc_init\"]\n",
        "        return model\n",
        "\n",
        "    raise TypeError(f\"Unsupported checkpoint type: {type(obj)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "9c4a8219",
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[58], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate_two_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcleaned_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcleaned_data_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdev_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m save_model(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtwo_stage_linear_ngrams.joblib\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[1;32mIn[56], line 34\u001b[0m, in \u001b[0;36mtrain_and_evaluate_two_stage\u001b[1;34m(cleaned_dir, dev_ratio, n_features, window, alpha, tune_tau, checkpoint_dir, checkpoint_frequency)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, fp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_files, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     33\u001b[0m     toks, y \u001b[38;5;241m=\u001b[39m load_sequence_from_file(fp)\n\u001b[1;32m---> 34\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mتم تدريب \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_files)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ملف\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m%\u001b[39m checkpoint_frequency \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
            "Cell \u001b[1;32mIn[21], line 83\u001b[0m, in \u001b[0;36mTwoStageLinearWithNgrams.partial_fit_file\u001b[1;34m(self, tokens, labels, batch_size)\u001b[0m\n\u001b[0;32m     80\u001b[0m         ym\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mint\u001b[39m(y))\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(Xb) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m batch_size:\n\u001b[1;32m---> 83\u001b[0m         \u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m flush()\n",
            "Cell \u001b[1;32mIn[21], line 64\u001b[0m, in \u001b[0;36mTwoStageLinearWithNgrams.partial_fit_file.<locals>.flush\u001b[1;34m()\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mc_init \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclf_mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m Xm, ym \u001b[38;5;241m=\u001b[39m [], []\n",
            "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:893\u001b[0m, in \u001b[0;36mBaseSGDClassifier.partial_fit\u001b[1;34m(self, X, y, classes, sample_weight)\u001b[0m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    882\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_weight \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not supported for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpartial_fit. In order to use \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m weights,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    890\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight)\n\u001b[0;32m    891\u001b[0m         )\n\u001b[1;32m--> 893\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_partial_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    896\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    898\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    899\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    901\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    903\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    904\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintercept_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    905\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:649\u001b[0m, in \u001b[0;36mBaseSGDClassifier._partial_fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, max_iter, classes, sample_weight, coef_init, intercept_init)\u001b[0m\n\u001b[0;32m    647\u001b[0m \u001b[38;5;66;03m# delegate to concrete training procedure\u001b[39;00m\n\u001b[0;32m    648\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 649\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_multiclass\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[43m        \u001b[49m\u001b[43mC\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    657\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m n_classes \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    659\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_binary(\n\u001b[0;32m    660\u001b[0m         X,\n\u001b[0;32m    661\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    666\u001b[0m         max_iter\u001b[38;5;241m=\u001b[39mmax_iter,\n\u001b[0;32m    667\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:804\u001b[0m, in \u001b[0;36mBaseSGDClassifier._fit_multiclass\u001b[1;34m(self, X, y, alpha, C, learning_rate, sample_weight, max_iter)\u001b[0m\n\u001b[0;32m    802\u001b[0m random_state \u001b[38;5;241m=\u001b[39m check_random_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n\u001b[0;32m    803\u001b[0m seeds \u001b[38;5;241m=\u001b[39m random_state\u001b[38;5;241m.\u001b[39mrandint(MAX_INT, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_))\n\u001b[1;32m--> 804\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequire\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msharedmem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m    806\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    807\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfit_binary\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    808\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    809\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    810\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    811\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    812\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    813\u001b[0m \u001b[43m        \u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    814\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    815\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    816\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_expanded_class_weight\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    817\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    818\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    819\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    820\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    821\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mseeds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[38;5;66;03m# take the maximum of n_iter_ over every binary fit\u001b[39;00m\n\u001b[0;32m    826\u001b[0m n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
            "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
            "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:463\u001b[0m, in \u001b[0;36mfit_binary\u001b[1;34m(est, i, X, y, alpha, C, learning_rate, max_iter, pos_weight, neg_weight, sample_weight, validation_mask, random_state)\u001b[0m\n\u001b[0;32m    460\u001b[0m tol \u001b[38;5;241m=\u001b[39m est\u001b[38;5;241m.\u001b[39mtol \u001b[38;5;28;01mif\u001b[39;00m est\u001b[38;5;241m.\u001b[39mtol \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf\n\u001b[0;32m    462\u001b[0m _plain_sgd \u001b[38;5;241m=\u001b[39m _get_plain_sgd_function(input_dtype\u001b[38;5;241m=\u001b[39mcoef\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m--> 463\u001b[0m coef, intercept, average_coef, average_intercept, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[43m_plain_sgd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[43maverage_coef\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[43maverage_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m    \u001b[49m\u001b[43mest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_loss_function_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpenalty_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    471\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43mest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_score_cb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter_no_change\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpos_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mneg_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[43mest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meta0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpower_t\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintercept_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m est\u001b[38;5;241m.\u001b[39maverage:\n\u001b[0;32m    496\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(est\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model = train_and_evaluate_two_stage(cleaned_dir=Config.cleaned_data_dir, dev_ratio=0.1)\n",
        "save_model(model, \"two_stage_linear_ngrams.joblib\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df836965",
      "metadata": {},
      "source": [
        "ملاحظة: قمت بتشغيل الخلية السابقة عن طريق الخطا وذهب الايرور الدال على امتلاء الرام :')\n",
        "\n",
        "\n",
        " هنا نلاحظ ان النموذج لم يقم بعملية تحسين للتاو (τ) نظراً لامتلاء الرام (RAM).\n",
        "\n",
        "\n",
        "يعود ذلك الى انني قمت بتحميل جميع ملفات `dev` للرام، كما موضح هنا:\n",
        "\n",
        "```python\n",
        "cached = []\n",
        "for fp in dev_files:\n",
        "    toks, y = load_tokens_labels_from_file(fp)\n",
        "    cached.append((toks, y))\n",
        "```\n",
        "\n",
        "ولذلك سوف أقوم بكتابة تابع جديد يقوم بنفس العمليات، ولكن سوف نقوم بعمل streaming للداتا عوضاً عن تحميلها جميعاً الى الذاكرة."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "59bd45d7",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_files, dev_files = train_dev_split(list(iter_cleaned_files(cleaned_dir=Config.cleaned_data_dir)), dev_ratio=0.1)\n",
        "model = load_model(\"linear_model_checkpoints/model_final.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9d9341d",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "taus = [0.20, 0.50, 0.80]\n",
        "best_tau = model.tune_tau_optimized(dev_files, taus=taus, objective=\"macro\")\n",
        "# best_tau = model.tune_tau(dev_files, taus=taus, objective=\"macro\")\n",
        "\n",
        "print(f\"أفضل tau على dev = {best_tau:.2f}\")\n",
        "\n",
        "\n",
        "\n",
        "import pickle \n",
        "tuned_checkpoint = os.path.join(\"linear_model_checkpoints\", \"model_tuned.pkl\")\n",
        "with open(tuned_checkpoint, 'wb') as f:\n",
        "    pickle.dump(model, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4ac98a3",
      "metadata": {},
      "source": [
        "### اختبار الموديل على ال dev set "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0640e923",
      "metadata": {},
      "source": [
        "هنا سنقوم بكتابعة تابعين اساسيان وهما:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afe40fe9",
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_linear_files(\n",
        "    model,\n",
        "    files: Sequence[str],\n",
        "    max_tokens_per_file: Optional[int] = None,\n",
        "    pred_batch_size: int = 50000,   \n",
        "    \n",
        "):\n",
        "    cm = np.zeros((7, 7), dtype=np.int64)\n",
        "\n",
        "    for fp in files:\n",
        "        toks, y = load_tokens_labels_from_file(fp, max_tokens=max_tokens_per_file)\n",
        "\n",
        "        yp = model.predict_streaming(toks, batch_size=pred_batch_size)\n",
        "\n",
        "        update_confusion(cm, y, yp)\n",
        "\n",
        "    summary = summarize_confusion(cm)\n",
        "    out = {\"confusion\": cm, \"summary\": summary}\n",
        "\n",
        "    print(\"=== Evaluation ===\")\n",
        "    print(\"Macro-F1(1..6):\", round(summary[\"macro_f1_1_6\"], 4))\n",
        "    print(\"Binary F1:\", round(summary.get(\"binary_f1\", summary.get(\"binary_f1_punct\", float(\"nan\"))), 4))\n",
        "    print(\"Support:\", summary.get(\"support\"))\n",
        "    print(\"Per-class F1:\", {k: round(v, 4) for k, v in summary.get(\"per_class_f1\", {}).items()})\n",
        "\n",
        "    return out\n",
        "\n",
        "def evaluate_liner_text(\n",
        "    model,\n",
        "    text\n",
        "):\n",
        "    cm = np.zeros((7, 7), dtype=np.int64)\n",
        "    preprocessor = ArabicPunctuationProcessor(remove_diacritics=True)\n",
        "     \n",
        "    text = preprocessor.preprocess_text(text)\n",
        "\n",
        "    toks, y = split_tokens_labels_from_tokens(text.split())\n",
        "    \n",
        "   \n",
        "    \n",
        "    print(f\"Evaluating on text with {len(toks)} tokens.\")\n",
        "    \n",
        "    print(f\"Tokens: {toks}\")\n",
        "    print(f\"Y = {y}\") \n",
        "    \n",
        "    yp = model.predict(toks)\n",
        "    print(f\"Prediction: {yp}\")\n",
        "    new_text = \"\" \n",
        "    \n",
        "    for token, punc in zip(toks, yp):\n",
        "        if token == ArabicPunctuationProcessor.SPECIAL_TOKENS[\"LINE\"]:\n",
        "            new_text += \"\\n\"\n",
        "            continue\n",
        "        new_text += token\n",
        "        punc_char = ArabicPunctuationProcessor.CLASS_TO_PUNCTUATION.get(punc, \"\")\n",
        "        if punc_char:\n",
        "            new_text += punc_char\n",
        "        new_text += \" \"\n",
        "        \n",
        "    print(f\"New Text: {new_text}\")\n",
        "    update_confusion(cm, y, yp)\n",
        "    \n",
        "    summary = summarize_confusion(cm)\n",
        "    out = {\n",
        "        \"confusion\": cm,\n",
        "        \"summary\": summary,\n",
        "    }\n",
        "\n",
        "    \n",
        "    print(\"=== Evaluation ===\")\n",
        "    print(\"Macro-F1(1..6):\", round(summary[\"macro_f1_1_6\"], 4))\n",
        "    print(\"Binary F1:\", round(summary.get(\"binary_f1\", summary.get(\"binary_f1_punct\", float(\"nan\"))), 4))\n",
        "    print(\"Support:\", summary.get(\"support\"))\n",
        "    print(\"Per-class F1:\", {ArabicPunctuationProcessor.CLASS_TO_PUNCTUATION.get(k): round(v, 4) for k, v in summary.get(\"per_class_f1\", {}).items()})\n",
        "\n",
        "    return new_text, out    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "ccc0659c",
      "metadata": {},
      "outputs": [],
      "source": [
        "linear_model = load_model(\"linear_model_checkpoints/model_final.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce3cbf5c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Evaluation ===\n",
            "Macro-F1(1..6): 0.3945\n",
            "Binary F1: 0.7184\n",
            "Support: {1: 1260516, 2: 127869, 3: 53679, 4: 1044643, 5: 4263, 6: 87}\n",
            "Per-class F1: {1: 0.3971, 2: 0.4792, 3: 0.4891, 4: 0.999, 5: 0.0028, 6: 0.0}\n",
            "{'confusion': array([[24438036,   130354,     4219,     1843,        0,        0,\n",
            "               0],\n",
            "       [  910782,   348431,      976,      327,        0,        0,\n",
            "               0],\n",
            "       [   77943,     7789,    42061,       75,        0,        1,\n",
            "               0],\n",
            "       [   27512,     7828,      235,    18104,        0,        0,\n",
            "               0],\n",
            "       [       0,        0,        0,        0,  1044643,        0,\n",
            "               0],\n",
            "       [    1985,       76,      190,        4,     2002,        6,\n",
            "               0],\n",
            "       [      80,        5,        0,        0,        2,        0,\n",
            "               0]]), 'summary': {'macro_f1_1_6': 0.39453359158987666, 'binary_f1_punct': 0.7183771243940581, 'per_class_f1': {1: 0.3970725909245532, 2: 0.4791911136428368, 3: 0.4890858007348174, 4: 0.999041739787404, 5: 0.002810304449648712, 6: 0.0}, 'support': {1: 1260516, 2: 127869, 3: 53679, 4: 1044643, 5: 4263, 6: 87}}}\n"
          ]
        }
      ],
      "source": [
        "out = evaluate_linear_files(linear_model, dev_files)\n",
        "\n",
        "print(out)\n",
        "# text = \"\"\n",
        "# out = evaluate_liner_text(linear_model, text)\n",
        "# dev_files[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "d5986285",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Evaluation ===\n",
            "Macro-F1(1..6): 0.4075\n",
            "Binary F1: 0.7275\n",
            "Support: {1: 184918, 2: 18795, 3: 10926, 4: 148909, 5: 943, 6: 2}\n",
            "Per-class F1: {1: 0.4269, 2: 0.4995, 3: 0.5199, 4: 0.9984, 5: 0.0, 6: 0.0}\n",
            "{'confusion': array([[3471930,   18967,     592,     257,       0,       0,       0],\n",
            "       [ 128466,   56225,     174,      53,       0,       0,       0],\n",
            "       [  11058,    1192,    6537,       8,       0,       0,       0],\n",
            "       [   4832,    2101,      43,    3950,       0,       0,       0],\n",
            "       [      0,       0,       0,       0,  148909,       0,       0],\n",
            "       [    429,       8,      34,       0,     472,       0,       0],\n",
            "       [      2,       0,       0,       0,       0,       0,       0]]), 'summary': {'macro_f1_1_6': 0.40745722974898246, 'binary_f1_punct': 0.7274852445717408, 'per_class_f1': {1: 0.42689940814924204, 2: 0.4994842406876791, 3: 0.5199420824009477, 4: 0.998417647256026, 5: 0.0, 6: 0.0}, 'support': {1: 184918, 2: 18795, 3: 10926, 4: 148909, 5: 943, 6: 2}}}\n"
          ]
        }
      ],
      "source": [
        "out2 = evaluate_linear_files(model=linear_model, files=[dev_files[0]])\n",
        "print(out2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83a5f698",
      "metadata": {},
      "source": [
        "كما هو موضح، فان النموذج شبه دائما يقوم بتوقع النقطة بشكل صحيح ولكن يفشل بتوقع اي شيء اخر"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "362f2864",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating on text with 43 tokens.\n",
            "Tokens: ['[LINE]', 'قالت', 'المعيدة', 'زينة', 'هذا', 'المشروع', 'يحتاج', 'إلى', 'ثلاث', 'أشخاص', 'فقمت', 'انا', 'بحماقتي', 'بأختياره', 'ظنا', 'مني', 'انه', 'بسيط', 'جدا', '[LINE]', 'أعتقد', 'في', 'رأيي', 'انه', 'كان', 'يجب', 'أن', 'اعلم', 'ان', 'المعيدة', 'طالما', 'قالت', 'انه', 'يحتاج', 'إلى', 'ثلاث', 'أشخاص', 'فهو', 'مشروع', 'صعب', 'وليس', 'سهل', '[LINE]']\n",
            "Y = [-100, 0, 0, 3, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 4, -100, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, -100]\n",
            "Prediction: [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, -100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, -100]\n",
            "New Text: \n",
            "قالت المعيدة زينة هذا المشروع يحتاج إلى ثلاث أشخاص فقمت انا بحماقتي بأختياره ظنا مني انه بسيط جدا. \n",
            "أعتقد في رأيي انه كان يجب أن اعلم ان المعيدة طالما قالت انه يحتاج إلى ثلاث أشخاص فهو مشروع صعب وليس سهل. \n",
            "\n",
            "=== Evaluation ===\n",
            "Macro-F1(1..6): 0.1111\n",
            "Binary F1: 0.25\n",
            "Support: {1: 4, 2: 0, 3: 1, 4: 1, 5: 0, 6: 0}\n",
            "Per-class F1: {'،': 0.0, '؛': 0.0, ':': 0.0, '.': 0.6667, '؟': 0.0, '!': 0.0}\n",
            "النص بعد الترقيم: \n",
            "قالت المعيدة زينة هذا المشروع يحتاج إلى ثلاث أشخاص فقمت انا بحماقتي بأختياره ظنا مني انه بسيط جدا. \n",
            "أعتقد في رأيي انه كان يجب أن اعلم ان المعيدة طالما قالت انه يحتاج إلى ثلاث أشخاص فهو مشروع صعب وليس سهل. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "text = \"\"\"\n",
        "قالت المعيدة زينة: هذا المشروع يحتاج إلى ثلاث أشخاص، فقمت انا بحماقتي بأختياره ظنا مني انه بسيط جدا.\n",
        "أعتقد، في رأيي، انه كان يجب أن اعلم ان المعيدة طالما قالت انه يحتاج إلى ثلاث أشخاص، فهو مشروع صعب وليس سهل \n",
        "\"\"\"\n",
        "\n",
        "new_text, output_of_my_text = evaluate_liner_text(linear_model, text)\n",
        "print(\"النص بعد الترقيم:\", new_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ada9551",
      "metadata": {},
      "source": [
        "# بناء نموذج BiLSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76133167",
      "metadata": {},
      "source": [
        "### هذا القسم من النوتبوك تم تشغيله على كولاب لتسريع عملية التدريب"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "056b5979",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import json\n",
        "import math\n",
        "import random\n",
        "from collections import Counter, deque\n",
        "from typing import Dict, Iterator, List, Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import IterableDataset, DataLoader\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)\n",
        "\n",
        "LINE_TOKEN = ArabicPunctuationProcessor.SPECIAL_TOKENS[\"LINE\"]\n",
        "\n",
        "PAD = \"[PAD]\"\n",
        "UNK = \"[UNK]\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2d7b039",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b45bb3f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "Torch: 2.9.0+cu126\n",
            "torch.version.cuda: 12.6\n",
            "cuda is built: True\n",
            "cuda available: True\n",
            "device count: 1\n",
            "Fri Dec 26 09:30:02 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8             11W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "import torch, sys\n",
        "\n",
        "print(\"Python:\", sys.version)\n",
        "print(\"Torch:\", torch.__version__)\n",
        "print(\"torch.version.cuda:\", torch.version.cuda)\n",
        "print(\"cuda is built:\", torch.backends.cuda.is_built())\n",
        "print(\"cuda available:\", torch.cuda.is_available())\n",
        "print(\"device count:\", torch.cuda.device_count())\n",
        "\n",
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8307e6f6",
      "metadata": {},
      "source": [
        " هذا التابع يقوم فقط ببناء لغة للموديل يستند عليها\n",
        "ونظرا لضخامة  الداتا يمكننا تحديد عدد الكلمات التي نريد مسحها، وحجم ال vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb796ff3",
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_word_vocab_streaming(\n",
        "    cleaned_dir: str,\n",
        "    vocab_size: int,\n",
        "    min_freq: int = 1,\n",
        "    max_word_tokens_scan: int = 20_000_000,\n",
        "    seed: int = 13,\n",
        "    max_files: Optional[int] = None,\n",
        "    prune_every: int = 2_000_000,\n",
        ") -> Dict[str, int]:\n",
        "\n",
        "    rnd = random.Random(seed)\n",
        "    files = list(iter_cleaned_files(cleaned_dir))\n",
        "    rnd.shuffle(files)\n",
        "    if max_files is not None:\n",
        "        files = files[: min(int(max_files), len(files))]\n",
        "\n",
        "    cnt = Counter()\n",
        "    seen = 0\n",
        "\n",
        "    punct_set = ArabicPunctuationProcessor.PUNCT_SET \n",
        "\n",
        "    for fp in files:\n",
        "        for tok in iter_tokens_from_file(fp):\n",
        "            if tok in punct_set:\n",
        "                continue  \n",
        "            cnt[tok] += 1\n",
        "            seen += 1\n",
        "\n",
        "            if prune_every and (seen % prune_every == 0):\n",
        "                cnt = Counter(dict(cnt.most_common(vocab_size * 4)))\n",
        "\n",
        "            if max_word_tokens_scan is not None and seen >= max_word_tokens_scan:\n",
        "                break\n",
        "        if max_word_tokens_scan is not None and seen >= max_word_tokens_scan:\n",
        "            break\n",
        "\n",
        "    items = [(w, c) for w, c in cnt.items() if c >= min_freq]\n",
        "    items.sort(key=lambda x: x[1], reverse=True)\n",
        "    items = items[: vocab_size]\n",
        "\n",
        "    word2id = {PAD: 0, UNK: 1}\n",
        "    for w, _c in items:\n",
        "        if w in word2id:\n",
        "            continue\n",
        "        word2id[w] = len(word2id)\n",
        "\n",
        "    return word2id\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "600d861e",
      "metadata": {},
      "source": [
        "الكلاس التالي سيقوم بتوليد ستريم للداتا\n",
        "\n",
        "تعود فائدته باننا لا نقوم بتحميل الداتا كلها للرام\n",
        "\n",
        "بالإضافة لسهولة استخدامها \n",
        "\n",
        "سنقوم بتحديد من خلاله حجم النافذة المراد استخدامها \n",
        "\n",
        "ومقدار ال overlap بين كل سيكونس"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e53f844",
      "metadata": {},
      "outputs": [],
      "source": [
        "class PunctWindowIterableDataset(IterableDataset):\n",
        "\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        files: List[str],\n",
        "        word2id: Dict[str, int],\n",
        "        seq_len: int,\n",
        "        stride: int,\n",
        "        shuffle_files: bool = True,\n",
        "        seed: int = 13,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.files = list(files)\n",
        "        self.word2id = word2id\n",
        "        self.seq_len = int(seq_len)\n",
        "        self.stride = int(stride)\n",
        "        self.shuffle_files = bool(shuffle_files)\n",
        "        self.seed = int(seed)\n",
        "        self.pad_id = word2id[PAD]\n",
        "        self.unk_id = word2id[UNK]\n",
        "\n",
        "    def _word_to_id(self, w: str) -> int:\n",
        "        return self.word2id.get(w, self.unk_id)\n",
        "\n",
        "    def __iter__(self):\n",
        "        files = list(self.files)\n",
        "        if self.shuffle_files:\n",
        "            rnd = random.Random(self.seed + int(time.time()) % 10_000)\n",
        "            rnd.shuffle(files)\n",
        "\n",
        "        buf_x: deque = deque()\n",
        "        buf_y: deque = deque()\n",
        "\n",
        "        for fp in files:\n",
        "            toks = list(iter_tokens_from_file(fp))\n",
        "            words, labels = split_tokens_labels_from_tokens(toks)\n",
        "\n",
        "            for w, y in zip(words, labels):\n",
        "                buf_x.append(self._word_to_id(w))\n",
        "                buf_y.append(int(y))\n",
        "\n",
        "                if len(buf_x) >= self.seq_len:\n",
        "                    x = list(buf_x)[: self.seq_len]\n",
        "                    yv = list(buf_y)[: self.seq_len]\n",
        "\n",
        "                    yield (\n",
        "                        torch.tensor(x, dtype=torch.long),\n",
        "                        torch.tensor(yv, dtype=torch.long),\n",
        "                    )\n",
        "\n",
        "                    # إزالة stride\n",
        "                    for _ in range(self.stride):\n",
        "                        if buf_x:\n",
        "                            buf_x.popleft()\n",
        "                            buf_y.popleft()\n",
        "\n",
        "        # flush الباقي (إن وجد)\n",
        "        if len(buf_x) > 0:\n",
        "            x = list(buf_x)\n",
        "            yv = list(buf_y)\n",
        "\n",
        "            if len(x) < self.seq_len:\n",
        "                pad_n = self.seq_len - len(x)\n",
        "                x.extend([self.pad_id] * pad_n)\n",
        "                yv.extend([-100] * pad_n)\n",
        "\n",
        "            yield (\n",
        "                torch.tensor(x[: self.seq_len], dtype=torch.long),\n",
        "                torch.tensor(yv[: self.seq_len], dtype=torch.long),\n",
        "            )\n",
        "\n",
        "\n",
        "def make_loaders_from_files(\n",
        "    train_files: List[str],\n",
        "    dev_files: List[str],\n",
        "    word2id: Dict[str, int],\n",
        "    cfg: TrainConfig,\n",
        ") -> Tuple[DataLoader, DataLoader]:\n",
        "    train_ds = PunctWindowIterableDataset(\n",
        "        train_files, word2id,\n",
        "        seq_len=cfg.seq_len, stride=cfg.stride,\n",
        "        shuffle_files=True, seed=cfg.seed\n",
        "    )\n",
        "    dev_ds = PunctWindowIterableDataset(\n",
        "        dev_files, word2id,\n",
        "        seq_len=cfg.seq_len, stride=cfg.stride,\n",
        "        shuffle_files=False, seed=cfg.seed\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_ds,\n",
        "        batch_size=cfg.batch_size,\n",
        "        num_workers=cfg.num_workers,\n",
        "        pin_memory=cfg.pin_memory,\n",
        "    )\n",
        "    dev_loader = DataLoader(\n",
        "        dev_ds,\n",
        "        batch_size=cfg.batch_size,\n",
        "        num_workers=cfg.num_workers,\n",
        "        pin_memory=cfg.pin_memory,\n",
        "    )\n",
        "    return train_loader, dev_loader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "245abf91",
      "metadata": {},
      "outputs": [],
      "source": [
        "class BiLSTMTagger(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size: int,\n",
        "        emb_dim: int,\n",
        "        hidden_size: int,\n",
        "        num_layers: int,\n",
        "        dropout: float,\n",
        "        num_classes: int,\n",
        "        pad_id: int,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_id)\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=emb_dim,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=True,\n",
        "            dropout=dropout if num_layers > 1 else 0.0,\n",
        "        )\n",
        "\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        e = self.emb(x)              \n",
        "        out, _ = self.lstm(e)           \n",
        "        out = self.drop(out)\n",
        "        logits = self.fc(out)           \n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41a61733",
      "metadata": {},
      "source": [
        "### FocalLoss\n",
        "\n",
        "هذا الكلاس يوفّر **دالة خسارة مخصّصة** لتدريب نماذج التصنيف في الحالات التي تعاني من **عدم توازن بين الفئات** (بعض الفئات كثيرة جدًا وأخرى نادرة).\n",
        "\n",
        "\n",
        "- يقلّل تأثير الأمثلة السهلة التي يتنبأ بها النموذج بثقة عالية.\n",
        "- يركّز أكثر على الأخطاء والأمثلة الصعبة.\n",
        "- يدعم تجاهل القيم غير المهمة (مثل التوكنز الخاصة) أثناء التدريب.\n",
        "\n",
        "- يستقبل **تنبؤات النموذج (logits)** و **التصنيفات الحقيقية (targets)**.\n",
        "- يتجاهل أي عنصر موسوم بالقيمة `-100` ولا يدخله في الحساب.\n",
        "- يحسب الخسارة فقط للفئة الصحيحة لكل مثال.\n",
        "- يخفّض وزن الأمثلة التي يتنبأ بها النموذج بسهولة.\n",
        "- يضاعف وزن الفئات النادرة باستخدام أوزان **Alpha** (إن وُجدت).\n",
        "- في النهاية:\n",
        "  - إمّا يأخذ **متوسط الخسارة**،\n",
        "  - أو **مجموعها** حسب الإعداد.\n",
        "\n",
        "يساعد هذا الأسلوب النموذج على:\n",
        "- تعلّم الفئات النادرة بشكل أفضل،\n",
        "- تقليل هيمنة الفئات الشائعة جدًا،\n",
        "- تحسين جودة التنبؤ في البيانات غير المتوازنة.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80e9604f",
      "metadata": {},
      "outputs": [],
      "source": [
        "class FocalLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Focal Loss للـmulti-class مع ignore_index=-100\n",
        "    alpha: Tensor [C] أو None\n",
        "    gamma: float\n",
        "    \"\"\"\n",
        "    def __init__(self, alpha: Optional[torch.Tensor], gamma: float = 2.0, ignore_index: int = -100, reduction: str = \"mean\"):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = float(gamma)\n",
        "        self.ignore_index = int(ignore_index)\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
        "        # logits: [N,C], targets: [N]\n",
        "        mask = targets != self.ignore_index\n",
        "        if mask.sum() == 0:\n",
        "            return logits.sum() * 0.0\n",
        "\n",
        "        logits = logits[mask]\n",
        "        targets = targets[mask]\n",
        "\n",
        "        log_probs = torch.log_softmax(logits, dim=-1)         # [M,C]\n",
        "        probs = torch.exp(log_probs)                          # [M,C]\n",
        "\n",
        "        idx = torch.arange(targets.size(0), device=targets.device)\n",
        "        pt = probs[idx, targets]                              # [M]\n",
        "        log_pt = log_probs[idx, targets]                      # [M]\n",
        "\n",
        "        if self.alpha is not None:\n",
        "            at = self.alpha[targets]                          # [M]\n",
        "        else:\n",
        "            at = 1.0\n",
        "\n",
        "        loss = -at * ((1.0 - pt) ** self.gamma) * log_pt\n",
        "\n",
        "        if self.reduction == \"mean\":\n",
        "            return loss.mean()\n",
        "        if self.reduction == \"sum\":\n",
        "            return loss.sum()\n",
        "        return loss\n",
        "\n",
        "\n",
        "def estimate_class_counts_from_dev(dev_loader: DataLoader, max_batches: int = 200) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    يحسب توزيع الفئات 0..6 من dev بشكل تقريبي (لتوليد alpha).\n",
        "    \"\"\"\n",
        "    counts = np.zeros(7, dtype=np.int64)\n",
        "    seen = 0\n",
        "\n",
        "    for xb, yb in dev_loader:\n",
        "        y = yb.view(-1).numpy()\n",
        "        y = y[y != -100]\n",
        "        if y.size > 0:\n",
        "            bc = np.bincount(y, minlength=7)\n",
        "            counts += bc\n",
        "        seen += 1\n",
        "        if seen >= max_batches:\n",
        "            break\n",
        "\n",
        "    return counts\n",
        "\n",
        "\n",
        "def compute_alpha_for_focal(counts: np.ndarray, alpha_pow: float = 0.5) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    alpha_c ∝ (1 / (count_c + eps))^alpha_pow ثم نطبعها بحيث max=1 تقريبًا.\n",
        "    \"\"\"\n",
        "    eps = 1.0\n",
        "    inv = 1.0 / (counts.astype(np.float64) + eps)\n",
        "    a = inv ** float(alpha_pow)\n",
        "\n",
        "    # لا نجعلها ضخمة جدًا\n",
        "    a = a / (a.max() + 1e-12)\n",
        "    return torch.tensor(a, dtype=torch.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48dea170",
      "metadata": {},
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def evaluate_bilstm(model: nn.Module, dev_loader: DataLoader, device: str, max_batches: int = 200) -> Dict[str, float]:\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    cm = np.zeros((7, 7), dtype=np.int64)\n",
        "\n",
        "    seen = 0\n",
        "    for xb, yb in dev_loader:\n",
        "        xb = xb.to(device, non_blocking=True)\n",
        "        yb = yb.to(device, non_blocking=True)\n",
        "\n",
        "        logits = model(xb)                  # [B,T,7]\n",
        "        yp = torch.argmax(logits, dim=-1)   # [B,T]\n",
        "\n",
        "        # flatten\n",
        "        yt = yb.view(-1).detach().cpu().numpy()\n",
        "        yp = yp.view(-1).detach().cpu().numpy()\n",
        "\n",
        "        # تحديث مصفوفة الالتباس باستخدام تابعك\n",
        "        update_confusion(cm, yt, yp)\n",
        "\n",
        "        seen += 1\n",
        "        if seen >= max_batches:\n",
        "            break\n",
        "    \n",
        "    s = summarize_confusion(cm)\n",
        "    out = {\n",
        "        \"macro_f1_1_6\": float(s[\"macro_f1_1_6\"]),\n",
        "        \"binary_f1_punct\": float(s[\"binary_f1_punct\"]),\n",
        "    }\n",
        "    # per-class f1 للفئات 1..6\n",
        "    for c in range(1, 7):\n",
        "        out[f\"f1_class_{c}\"] = float(s[\"per_class_f1\"][c])\n",
        "    if was_training:\n",
        "        model.train()\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ded01ff6",
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_ckpt(path: str, model: nn.Module, optim: torch.optim.Optimizer,\n",
        "              scaler: Optional[torch.cuda.amp.GradScaler],\n",
        "              epoch: int, global_step: int,\n",
        "              word2id: Dict[str, int], cfg: TrainConfig) -> None:\n",
        "    obj = {\n",
        "        \"model\": model.state_dict(),\n",
        "        \"optim\": optim.state_dict(),\n",
        "        \"scaler\": scaler.state_dict() if (scaler is not None and scaler.is_enabled()) else None,\n",
        "        \"epoch\": int(epoch),\n",
        "        \"global_step\": int(global_step),\n",
        "        \"word2id\": word2id,\n",
        "        \"train_cfg\": cfg.__dict__,\n",
        "    }\n",
        "    torch.save(obj, path)\n",
        "\n",
        "\n",
        "def load_ckpt(path: str, device: str):\n",
        "    return torch.load(path, map_location=device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40722483",
      "metadata": {},
      "source": [
        "الخلية التالية سوف تحوي فقط تابع مساعد لطباعة المدة المتوقعة للتنفيذ \n",
        "\n",
        "وتابع لحلقلة تدريب الموديل "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb2368d6",
      "metadata": {},
      "outputs": [],
      "source": [
        "def _estimate_steps_per_epoch_quick(\n",
        "    train_files: List[str],\n",
        "    seq_len: int,\n",
        "    stride: int,\n",
        "    batch_size: int,\n",
        "    sample_files: int = 3,\n",
        ") -> int:\n",
        "    \"\"\"\n",
        "    تقدير سريع للـsteps/epoch عبر قياس عدد الكلمات في عدد قليل من الملفات ثم إسقاط المتوسط.\n",
        "    \"\"\"\n",
        "    sample = train_files[: min(sample_files, len(train_files))]\n",
        "    if not sample:\n",
        "        return 1\n",
        "\n",
        "    word_counts = []\n",
        "    punct_set = ArabicPunctuationProcessor.PUNCT_SET\n",
        "\n",
        "    for fp in sample:\n",
        "        n_words = 0\n",
        "        for tok in iter_tokens_from_file(fp):\n",
        "            if tok in punct_set:\n",
        "                continue\n",
        "            n_words += 1\n",
        "        word_counts.append(n_words)\n",
        "\n",
        "    avg_words = float(np.mean(word_counts))\n",
        "    total_words_est = avg_words * len(train_files)\n",
        "\n",
        "    if total_words_est <= 0:\n",
        "        return 1\n",
        "\n",
        "    # عدد النوافذ التقريبي\n",
        "    if total_words_est <= seq_len:\n",
        "        total_windows = 1\n",
        "    else:\n",
        "        total_windows = 1 + int((total_words_est - seq_len) // stride)\n",
        "\n",
        "    steps = int(math.ceil(total_windows / max(1, batch_size)))\n",
        "    return max(1, steps)\n",
        "\n",
        "\n",
        "def train_bilstm_focal(\n",
        "    cleaned_dir: str,\n",
        "    cfg: TrainConfig,\n",
        "    out_dir: str = \"./checkpoints_bilstm\",\n",
        "    ckpt_latest_name: str = \"bilstm_latest.pt\",\n",
        "    max_files: Optional[int] = None,  # مهم لاختبار سريع (مثلاً 10 ملفات)\n",
        "    dev_files_count: Optional[int] = None,  # إن لم يُحدد نستخدم cfg.dev_files\n",
        "    vocab_scan_words: int = 20_000_000,\n",
        "    use_existing_vocab_path: bool = True,\n",
        "):\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    ckpt_latest_path = os.path.join(out_dir, ckpt_latest_name)\n",
        "\n",
        "    # 1) الملفات\n",
        "    files = list(iter_cleaned_files(cleaned_dir))\n",
        "    if not files:\n",
        "        raise FileNotFoundError(f\"لا توجد ملفات في {cleaned_dir}\")\n",
        "\n",
        "    rnd = random.Random(cfg.seed)\n",
        "    rnd.shuffle(files)\n",
        "\n",
        "    if max_files is not None:\n",
        "        files = files[: min(int(max_files), len(files))]\n",
        "\n",
        "    if dev_files_count is None:\n",
        "        dev_files_count = int(cfg.dev_files)\n",
        "\n",
        "    dev_files = files[: min(dev_files_count, len(files))]\n",
        "    train_files = files[min(dev_files_count, len(files)) :]\n",
        "\n",
        "    print(f\"Files: total={len(files)} train={len(train_files)} dev={len(dev_files)}\")\n",
        "\n",
        "    # 2) vocab: تحميل إن وجد أو بناء\n",
        "    word2id = None\n",
        "    start_epoch = 0\n",
        "    global_step = 0\n",
        "\n",
        "    # resume من latest إن وجد\n",
        "    if os.path.exists(ckpt_latest_path):\n",
        "        ckpt = load_ckpt(ckpt_latest_path, device=device)\n",
        "        word2id = ckpt[\"word2id\"]\n",
        "        start_epoch = int(ckpt[\"epoch\"])\n",
        "        global_step = int(ckpt[\"global_step\"])\n",
        "        print(f\"Resuming from {ckpt_latest_path} | epoch={start_epoch} step={global_step}\")\n",
        "\n",
        "    if word2id is None and use_existing_vocab_path and getattr(cfg, \"vocab_path\", None) and os.path.exists(cfg.vocab_path):\n",
        "        with open(cfg.vocab_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            word2id = json.load(f)\n",
        "        print(\"Loaded vocab from:\", cfg.vocab_path, \"| size:\", len(word2id))\n",
        "\n",
        "    if word2id is None:\n",
        "        print(\"Building vocab (streaming) ...\")\n",
        "        word2id = build_word_vocab_streaming(\n",
        "            cleaned_dir=cleaned_dir,\n",
        "            vocab_size=int(cfg.vocab_size),\n",
        "            min_freq=int(cfg.min_token_freq),\n",
        "            max_word_tokens_scan=vocab_scan_words,\n",
        "            seed=cfg.seed,\n",
        "            max_files=max_files,  # نفس ملفات الاختبار إن كانت محددة\n",
        "        )\n",
        "        print(\"Vocab size:\", len(word2id))\n",
        "\n",
        "        # حفظ vocab اختياريًا\n",
        "        if getattr(cfg, \"vocab_path\", None):\n",
        "            with open(cfg.vocab_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                json.dump(word2id, f, ensure_ascii=False)\n",
        "            print(\"Saved vocab to:\", cfg.vocab_path)\n",
        "\n",
        "    pad_id = word2id[PAD]\n",
        "\n",
        "    # 3) loaders\n",
        "    train_loader, dev_loader = make_loaders_from_files(train_files, dev_files, word2id, cfg)\n",
        "\n",
        "    # 4) تقدير alpha للفوكال من dev\n",
        "    counts = estimate_class_counts_from_dev(dev_loader, max_batches=200)\n",
        "    alpha = compute_alpha_for_focal(counts, alpha_pow=0.5).to(device)\n",
        "    print(\"Dev counts sample:\", counts)\n",
        "    print(\"Focal alpha:\", alpha.detach().cpu().numpy())\n",
        "\n",
        "    # 5) model/optim/loss/scaler\n",
        "    model = BiLSTMTagger(\n",
        "        vocab_size=len(word2id),\n",
        "        emb_dim=int(cfg.emb_dim),\n",
        "        hidden_size=int(cfg.hidden_size),\n",
        "        num_layers=int(cfg.num_layers),\n",
        "        dropout=float(cfg.dropout),\n",
        "        num_classes=7,\n",
        "        pad_id=pad_id,\n",
        "    ).to(device)\n",
        "\n",
        "    optim = torch.optim.AdamW(model.parameters(), lr=float(cfg.lr), weight_decay=float(cfg.weight_decay))\n",
        "    criterion = FocalLoss(alpha=alpha, gamma=2.0, ignore_index=-100, reduction=\"mean\")\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=(bool(cfg.amp) and device == \"cuda\"))\n",
        "\n",
        "    # تحميل حالة الاستكمال\n",
        "    if os.path.exists(ckpt_latest_path):\n",
        "        model.load_state_dict(ckpt[\"model\"])\n",
        "        optim.load_state_dict(ckpt[\"optim\"])\n",
        "        if ckpt.get(\"scaler\") is not None and scaler.is_enabled():\n",
        "            scaler.load_state_dict(ckpt[\"scaler\"])\n",
        "\n",
        "    # 6) تقدير steps/epoch لعرض ETA\n",
        "    est_steps_epoch = _estimate_steps_per_epoch_quick(\n",
        "        train_files=train_files,\n",
        "        seq_len=int(cfg.seq_len),\n",
        "        stride=int(cfg.stride),\n",
        "        batch_size=int(cfg.batch_size),\n",
        "        sample_files=min(3, len(train_files)),\n",
        "    )\n",
        "    print(\"Estimated steps/epoch:\", est_steps_epoch)\n",
        "\n",
        "    # 7) تدريب\n",
        "    model.train()\n",
        "    for epoch in range(start_epoch, int(cfg.epochs)):\n",
        "        t0 = time.time()\n",
        "        running_loss = 0.0\n",
        "        steps_in_epoch = 0\n",
        "        loss_ema = None\n",
        "        step_time_ema = None\n",
        "\n",
        "        for xb, yb in train_loader:\n",
        "            step_start = time.time()\n",
        "\n",
        "            xb = xb.to(device, non_blocking=True)\n",
        "            yb = yb.to(device, non_blocking=True)\n",
        "\n",
        "            optim.zero_grad(set_to_none=True)\n",
        "\n",
        "            with torch.cuda.amp.autocast(enabled=(bool(cfg.amp) and device == \"cuda\")):\n",
        "                logits = model(xb)  # [B,T,7]\n",
        "                loss = criterion(logits.view(-1, 7), yb.view(-1))\n",
        "\n",
        "            if scaler.is_enabled():\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.unscale_(optim)\n",
        "                nn.utils.clip_grad_norm_(model.parameters(), float(cfg.max_grad_norm))\n",
        "                scaler.step(optim)\n",
        "                scaler.update()\n",
        "            else:\n",
        "                loss.backward()\n",
        "                nn.utils.clip_grad_norm_(model.parameters(), float(cfg.max_grad_norm))\n",
        "                optim.step()\n",
        "\n",
        "            # stats\n",
        "            l = float(loss.item())\n",
        "            running_loss += l\n",
        "            global_step += 1\n",
        "            steps_in_epoch += 1\n",
        "\n",
        "            loss_ema = l if loss_ema is None else (0.95 * loss_ema + 0.05 * l)\n",
        "\n",
        "            step_dt = time.time() - step_start\n",
        "            step_time_ema = step_dt if step_time_ema is None else (0.90 * step_time_ema + 0.10 * step_dt)\n",
        "\n",
        "            if steps_in_epoch % int(cfg.log_every_steps) == 0:\n",
        "                elapsed = time.time() - t0\n",
        "                remaining = max(0, est_steps_epoch - steps_in_epoch)\n",
        "                eta = (step_time_ema * remaining) if step_time_ema is not None else 0.0\n",
        "                pct = 100.0 * steps_in_epoch / max(1, est_steps_epoch)\n",
        "                print(\n",
        "                    f\"[epoch {epoch} {steps_in_epoch}/{est_steps_epoch} ({pct:.1f}%)] \"\n",
        "                    f\"loss_ema={loss_ema:.4f} step={step_dt:.3f}s \"\n",
        "                    f\"elapsed={elapsed/60:.1f}m ETA={eta/60:.1f}m\"\n",
        "                )\n",
        "\n",
        "            if steps_in_epoch >= est_steps_epoch:\n",
        "                break\n",
        "\n",
        "        metrics = evaluate_bilstm(model, dev_loader, device=device, max_batches=200)\n",
        "        epoch_time = time.time() - t0\n",
        "        print(\n",
        "            f\"== Epoch {epoch} done | time={epoch_time/60:.1f}m \"\n",
        "            f\"dev_macroF1={metrics['macro_f1_1_6']:.4f} dev_binF1={metrics['binary_f1_punct']:.4f} ==\"\n",
        "        )\n",
        "        print(\"Per-class F1:\", {\n",
        "            ArabicPunctuationProcessor.CLASS_TO_PUNCTUATION[c]: round(metrics[f\"f1_class_{c}\"], 4)\n",
        "            for c in range(1, 7)\n",
        "        })\n",
        "\n",
        "        latest_path = ckpt_latest_path\n",
        "        epoch_path = os.path.join(out_dir, f\"bilstm_epoch_{epoch+1:02d}.pt\")\n",
        "\n",
        "        save_ckpt(latest_path, model, optim, scaler, epoch + 1, global_step, word2id, cfg)\n",
        "        save_ckpt(epoch_path, model, optim, scaler, epoch + 1, global_step, word2id, cfg)\n",
        "\n",
        "        print(\"Saved:\", latest_path)\n",
        "        print(\"Saved:\", epoch_path)\n",
        "\n",
        "    return ckpt_latest_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "7eee7ea4",
      "metadata": {},
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class TrainConfig:\n",
        "    # بيانات\n",
        "    data_dir: str = \"./Clean/full-corpus2/\"\n",
        "    vocab_path: str = \"./vocab_top50k.json\"\n",
        "\n",
        "    # vocab\n",
        "    vocab_size: int = 50_000\n",
        "    min_token_freq: int = 2\n",
        "\n",
        "    # نافذة التسلسل\n",
        "    seq_len: int = 256\n",
        "    stride: int = 128\n",
        "\n",
        "    # DataLoader\n",
        "    batch_size: int = 16\n",
        "    num_workers: int = 0\n",
        "    pin_memory: bool = True\n",
        "\n",
        "    # نموذج BiLSTM\n",
        "    emb_dim: int = 200\n",
        "    hidden_size: int = 256\n",
        "    num_layers: int = 2\n",
        "    dropout: float = 0.3\n",
        "\n",
        "    # تدريب\n",
        "    lr: float = 1e-3\n",
        "    weight_decay: float = 0.01\n",
        "    max_grad_norm: float = 1.0\n",
        "    epochs: int = 5\n",
        "\n",
        "    # (اختياري) تراكم التدرجات — إذا أردت تفعيله لاحقًا داخل حلقة التدريب\n",
        "    grad_accum_steps: int = 1\n",
        "\n",
        "    # AMP\n",
        "    amp: bool = True\n",
        "\n",
        "    # logging\n",
        "    log_every_steps: int = 200\n",
        "\n",
        "    # تقسيم dev\n",
        "    dev_files: int = 5\n",
        "\n",
        "    # seed\n",
        "    seed: int = 42\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ff045b7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files: total=79 train=70 dev=9\n",
            "Building vocab (streaming) ...\n",
            "Vocab size: 50002\n",
            "Saved vocab to: ./vocab_top50k.json\n",
            "Dev counts sample: [704515  36376   1102   2285  36713    842     26]\n",
            "Focal alpha: [0.00619065 0.02724385 0.15645668 0.10867853 0.02711852 0.178965\n",
            " 1.        ]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_22604\\2427432429.py:137: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(bool(cfg.amp) and device == \"cuda\"))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Estimated steps/epoch: 140585\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_22604\\2427432429.py:173: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(bool(cfg.amp) and device == \"cuda\")):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[epoch 0 200/140585 (0.1%)] loss_ema=0.0034 step=0.467s elapsed=1.6m ETA=1110.8m\n",
            "[epoch 0 400/140585 (0.3%)] loss_ema=0.0017 step=0.466s elapsed=3.2m ETA=1093.6m\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[38], line 28\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Cell I — اختبار سريع على 10 ملفات للتأكد أن كل شيء يعمل\u001b[39;00m\n\u001b[0;32m      3\u001b[0m cfg \u001b[38;5;241m=\u001b[39m TrainConfig(\n\u001b[0;32m      4\u001b[0m     data_dir\u001b[38;5;241m=\u001b[39mConfig\u001b[38;5;241m.\u001b[39mcleaned_data_dir,\n\u001b[0;32m      5\u001b[0m     vocab_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./vocab_top50k.json\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m,\n\u001b[0;32m     26\u001b[0m )\n\u001b[1;32m---> 28\u001b[0m ckpt \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_bilstm_focal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcleaned_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcleaned_data_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./checkpoints_bilstm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m79\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# <-- اختبار 10 ملفات فقط\u001b[39;49;00m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdev_files_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# 2 dev + 8 train\u001b[39;49;00m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvocab_scan_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10_000_000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# سريع لبناء vocab في الاختبار\u001b[39;49;00m\n\u001b[0;32m     35\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLatest checkpoint:\u001b[39m\u001b[38;5;124m\"\u001b[39m, ckpt)\n",
            "Cell \u001b[1;32mIn[35], line 179\u001b[0m, in \u001b[0;36mtrain_bilstm_focal\u001b[1;34m(cleaned_dir, cfg, out_dir, ckpt_latest_name, max_files, dev_files_count, vocab_scan_words, use_existing_vocab_path)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scaler\u001b[38;5;241m.\u001b[39mis_enabled():\n\u001b[0;32m    178\u001b[0m     scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m--> 179\u001b[0m     \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munscale_\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m     nn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;28mfloat\u001b[39m(cfg\u001b[38;5;241m.\u001b[39mmax_grad_norm))\n\u001b[0;32m    181\u001b[0m     scaler\u001b[38;5;241m.\u001b[39mstep(optim)\n",
            "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:339\u001b[0m, in \u001b[0;36mGradScaler.unscale_\u001b[1;34m(self, optimizer)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;66;03m# FP32 division can be imprecise for certain compile options, so we carry out the reciprocal in FP64.\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 339\u001b[0m inv_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_scale\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdouble\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreciprocal()\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m    340\u001b[0m found_inf \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull((), \u001b[38;5;241m0.0\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scale\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    342\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unscale_grads_(\n\u001b[0;32m    343\u001b[0m     optimizer, inv_scale, found_inf, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    344\u001b[0m )\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "cfg = TrainConfig(\n",
        "    data_dir=Config.cleaned_data_dir,\n",
        "    vocab_path=\"./vocab_top50k.json\",\n",
        "    vocab_size=50_000,\n",
        "    min_token_freq=2,\n",
        "    seq_len=256,\n",
        "    stride=128,\n",
        "    batch_size=16,\n",
        "    num_workers=0,\n",
        "    pin_memory=True,\n",
        "    emb_dim=200,\n",
        "    hidden_size=256,\n",
        "    num_layers=3,     \n",
        "    dropout=0.3,\n",
        "    lr=1e-3,\n",
        "    weight_decay=0.01,\n",
        "    max_grad_norm=1.0,\n",
        "    epochs=10,\n",
        "    grad_accum_steps=1,  \n",
        "    amp=True,\n",
        "    log_every_steps=200,\n",
        "    dev_files=2,\n",
        "    seed=42,\n",
        ")\n",
        "\n",
        "ckpt = train_bilstm_focal(\n",
        "    cleaned_dir=Config.cleaned_data_dir,\n",
        "    cfg=cfg,\n",
        "    out_dir=\"./checkpoints_bilstm\",\n",
        "    max_files=79,          # <-- اختبار 10 ملفات فقط\n",
        "    dev_files_count=9,     # 2 dev + 8 train\n",
        "    vocab_scan_words=10_000_000,  # سريع لبناء vocab في الاختبار\n",
        ")\n",
        "print(\"Latest checkpoint:\", ckpt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "id": "e28d3887",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50002"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lstm_model = load_ckpt(\"BiLSTM_checkpoint/bilstm_latest.pt\" , device=device)\n",
        "\n",
        "len(lstm_model.get(\"word2id\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79753a18",
      "metadata": {},
      "source": [
        "# قسم اختبار النماذج\n",
        "\n",
        "في هذا القسم من النوتبوك سيتم وضع جميع توابع الاختبار للموديلات الثلاثة التي قمت ببنائها:\n",
        "\n",
        "## النماذج التي سيتم اختبارها\n",
        "\n",
        "\n",
        "### 1. **Terminal Prediction (Base Model)**\n",
        "- النموذج الأساسي للتنبؤ بنهاية الجمل\n",
        "\n",
        "### 2. **Two Stage Linear Model (Base Model)**\n",
        "- النموذج الخطي ثنائي المراحل\n",
        "\n",
        "### 3. **BiLSTM**\n",
        "- نموذج الشبكة العصبية المتكررة ثنائية الاتجاه\n",
        "\n",
        "## التوابع المساعدة\n",
        "\n",
        "### **`preprocess_text(text, preprocessor)`**\n",
        "- هذا التابع سيقوم بعمل **معالجة مسبقة للنص** باستخدام الكلاس الذي عرفته مسبقاً `ArabicPunctuationProcessor`\n",
        "\n",
        "###  **`remove_punctuation_from_text(text)`**\n",
        "- هذا التابع سوف يقوم بإعادة **نص ولكن بدون علامات ترقيم**\n",
        "\n",
        "###  **`decode_text(tokens, labels)`**\n",
        "- هذا التابع سيقوم بإعادة **تركيب النص** الذي قام الموديل بتنبؤه\n",
        "\n",
        "\n",
        "بالأضافة للتوابع المساعدة التي تحسب الدقة "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "id": "23bd4dd4",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Optional, Sequence, Dict, Any, Tuple, List, Union\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "\n",
        "def preprocess_text(text, preprocessor: Optional[ArabicPunctuationProcessor] = None):\n",
        "    if preprocessor is None:\n",
        "        preprocessor = ArabicPunctuationProcessor(remove_diacritics=True)\n",
        "    return preprocessor.preprocess_text(text)\n",
        "\n",
        "def remove_punctuation_from_text(text, preprocessor: Optional[ArabicPunctuationProcessor] = None):\n",
        "    if preprocessor is None:\n",
        "        preprocessor = ArabicPunctuationProcessor(remove_diacritics=True)\n",
        "    words, _ = split_tokens_labels_from_tokens(text.split())\n",
        "    return \" \".join(words)\n",
        "\n",
        "def decode_text(tokens, labels):\n",
        "    new_text = \"\" \n",
        "    for token, punc in zip(tokens, labels):\n",
        "        if token == ArabicPunctuationProcessor.SPECIAL_TOKENS[\"LINE\"]:\n",
        "            new_text += \"\\n\"\n",
        "            continue\n",
        "        new_text += token\n",
        "        punc_char = ArabicPunctuationProcessor.CLASS_TO_PUNCTUATION.get(punc, \"\")\n",
        "        if punc_char:\n",
        "            new_text += punc_char\n",
        "        new_text += \" \"\n",
        "    return new_text\n",
        "        \n",
        "\n",
        "def prepare_text_and_labels(text: str, preprocessor: Optional[ArabicPunctuationProcessor] = None) -> Tuple[List[str], List[int], str, str]:\n",
        "    \n",
        "    if preprocessor is None:\n",
        "        preprocessor = ArabicPunctuationProcessor(remove_diacritics=True)\n",
        "        \n",
        "    processed_text = preprocessor.preprocess_text(text)\n",
        "    no_punctuation = remove_punctuation_from_text(processed_text, preprocessor)\n",
        "    \n",
        "    tokens, labels = split_tokens_labels_from_tokens(processed_text.split())\n",
        "\n",
        "    return tokens, labels, processed_text, no_punctuation\n",
        "\n",
        "def evaluate_on_sequences(\n",
        "    pairs: Sequence[Tuple[List[str], List[int]]],\n",
        "    predict_fn, \n",
        "    return_text_example: bool = False\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Pairs: قائمة من (tokens, labels)\n",
        "    predict_fn(toekns) -> y_pred\n",
        "    \"\"\"\n",
        "    cm = np.zeros((7, 7), dtype=np.int64)\n",
        "    \n",
        "    example = None \n",
        "    \n",
        "    for i , (tokens, labels) in enumerate(pairs):\n",
        "        y_pred = predict_fn(tokens)\n",
        "        \n",
        "        update_confusion(cm, labels, y_pred)\n",
        "        \n",
        "        if return_text_example:\n",
        "            example = {\n",
        "                \"tokens\": tokens[:2000], \n",
        "                \"y_true\": labels[:2000],\n",
        "                \"y_pred\": y_pred[:2000],\n",
        "                \"decoded_pred\": decode_text(tokens[:2000], y_pred[:2000]),\n",
        "                \"decoded_true\": decode_text(tokens[:2000], labels[:2000]),\n",
        "            }\n",
        "\n",
        "    summary = summarize_confusion(cm)\n",
        "    return {\n",
        "        \"confusion\": cm,\n",
        "        \"summary\": summary,\n",
        "        \"example\": example,\n",
        "    }     \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def load_file_pairs(files: Sequence[str], max_tokens_per_file: Optional[int] = None) -> List[Tuple[List[str], List[int]]]:\n",
        "    pairs = []\n",
        "    for fp in files:\n",
        "        tokens, y = load_tokens_labels_from_file(fp, max_tokens=max_tokens_per_file)\n",
        "        pairs.append((tokens, y))\n",
        "    return pairs\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from typing import Dict, Optional\n",
        "\n",
        "def accuracy_from_confusion(\n",
        "    cm: np.ndarray,\n",
        "    *,\n",
        "    ignore_class: Optional[int] = None,\n",
        ") -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    يحسب Accuracy مباشرة من مصفوفة الالتباس cm (حجمها 7x7 غالبًا).\n",
        "\n",
        "    - accuracy: الدقة الكلية = sum(diag) / sum(all)\n",
        "    - total: مجموع العينات\n",
        "    - correct: مجموع القطر\n",
        "\n",
        "    إذا مرّرت ignore_class (مثلاً 0 لاستثناء \"لا ترقيم\") سيتم استثناؤه\n",
        "    من المقام والبسط (أي نحسب الدقة على بقية الفئات فقط).\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    cm = np.asarray(cm)\n",
        "    assert cm.shape[0] == cm.shape[1], \"Confusion matrix must be square.\"\n",
        "\n",
        "    if ignore_class is None:\n",
        "        total = float(cm.sum())\n",
        "        correct = float(np.trace(cm))\n",
        "        acc = float(correct / total) if total > 0 else 0.0\n",
        "        return {\"accuracy\": acc, \"total\": total, \"correct\": correct}\n",
        "\n",
        "    # Accuracy over TRUE labels excluding ignore_class (row-based masking)\n",
        "    keep_rows = [i for i in range(cm.shape[0]) if i != ignore_class]\n",
        "    total = float(cm[keep_rows, :].sum())\n",
        "    correct = float(sum(cm[i, i] for i in keep_rows))\n",
        "    acc = float(correct / total) if total > 0 else 0.0\n",
        "    return {\"accuracy\": acc, \"total\": total, \"correct\": correct}\n",
        "\n",
        "\n",
        "def binary_accuracy_punct_vs_none_from_confusion(\n",
        "    cm: np.ndarray,\n",
        "    *,\n",
        "    none_class: int = 0,\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Binary accuracy where:\n",
        "      - negative = class none_class (usually 0)\n",
        "      - positive = all other classes (1..6)\n",
        "\n",
        "    Returns: {\"binary_accuracy\": float, \"tp\": float, \"tn\": float, \"fp\": float, \"fn\": float, \"total\": float}\n",
        "    \"\"\"\n",
        "    cm = np.asarray(cm)\n",
        "    assert cm.shape[0] == cm.shape[1], \"Confusion matrix must be square.\"\n",
        "\n",
        "    # True negatives: true none predicted none\n",
        "    tn = float(cm[none_class, none_class])\n",
        "\n",
        "    # False positives: true none predicted punct\n",
        "    fp = float(cm[none_class, :].sum() - cm[none_class, none_class])\n",
        "\n",
        "    # False negatives: true punct predicted none\n",
        "    fn = float(cm[:, none_class].sum() - cm[none_class, none_class])\n",
        "\n",
        "    # True positives: true punct predicted punct (all non-none rows/cols)\n",
        "    # Equivalent: total - (tn + fp + fn)\n",
        "    total = float(cm.sum())\n",
        "    tp = float(total - (tn + fp + fn))\n",
        "\n",
        "    acc = float((tp + tn) / total) if total > 0 else 0.0\n",
        "    return {\"binary_accuracy\": acc, \"tp\": tp, \"tn\": tn, \"fp\": fp, \"fn\": fn, \"total\": total}\n",
        "\n",
        "\n",
        "def compute_all_accuracies(cm: np.ndarray) -> Dict[str, Any]:\n",
        "    return {\n",
        "        \"accuracy with all classes\": accuracy_from_confusion(cm),\n",
        "        \"accuracy without none\": accuracy_from_confusion(cm, ignore_class=0),  # punctuation-only TRUE positions\n",
        "        \"binary accuracy punct vs none\": binary_accuracy_punct_vs_none_from_confusion(cm, none_class=0),\n",
        "    }\n",
        "\n",
        "preprocess_methods = [\n",
        "    \"Text preprocessing via ArabicPunctuationProcessor.preprocess_text (convert newlines to [LINE])\",\n",
        "    \"Remove control characters (/r /t )\",\n",
        "    \"Punctuation normalization: convert (, ; ?) to (، ؛ ؟)\",\n",
        "    \"Number normalization: convert Western digits to Arabic digits\",\n",
        "    \"Remove diacritics (when remove_diacritics=True)\",\n",
        "    \"Replace emails with [EMAIL]\",\n",
        "    \"Replace URLs with [URL]\",\n",
        "    \"Replace dates (numeric + textual) with [DATE]\",\n",
        "    \"Replace times with [TIME]\",\n",
        "    \"Replace remaining numbers with [NUM]\",\n",
        "    \"Separate target punctuation from words using spaces\",\n",
        "    \"Normalize whitespace and remove extra spaces\",\n",
        "    \"Scrub/remove unwanted symbols inside/around tokens (e.g., « » … —), while keeping special tokens intact\",\n",
        "    \"Split into tokens + labels via split_tokens_labels_from_tokens (label punctuation after each word; label [LINE] as -100)\",\n",
        "]\n",
        "\n",
        "\n",
        "def evaluate_terminal(\n",
        "    data: Union[str, Sequence[str]],\n",
        "    is_text: bool = True, # اذا كان هذا المتغير صحيح، فالمدخل هو نص، غير ذلك هو مصفوفة تحوي على باثات الفايلات\n",
        "    *, \n",
        "    preprocessor: Optional[ArabicPunctuationProcessor] = None,\n",
        "    max_tokens_per_file: Optional[int] = None\n",
        "):\n",
        "    \n",
        "    \n",
        "    model_name = \"Terminal Prediction (Heuristic Baseline)\"\n",
        "    features = \"Rule-Based terminal punctuation prediction using [LINE] and question cues\"\n",
        "    model_parameters = \"NONE\"\n",
        "    \n",
        "    \n",
        "    def _pred_fn(tokens):\n",
        "        return predict_terminal(tokens)\n",
        "    if is_text:\n",
        "        tokens, labels, preprocessed, no_punctuation = prepare_text_and_labels(data, preprocessor)\n",
        "        \n",
        "    \n",
        "        out = evaluate_on_sequences(\n",
        "            pairs=[(tokens, labels)],\n",
        "            predict_fn=_pred_fn,\n",
        "            return_text_example=True\n",
        "        )\n",
        "        return {\n",
        "            \"number_step\": 1,\n",
        "            \"model_name\": model_name,\n",
        "            \"features\": features,\n",
        "            \"model_parameters\": model_parameters,\n",
        "            \"preprocessing_methods\": preprocess_methods,\n",
        "            \"accuracy\": compute_all_accuracies(out[\"confusion\"]),\n",
        "            \"F-score\": out[\"summary\"],  \n",
        "            \"confusion\": out[\"confusion\"],\n",
        "            \"text\": {\n",
        "                \"original\": str(data),\n",
        "                \"preprocessed\": preprocessed,\n",
        "                \"no_punctuation\": no_punctuation,\n",
        "                \"decoded_prediction\": out[\"example\"][\"decoded_pred\"],\n",
        "            },\n",
        "        }\n",
        "    files = list(data) \n",
        "    pairs = load_file_pairs(files, max_tokens_per_file=max_tokens_per_file)\n",
        "    \n",
        "    out = evaluate_on_sequences(pairs, _pred_fn, return_text_example=True)    \n",
        "    return {\n",
        "        \"number_step\": 1,\n",
        "        \"model_name\": model_name,\n",
        "        \"features\": features,\n",
        "        \"model_parameters\": model_parameters,\n",
        "        \"preprocessing_methods\": preprocess_methods,\n",
        "        \"accuracy\": compute_all_accuracies(out[\"confusion\"]),\n",
        " \n",
        "        \"F-score\": out[\"summary\"],\n",
        "        \"confusion\": out[\"confusion\"],\n",
        "        \"example\": out[\"example\"],\n",
        "    }\n",
        "    \n",
        "    \n",
        "    \n",
        "def evaluate_TwoStageLinear(\n",
        "    model: TwoStageLinearWithNgrams,\n",
        "    data: Union[str, Sequence[str]],\n",
        "    is_text: bool = True,\n",
        "    *,\n",
        "    preprocessor: Optional[ArabicPunctuationProcessor] = None,\n",
        "    max_tokens_per_file: Optional[int] = None,\n",
        "    pred_batch_size: int = 50000,\n",
        ") -> Dict[str, Any]:\n",
        "    model_name = \"Two Stage Linear Model (SGD + FeatureHasher)\"\n",
        "    features = f\"window={model.extractor.cfg.window}, word_ngrams={model.extractor.cfg.use_word_ngrams}, char_ngrams={model.extractor.cfg.use_char_ngrams}, hashed_dim={model.hasher.n_features}\"\n",
        "\n",
        "    model_parameters = {\n",
        "        \"tau\": float(getattr(model, \"tau\", 0.5)),\n",
        "        \"alpha\": \"as-trained\",\n",
        "        \"loss\": \"log_loss\",\n",
        "        \"n_features\": int(model.hasher.n_features),\n",
        "    }\n",
        "    \n",
        "    def _pred(tokens: Sequence[str]) -> List[int]:\n",
        "        return model.predict_streaming(tokens, batch_size=pred_batch_size)\n",
        "    if is_text:\n",
        "        tokens, y_true, preprocessed, no_punctuation = prepare_text_and_labels(str(data), preprocessor)\n",
        "        y_pred = _pred(tokens)\n",
        "        cm = np.zeros((7, 7), dtype=np.int64)\n",
        "        update_confusion(cm, y_true, y_pred)\n",
        "        summary = summarize_confusion(cm)\n",
        "        decoded_pred = decode_text(tokens, y_pred)\n",
        "\n",
        "        return {\n",
        "            \"number_step\": 2,\n",
        "            \"name_model\": model_name,\n",
        "            \"features\": features,\n",
        "            \"model_parameters\": model_parameters,\n",
        "            \"preprocessing_methods\": preprocess_methods,\n",
        "            \"accuracy\": compute_all_accuracies(cm),\n",
        "\n",
        "            \"F-score\": summary,\n",
        "            \"confusion\": cm,\n",
        "            \"text\": {\n",
        "                \"original\": str(data),\n",
        "                \"preprocessed\": preprocessed,\n",
        "                \"no_punctuation\": no_punctuation,\n",
        "                \"decoded_prediction\": decoded_pred,\n",
        "            },\n",
        "        }\n",
        "\n",
        "    files = list(data)\n",
        "    pairs = load_file_pairs(files, max_tokens_per_file=max_tokens_per_file)\n",
        "    out = evaluate_on_sequences(pairs, _pred, return_text_example=True)\n",
        "\n",
        "    return {\n",
        "        \"number_step\": 2,\n",
        "        \"name_model\": model_name,\n",
        "        \"features\": features,\n",
        "        \"model_parameters\": model_parameters,\n",
        "        \"preprocessing_methods\": preprocess_methods,\n",
        "        \"accuracy\": compute_all_accuracies(out[\"confusion\"]),\n",
        "\n",
        "        \"F-score\": out[\"summary\"],\n",
        "        \"confusion\": out[\"confusion\"],\n",
        "        \"example\": out[\"example\"],\n",
        "    }\n",
        "    \n",
        "def evaluate_bilstm(\n",
        "    ckpt: Dict,\n",
        "    data: Union[str, Sequence[str]],\n",
        "    is_text: bool = True,\n",
        "    *,\n",
        "    preprocessor: Optional[ArabicPunctuationProcessor] = None,\n",
        "    device: Optional[str] = None,\n",
        "    max_tokens_per_file: Optional[int] = None,\n",
        "    seq_len: int = 256,\n",
        "    stride: int = 128,\n",
        ") -> Dict[str, Any]:\n",
        "    # إعادة بناء النموذج \n",
        "    word2id = ckpt[\"word2id\"]\n",
        "    state_dict = ckpt[\"model\"]\n",
        "    train_cfg = ckpt.get(\"train_cfg\", {})\n",
        "    \n",
        "    emb_dim = int(train_cfg.get(\"emb_dim\", 200))\n",
        "    hidden = int(train_cfg.get(\"hidden\", train_cfg.get(\"hidden_size\", 256)))\n",
        "    num_layers = int(train_cfg.get(\"num_layers\", 2))\n",
        "    dropout = float(train_cfg.get(\"dropout\", 0.3))\n",
        "\n",
        "    model = BiLSTMTagger(\n",
        "        vocab_size=len(word2id),\n",
        "        emb_dim=emb_dim,\n",
        "        hidden_size=hidden,\n",
        "        num_layers=num_layers,\n",
        "        dropout=dropout,\n",
        "        num_classes=7,\n",
        "        pad_id=word2id.get(\"[PAD]\", 0),\n",
        "    )\n",
        "\n",
        "    model.load_state_dict(state_dict)\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    model_name = \"BiLSTM Tagger\"\n",
        "    features = f\"token-ids + BiLSTM sequence labeling, window={seq_len}, stride={stride}\"\n",
        "    model_parameters = \"as-trained\"\n",
        "    \n",
        "    if device is None:\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "\n",
        "    UNK_ID = word2id.get(\"[UNK]\", word2id.get(\"[UNK]\".lower(), 1))\n",
        "    PAD_ID = word2id.get(\"[PAD]\", 0)\n",
        "    def tokens_to_ids(tokens: Sequence[str]) -> np.ndarray:\n",
        "        return np.asarray([word2id.get(t, UNK_ID) for t in tokens], dtype=np.int64)\n",
        "    @torch.no_grad()\n",
        "    def _pred(tokens: List[str]) -> List[int]:\n",
        "        \n",
        "        n = len(tokens)\n",
        "        num_classes = 7\n",
        "        acc = np.zeros((n, num_classes), dtype=np.float32)\n",
        "        cnt = np.zeros((n,), dtype=np.float32)\n",
        "\n",
        "        ids = tokens_to_ids(tokens)\n",
        "        start = 0\n",
        "        while start < n:\n",
        "            end = min(n, start + seq_len)\n",
        "            window_ids = ids[start:end]\n",
        "\n",
        "            if len(window_ids) < seq_len:\n",
        "                pad = np.full((seq_len - len(window_ids),), PAD_ID, dtype=np.int64)\n",
        "                window_ids = np.concatenate([window_ids, pad], axis=0)\n",
        "\n",
        "            xb = torch.from_numpy(window_ids[None, :]).to(device)\n",
        "\n",
        "            logits = model(xb)  # [1, T, C]\n",
        "            logits = logits.squeeze(0).detach().float().cpu().numpy()  # [T, C]\n",
        "\n",
        "            valid_len = end - start\n",
        "            acc[start:end] += logits[:valid_len]\n",
        "            cnt[start:end] += 1.0\n",
        "\n",
        "            if end == n:\n",
        "                break\n",
        "            start += stride\n",
        "\n",
        "        acc /= np.maximum(cnt[:, None], 1e-6)\n",
        "        y_pred = acc.argmax(axis=1).astype(np.int64).tolist()\n",
        "\n",
        "        # keep [LINE] masked\n",
        "        for i, t in enumerate(tokens):\n",
        "            if t == ArabicPunctuationProcessor.SPECIAL_TOKENS[\"LINE\"]:\n",
        "                y_pred[i] = -100\n",
        "\n",
        "        return y_pred\n",
        "\n",
        "    if is_text:\n",
        "        tokens, y_true, preprocessed, no_punctuation = prepare_text_and_labels(str(data), preprocessor)\n",
        "        y_pred = _pred(tokens)\n",
        "        cm = np.zeros((7, 7), dtype=np.int64)\n",
        "        update_confusion(cm, y_true, y_pred)\n",
        "        summary = summarize_confusion(cm)\n",
        "        decoded_pred = decode_text(tokens, y_pred)\n",
        "\n",
        "        return {\n",
        "            \"number_step\": 3,\n",
        "            \"name_model\": model_name,\n",
        "            \"features\": features,\n",
        "            \"model_parameters\": model_parameters,\n",
        "            \"preprocessing_methods\": preprocess_methods,\n",
        "            \"accuracy\": compute_all_accuracies(cm),\n",
        "\n",
        "            \"F-score\": summary,\n",
        "            \"confusion\": cm,\n",
        "            \"text\": {\n",
        "                \"original\": str(data),\n",
        "                \"preprocessed\": preprocessed,\n",
        "                \"no_punctuation\": no_punctuation,\n",
        "                \"decoded_prediction\": decoded_pred,\n",
        "            },\n",
        "        }\n",
        "\n",
        "    files = list(data)\n",
        "    pairs = load_file_pairs(files, max_tokens_per_file=max_tokens_per_file)\n",
        "    out = evaluate_on_sequences(pairs, _pred, return_text_example=True)\n",
        "\n",
        "    return {\n",
        "        \"number_step\": 3,\n",
        "        \"name_model\": model_name,\n",
        "        \"features\": features,\n",
        "        \"model_parameters\": model_parameters,\n",
        "        \"preprocessing_methods\": preprocess_methods,\n",
        "        \"accuracy\": compute_all_accuracies(out[\"confusion\"]),\n",
        "\n",
        "        \"F-score\": out[\"summary\"],\n",
        "        \"confusion\": out[\"confusion\"],\n",
        "        \"example\": out[\"example\"],\n",
        "    }\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "id": "6ce4aa10",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BiLSTM Evaluation on Sample Text:\n",
            "Accuracy: {'accuracy with all classes': {'accuracy': 0.7363636363636363, 'total': 220.0, 'correct': 162.0}, 'accuracy without none': {'accuracy': 0.11764705882352941, 'total': 34.0, 'correct': 4.0}, 'binary accuracy punct vs none': {'binary_accuracy': 0.8136363636363636, 'tp': 21.0, 'tn': 158.0, 'fp': 28.0, 'fn': 13.0, 'total': 220.0}}\n",
            "Linear Evaluation on Sample Text:\n",
            "Accuracy: {'accuracy with all classes': {'accuracy': 0.8318181818181818, 'total': 220.0, 'correct': 183.0}, 'accuracy without none': {'accuracy': 0.0, 'total': 34.0, 'correct': 0.0}, 'binary accuracy punct vs none': {'binary_accuracy': 0.8454545454545455, 'tp': 3.0, 'tn': 183.0, 'fp': 3.0, 'fn': 31.0, 'total': 220.0}}\n",
            "Terminal Heuristic Evaluation on Sample Text:\n",
            "Accuarcy: {'accuracy with all classes': {'accuracy': 0.8409090909090909, 'total': 220.0, 'correct': 185.0}, 'accuracy without none': {'accuracy': 0.0, 'total': 34.0, 'correct': 0.0}, 'binary accuracy punct vs none': {'binary_accuracy': 0.8454545454545455, 'tp': 1.0, 'tn': 185.0, 'fp': 1.0, 'fn': 33.0, 'total': 220.0}}\n"
          ]
        }
      ],
      "source": [
        "testing_text = \"\"\"\n",
        "ثانيًا: المجد الروماني\n",
        "\n",
        "ابتداءً من القرن الثاني عشر قبل الميلاد، تدفَّق الرومان من شرق أوروبا إلى شبه الجزيرة الإيطالية مؤسسين روما القديمة عاصمة لهم. وافتتانًا بالحضارة اليونانية، نظَّم الرومان دولتهم. وأبدعوا في علوم القانون، وأخذوا في التوسع العسكري حتى تمكنت جيوش روما من فرض هيمنتها على كامل الأراضي الإيطالية، ثم انطلقت لإحكام السيطرة على ممالك العالم القديم. فمن الجزر البريطانية وسواحل المحيط الأطلسي غربًا إلى بلادِ ما بين النهرَين وبحر قزوين شرقًا، ومن وسط أوروبا وجبال الألب شمالًا إلى الصحراء الكبرى والبحر الأحمر جنوبًا، نشأتِ الإمبراطورية الرومانية كدولةٍ توسعية ذات طابعٍ استعماري. وحينما سقطت روما في منتصف القرن الخامس الميلادي. وورث الملوك الجرمان النظام الإمبراطوري. نشأت دول غرب أوروبا بخاصة إسبانيا، والبرتغال، وفرنسا، وإنجلترا، وهولندا كممالكَ توسُّعية حاملة شعلة المجد الروماني. وسيصبح العالم بأسره حقلًا لعملياتها الاستعمارية. ولم يكن من الممكن أيديولوجيًّا اعتبار العالم مسرحًا لتمدُّد حدود هذه الدول الاستعمارية إلا ابتداءً من أيديولوجيةٍ استعمارية/استبعادية أساسها اعتبار كلِّ ما هو غير أوروبي، تمامًا كما كانت روما تنظر إلى غيرها، خارج الحضارة الإنسانية وفي انتظار أوروبا من أجل «إعماره» وجعله متحضرًا مثل أوروبا. فكما نظرت روما إلى الجرمان كبرابرة، نظر الجرمان، بعد رومنتهم، وأحفادهم من بعدهم، إلى غيرهم نفس النظرة المتعالية. فقبائل أمريكا الجنوبية وثنية يجب هدايتها أو إحراقها والاستيلاء على كنوزها. والأفارقة عبيدٌ أدنياء. والعرب أجْلَاف بالسليقة. والمسلمون هَمج رعاع. والحضارة، بجميع مفرداتها وظواهرها الاجتماعية، لم تبدأ إلا من أوروبا!\n",
        "\"\"\"\n",
        "\n",
        "lstm_model = load_ckpt(\"BiLSTM_checkpoint/bilstm_latest.pt\" , device=device)\n",
        "\n",
        "out_lstm = evaluate_bilstm(\n",
        "    ckpt=lstm_model,\n",
        "    data=testing_text,\n",
        "    is_text=True,\n",
        "    device=device,\n",
        "    max_tokens_per_file=None,\n",
        "    seq_len=256,\n",
        "    stride=128,\n",
        ")\n",
        "print(\"BiLSTM Evaluation on Sample Text:\")\n",
        "print(\"Accuracy:\", out_lstm[\"accuracy\"])\n",
        "\n",
        "linear_model = load_model(\"linear_model_checkpoints/model_final.pkl\")\n",
        "out_linear = evaluate_TwoStageLinear(\n",
        "    model=linear_model,\n",
        "    data=testing_text,\n",
        "    is_text=True\n",
        ")\n",
        "\n",
        "print(\"Linear Evaluation on Sample Text:\")\n",
        "print(\"Accuracy:\", out_linear[\"accuracy\"])\n",
        "\n",
        "out_terminal = evaluate_terminal(\n",
        "    data=testing_text,\n",
        "    is_text=True)\n",
        "print(\"Terminal Heuristic Evaluation on Sample Text:\")\n",
        "print(\"Accuarcy:\", out_terminal[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c3fc8ed",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 154,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "id": "2837d002",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BiLSTM Evaluation on Sample Text:\n",
            "Accuracy: {'accuracy with all classes': {'accuracy': 0.9555257209461681, 'total': 27065509.0, 'correct': 25861790.0}, 'accuracy without none': {'accuracy': 0.8896697265457997, 'total': 2491057.0, 'correct': 2216218.0}, 'binary accuracy punct vs none': {'binary_accuracy': 0.9585659371859587, 'tp': 2298503.0, 'tn': 23645572.0, 'fp': 928880.0, 'fn': 192554.0, 'total': 27065509.0}}\n",
            "Linear Evaluation on Sample Text:\n",
            "Accuracy: {'accuracy with all classes': {'accuracy': 0.9566153365155631, 'total': 27065509.0, 'correct': 25891281.0}, 'accuracy without none': {'accuracy': 0.5833848844085061, 'total': 2491057.0, 'correct': 1453245.0}, 'binary accuracy punct vs none': {'binary_accuracy': 0.957336180154602, 'tp': 1472755.0, 'tn': 24438036.0, 'fp': 136416.0, 'fn': 1018302.0, 'total': 27065509.0}}\n",
            "Terminal Heuristic Evaluation on Sample Text:\n",
            "Accuarcy: {'accuracy with all classes': {'accuracy': 0.9364774554951101, 'total': 27065509.0, 'correct': 25346239.0}, 'accuracy without none': {'accuracy': 0.309823099190424, 'total': 2491057.0, 'correct': 771787.0}, 'binary accuracy punct vs none': {'binary_accuracy': 0.9466328159577564, 'tp': 1046647.0, 'tn': 24574452.0, 'fp': 0.0, 'fn': 1444410.0, 'total': 27065509.0}}\n"
          ]
        }
      ],
      "source": [
        "files = dev_files\n",
        "\n",
        "lstm_model = load_ckpt(\"BiLSTM_checkpoint/bilstm_latest.pt\" , device=device)\n",
        "\n",
        "out_lstm = evaluate_bilstm(\n",
        "    ckpt=lstm_model,\n",
        "    data=files,\n",
        "    is_text=False,\n",
        "    device=device,\n",
        "    max_tokens_per_file=None,\n",
        "    seq_len=256,\n",
        "    stride=128,\n",
        ")\n",
        "print(\"BiLSTM Evaluation on Sample Text:\")\n",
        "print(\"Accuracy:\", out_lstm[\"accuracy\"])\n",
        "\n",
        "linear_model = load_model(\"linear_model_checkpoints/model_final.pkl\")\n",
        "out_linear = evaluate_TwoStageLinear(\n",
        "    model=linear_model,\n",
        "    data=files,\n",
        "    is_text=False,\n",
        ")\n",
        "\n",
        "print(\"Linear Evaluation on Sample Text:\")\n",
        "print(\"Accuracy:\", out_linear[\"accuracy\"])\n",
        "\n",
        "out_terminal = evaluate_terminal(\n",
        "    data=files,\n",
        "    is_text=False\n",
        ")\n",
        "print(\"Terminal Heuristic Evaluation on Sample Text:\")\n",
        "print(\"Accuarcy:\", out_terminal[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e25c79e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def display_comparison_table(\n",
        "    out_terminal: dict,\n",
        "    out_linear: dict,\n",
        "    out_lstm: dict,\n",
        "    *,\n",
        "    include_per_class: bool = True,\n",
        "    sort_per_class_cols: bool = True,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Takes the already-produced evaluation dicts (out_terminal/out_linear/out_lstm)\n",
        "    and returns a comparison DataFrame you can `display(df)`.\n",
        "\n",
        "    Assumes your eval dicts follow your format:\n",
        "      out[\"accuracy\"][\"accuracy with all classes\"][\"accuracy\"]\n",
        "      out[\"accuracy\"][\"accuracy without none\"][\"accuracy\"]\n",
        "      out[\"accuracy\"][\"binary accuracy punct vs none\"][\"binary_accuracy\"]\n",
        "      out[\"F-score\"][\"macro_f1_1_6\"]\n",
        "      out[\"F-score\"][\"binary_f1_punct\"]\n",
        "      out[\"F-score\"][\"per_class_f1\"] -> {1..6: f1}\n",
        "    And assumes ArabicPunctuationProcessor.CLASS_TO_PUNCTUATION exists.\n",
        "    \"\"\"\n",
        "    def _safe_get(d, *keys, default=None):\n",
        "        cur = d\n",
        "        for k in keys:\n",
        "            if not isinstance(cur, dict) or k not in cur:\n",
        "                return default\n",
        "            cur = cur[k]\n",
        "        return cur\n",
        "\n",
        "    def _row(name: str, out: dict) -> dict:\n",
        "        row = {\n",
        "            \"Model\": name,\n",
        "            \"Accuracy (all classes)\": _safe_get(out, \"accuracy\", \"accuracy with all classes\", \"accuracy\"),\n",
        "            \"Accuracy (exclude class 0)\": _safe_get(out, \"accuracy\", \"accuracy without none\", \"accuracy\"),\n",
        "            \"Binary Accuracy (punct vs none)\": _safe_get(out, \"accuracy\", \"binary accuracy punct vs none\", \"binary_accuracy\"),\n",
        "            \"Macro-F1 (classes 1..6)\": _safe_get(out, \"F-score\", \"macro_f1_1_6\"),\n",
        "            \"Binary F1 (punct vs none)\": _safe_get(out, \"F-score\", \"binary_f1_punct\"),\n",
        "        }\n",
        "\n",
        "        if include_per_class:\n",
        "            per = _safe_get(out, \"F-score\", \"per_class_f1\", default={}) or {}\n",
        "            for cls_id, f1v in per.items():\n",
        "                p = ArabicPunctuationProcessor.CLASS_TO_PUNCTUATION.get(int(cls_id), str(cls_id))\n",
        "                row[f\"F1 [{p}]\"] = float(f1v)\n",
        "        return row\n",
        "\n",
        "    rows = [\n",
        "        _row(\"Terminal Heuristic\", out_terminal),\n",
        "        _row(\"TwoStageLinear\", out_linear),\n",
        "        _row(\"BiLSTM\", out_lstm),\n",
        "    ]\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "\n",
        "    core_cols = [\n",
        "        \"Model\",\n",
        "        \"Accuracy (all classes)\",\n",
        "        \"Accuracy (exclude class 0)\",\n",
        "        \"Binary Accuracy (punct vs none)\",\n",
        "        \"Macro-F1 (classes 1..6)\",\n",
        "        \"Binary F1 (punct vs none)\",\n",
        "    ]\n",
        "    other_cols = [c for c in df.columns if c not in core_cols]\n",
        "\n",
        "    if sort_per_class_cols:\n",
        "        # Keep F1 columns in punctuation order if possible\n",
        "        order = [\"،\", \"؛\", \":\", \".\", \"؟\", \"!\"]\n",
        "        f1_cols = [f\"F1 [{p}]\" for p in order if f\"F1 [{p}]\" in other_cols]\n",
        "        other_cols = [c for c in other_cols if c not in f1_cols]\n",
        "        df = df[core_cols + f1_cols + sorted(other_cols)]\n",
        "    else:\n",
        "        df = df[core_cols + other_cols]\n",
        "\n",
        "    # Round numeric columns\n",
        "    for c in df.columns:\n",
        "        if c != \"Model\":\n",
        "            df[c] = pd.to_numeric(df[c], errors=\"coerce\").round(4)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "id": "07c93c46",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Model",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "Accuracy (all classes)",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Accuracy (exclude class 0)",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Binary Accuracy (punct vs none)",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Macro-F1 (classes 1..6)",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Binary F1 (punct vs none)",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "F1 [،]",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "F1 [؛]",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "F1 [:]",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "F1 [.]",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "F1 [؟]",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "F1 [!]",
                  "rawType": "float64",
                  "type": "float"
                }
              ],
              "ref": "91239a9f-58c6-4613-a2b0-d03e47ff53e2",
              "rows": [
                [
                  "0",
                  "Terminal Heuristic",
                  "0.9365",
                  "0.3098",
                  "0.9466",
                  "0.1426",
                  "0.5917",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.8487",
                  "0.0071",
                  "0.0"
                ],
                [
                  "1",
                  "TwoStageLinear",
                  "0.9566",
                  "0.5834",
                  "0.9573",
                  "0.3945",
                  "0.7184",
                  "0.3971",
                  "0.4792",
                  "0.4891",
                  "0.999",
                  "0.0028",
                  "0.0"
                ],
                [
                  "2",
                  "BiLSTM",
                  "0.9555",
                  "0.8897",
                  "0.9586",
                  "0.6825",
                  "0.8039",
                  "0.6459",
                  "0.6176",
                  "0.7125",
                  "0.9996",
                  "0.8177",
                  "0.3019"
                ]
              ],
              "shape": {
                "columns": 12,
                "rows": 3
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy (all classes)</th>\n",
              "      <th>Accuracy (exclude class 0)</th>\n",
              "      <th>Binary Accuracy (punct vs none)</th>\n",
              "      <th>Macro-F1 (classes 1..6)</th>\n",
              "      <th>Binary F1 (punct vs none)</th>\n",
              "      <th>F1 [،]</th>\n",
              "      <th>F1 [؛]</th>\n",
              "      <th>F1 [:]</th>\n",
              "      <th>F1 [.]</th>\n",
              "      <th>F1 [؟]</th>\n",
              "      <th>F1 [!]</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Terminal Heuristic</td>\n",
              "      <td>0.9365</td>\n",
              "      <td>0.3098</td>\n",
              "      <td>0.9466</td>\n",
              "      <td>0.1426</td>\n",
              "      <td>0.5917</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.8487</td>\n",
              "      <td>0.0071</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TwoStageLinear</td>\n",
              "      <td>0.9566</td>\n",
              "      <td>0.5834</td>\n",
              "      <td>0.9573</td>\n",
              "      <td>0.3945</td>\n",
              "      <td>0.7184</td>\n",
              "      <td>0.3971</td>\n",
              "      <td>0.4792</td>\n",
              "      <td>0.4891</td>\n",
              "      <td>0.9990</td>\n",
              "      <td>0.0028</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BiLSTM</td>\n",
              "      <td>0.9555</td>\n",
              "      <td>0.8897</td>\n",
              "      <td>0.9586</td>\n",
              "      <td>0.6825</td>\n",
              "      <td>0.8039</td>\n",
              "      <td>0.6459</td>\n",
              "      <td>0.6176</td>\n",
              "      <td>0.7125</td>\n",
              "      <td>0.9996</td>\n",
              "      <td>0.8177</td>\n",
              "      <td>0.3019</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Model  Accuracy (all classes)  Accuracy (exclude class 0)  \\\n",
              "0  Terminal Heuristic                  0.9365                      0.3098   \n",
              "1      TwoStageLinear                  0.9566                      0.5834   \n",
              "2              BiLSTM                  0.9555                      0.8897   \n",
              "\n",
              "   Binary Accuracy (punct vs none)  Macro-F1 (classes 1..6)  \\\n",
              "0                           0.9466                   0.1426   \n",
              "1                           0.9573                   0.3945   \n",
              "2                           0.9586                   0.6825   \n",
              "\n",
              "   Binary F1 (punct vs none)  F1 [،]  F1 [؛]  F1 [:]  F1 [.]  F1 [؟]  F1 [!]  \n",
              "0                     0.5917  0.0000  0.0000  0.0000  0.8487  0.0071  0.0000  \n",
              "1                     0.7184  0.3971  0.4792  0.4891  0.9990  0.0028  0.0000  \n",
              "2                     0.8039  0.6459  0.6176  0.7125  0.9996  0.8177  0.3019  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df = display_comparison_table(out_terminal=out_terminal, out_linear=out_linear, out_lstm=out_lstm)\n",
        "display(df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
